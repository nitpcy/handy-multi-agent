{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第四章: CAMEL框架下的RAG应用\n",
    "\n",
    "本章将深入探讨在CAMEL框架下如何构建和应用RAG（Retrieval-AugmentedGeneration）技术。我们将介绍关键模块，包括存储、加载器、嵌入、检索器，以及如何搭建知识库和评估RAG应用。\n",
    "\n",
    "## RAG的组件介绍\n",
    "\n",
    "### RAG简介\n",
    "\n",
    "要理解生成式AI的最新进展，可以想象一个法庭场景。\n",
    "\n",
    "法官基于对法律的一般理解听取并裁定案件。有时，一些案件——比如医疗事故诉讼或劳动争议——需要特殊的专业知识，于是法官会派书记员去法律图书馆查找先例和具体的法律案例以供引用。\n",
    "\n",
    "像优秀的法官一样，大型语言模型（LLM）能够回答各种人类问题。但如果需要提供权威答案并引用具体来源，模型需要一个助手来进行研究。\n",
    "\n",
    "AI的“法庭书记员”就是一种被称为检索增强生成（RAG，Retrieval-Augmented Generation）的技术。\n",
    "\n",
    " **\"**  **RAG**  **\"**  **这个名字的由来** \n",
    "\n",
    "2020年首次提出这一术语的论文主作者帕特里克·刘易斯（Patrick Lewis）对现在这一流行技术的不起眼缩写表示歉意。他认为这一方法已代表生成式AI的未来，相关研究已覆盖数百篇论文和众多商业服务。\n",
    "\n",
    "\"如果早知道我们的研究会被如此广泛应用，我们一定会更认真地起名字\"刘易斯在一次新加坡区域数据库开发者会议的采访中说道。\n",
    "\n",
    "\"我们原本计划为这个技术取一个更好听的名字，但最终写论文时，大家都没有提出更好的想法。\"刘易斯目前领导AI初创公司Cohere的一支RAG团队。\n",
    "\n",
    " **什么是检索增强生成（RAG）？** \n",
    "\n",
    "检索增强生成是一种通过从外部资源获取事实来提高生成式AI模型准确性和可靠性的技术。\n",
    "\n",
    "换句话说，它弥补了LLM工作中的一个空白。从底层来看，LLM是神经网络，其能力通常通过参数数量来衡量。LLM的参数本质上代表了人类使用单词构造句子的通用模式。\n",
    "\n",
    "这种深度理解（有时称为参数化知识）使得LLM能够以极快的速度对一般性提示做出回应。然而，当用户需要深入探讨某一当前或特定话题时，LLM可能力不从心。\n",
    "\n",
    " **内部与外部资源的结合** \n",
    "\n",
    "刘易斯及其同事开发了RAG技术，将生成式AI服务与外部资源相连，特别是那些富含最新技术细节的资源。\n",
    "\n",
    "他们与前Facebook AI研究团队（现为Meta AI）、伦敦大学学院（UCL）和纽约大学的共同作者在论文中将RAG称为“一种通用的微调方法”，因为几乎任何LLM都可以使用它连接几乎任何外部资源。\n",
    "\n",
    " **建立用户信任** \n",
    "\n",
    "检索增强生成为模型提供了可引用的来源，就像研究论文中的脚注，用户可以查证这些信息。这有助于建立信任。\n",
    "\n",
    "此外，这项技术还可以帮助模型澄清用户查询中的歧义，并减少模型“猜错”的可能性——这种现象有时被称为“幻觉”（hallucination）。\n",
    "\n",
    "RAG的另一个显著优势在于其实现相对简单。刘易斯和论文的三位共同作者在博客中提到，开发者可以用少至五行代码来实现这一过程。这使得RAG比用额外数据集重新训练模型更快捷、更经济。此外，它还支持用户即时更换新的信息源。\n",
    "\n",
    " **RAG的应用** \n",
    "\n",
    "通过检索增强生成，用户可以与数据存储库进行交互，从而开辟新的应用体验。这意味着RAG的潜在应用可以是可用数据集数量的多倍。\n",
    "\n",
    "例如，一个结合了医学索引的生成式AI模型可以成为医生或护士的得力助手。金融分析师可以借助与市场数据相连的助手提高工作效率。\n",
    "\n",
    "事实上，几乎任何企业都可以将其技术手册、政策手册、视频或日志转化为知识库，以提升LLM的能力。这些资源可以支持诸如客户服务、员工培训和开发者生产力等用例。\n",
    "\n",
    "正因如此，包括AWS、IBM、Glean、Google、Microsoft、NVIDIA、Oracle和Pinecone在内的公司正在广泛采用RAG技术。\n",
    "\n",
    "在CAMEL框架中，RAG被用于构建智能问答系统、对话Agent等应用，充分利用了框架的模块化设计和强大的处理能力。\n",
    "\n",
    "### Loaders\n",
    "\n",
    " **基本概念** \n",
    "\n",
    "Loaders是CAMEL框架中用于数据加载和预处理的模块。简而言之就是在 **CAMEL 框架** 中，引入了两个 IO 模块： **Base IO** 和 **Unstructured IO** ，用于处理多种文件类型以及非结构化数据的处理。此外，还新增了四种数据读取器： **Apify Reader** 、 **Chunkr Reader** 、 **Firecrawl Reader** 和 **Jina_url Reader** ，这些读取器能够从外部获取数据，从而提升数据集成与分析的能力。\n",
    "\n",
    " **Base IO** \n",
    "\n",
    " **Base IO 模块** 专注于与文件相关的基础输入/输出操作，提供了表示、读取和处理多种文件格式的功能。\n",
    "\n",
    "在实践环节中，该模块旨在读取各种格式的文件，提取其内容，并将其表示为 **File 对象** ，每个对象都针对特定的文件类型进行了专门设计以便高效处理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executable Code Actions Elicit Better LLM Agents\n",
      "Xingyao Wang 1 Yangyi Chen 1 Lifan Yuan 1 Yizhe Zhang 2 Yunzhu Li 1 Hao Peng 1 Heng Ji 1\n",
      "Abstract                         1. Introduction\n",
      "Large Language Models (LLMs) have emerged as a pivotal\n",
      "Large Language Model (LLM) agents, capable                                                                   breakthrough in natural language processing (NLP). When\n",
      "of performing a broad range of actions, such                                                            augmented with action modules that allow access to APIs,\n",
      "as invoking tools and controlling robots, show                                                                                their action space expands beyond conventional text pro-\n",
      "great potential in tackling real-world challenges.                                                                           cessing, allowing LLMs to acquire capabilities such as tool2024     LLM agents are typically prompted to produce ac-                                                                      invocation and memory management (Mialon et al., 2023;\n",
      "tions by generating JSON or text in a pre-defined                                                                   Schick et al., 2023) and venture into real-world tasks such as\n",
      "format, which is usually limited by constrainedJun                                                                     controlling robots (Ahn et al., 2022; Huang et al., 2023; Ma                action space  (e.g.,  the scope of pre-defined                                                                                 et al., 2023) and performing scientific experiments (Bran\n",
      "7          tools) and restricted flexibility (e.g., inability to                                                                                  et al., 2023).\n",
      "compose multiple tools).  This work proposes\n",
      "to use executable Python code to consolidate      We inquire: how to effectively expand LLM agents’ action\n",
      "LLM agents’ actions into a unified action space        space for solving complex real-world problems? Much\n",
      "(CodeAct). Integrated with a Python interpreter,          existing research has examined using text (Yao et al., 2022b;\n",
      "CodeAct can execute code actions and dynam-        Park et al., 2023, inter alia) or JSON (Qin et al., 2023b;[cs.CL]          ically revise prior actions or emit new actions        Chase, 2022, inter alia) to produce actions (e.g., tool uses\n",
      "upon new observations through multi-turn interac-         in Fig. 1 top left). However, both methods typically suffer\n",
      "tions. Our extensive analysis of 17 LLMs on API-        from constrained scope of action spaces (actions are usually\n",
      "Bank and a newly curated benchmark shows that          tailored for specific tasks) and restricted flexibility (e.g.,\n",
      "CodeAct outperforms widely used alternatives          inability to compose multiple tools in a single action). As an\n",
      "(up to 20% higher success rate). The encouraging          alternative approach, several work (Liang et al., 2022; Singh\n",
      "performance of CodeAct motivates us to build          et al., 2023; Wang et al., 2023a) demonstrate the potential\n",
      "an open-source LLM agent that interacts with en-         of using LLMs to generate code to control robots or game\n",
      "vironments by executing interpretable code and          characters. However, they typically rely on pre-specified\n",
      "collaborates with users using natural language. To         control primitives and hand-engineered prompts and, more\n",
      "this end, we collect an instruction-tuning dataset         importantly, struggle to dynamically adjust or emit actions\n",
      "CodeActInstruct that consists of 7k multi-turn in-        based on new environmental observation and feedback.\n",
      "teractions using CodeAct. We show that it can                                                                  This work proposes CodeAct, a general-purpose frame-\n",
      "be used with existing data to improve models in                                                           work that allows LLMs to generate executable Python code\n",
      "agent-oriented tasks without compromising theirarXiv:2402.01030v4                                                                  as actions (Fig. 1 top right). CodeAct is designed to handle\n",
      "general capability. CodeActAgent, finetuned from                                                                    a variety of applications and comes with unique advantages:\n",
      "Llama2 and Mistral, is integrated with Python in-\n",
      "terpreter and uniquely tailored to perform sophis-         (1)  Integrated with a Python interpreter, CodeAct can ex-\n",
      "ticated tasks (e.g., model training) using existing              ecute code actions and dynamically adjust prior actions\n",
      "libraries and autonomously self-debug1.                    or emit new action based on observations (e.g., code\n",
      "execution results) it receives through multiple turns of\n",
      "interactions.              1Department of Computer Science, University of Illinois\n",
      "(2) Code actions allow LLM to leverage existing software          Urbana-Champaign 2Apple. Correspondence to: Xingyao Wang\n",
      "<xingyao6@illinois.edu>, Heng Ji <hengji@illinois.edu>.            packages. CodeAct can use readily available Python\n",
      "packages for an expanded action space instead of hand-\n",
      "Proceedings of the 41 st International Conference on Machine         crafted task-specific tools (Yuan et al., 2023; Shen et al.,\n",
      "Learning, Vienna, Austria. PMLR 235, 2024. Copyright 2024 by                                                                        2023). It also allows LLM to use automated feedback\n",
      "the author(s).\n",
      "(e.g., error messages) implemented in most software to             1The code, data, model, and demo are available at https:\n",
      "//github.com/xingyaoww/code-act.                     improve task-solving by self-debugging its generated\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "from io import BytesIO\n",
    "from camel.loaders import create_file_from_raw_bytes\n",
    "\n",
    "# 读取pdf文件\n",
    "with open(\"test.pdf\", \"rb\") as file:\n",
    "    file_content = file.read()\n",
    "\n",
    "\n",
    "# 使用create_file函数根据文件扩展名创建对象\n",
    "file_obj = create_file_from_raw_bytes(file_content, \"test.pdf\")\n",
    "\n",
    "# 获取File对象的内容\n",
    "print(file_obj.docs[0][\"page_content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "File(name=test.pdf, id=4218aac51272d56620465ea8c1aaed76, metadata={}, docs=[{'page_content': 'Executable Code Actions Elicit Better LLM Agents\\nXingyao Wang 1 Yangyi Chen 1 Lifan Yuan 1 Yizhe Zhang 2 Yunzhu Li 1 Hao Peng 1 Heng Ji 1\\nAbstract                         1. Introduction\\nLarge Language Models (LLMs) have emerged as a pivotal\\nLarge Language Model (LLM) agents, capable                                                                   breakthrough in natural language processing (NLP). When\\nof performing a broad range of actions, such                                                            augmented with action modules that allow access to APIs,\\nas invoking tools and controlling robots, show                                                                                their action space expands beyond conventional text pro-\\ngreat potential in tackling real-world challenges.                                                                           cessing, allowing LLMs to acquire capabilities such as tool2024     LLM agents are typically prompted to produce ac-                                                                      invocation and memory management (Mialon et al., 2023;\\ntions by generating JSON or text in a pre-defined                                                                   Schick et al., 2023) and venture into real-world tasks such as\\nformat, which is usually limited by constrainedJun                                                                     controlling robots (Ahn et al., 2022; Huang et al., 2023; Ma                action space  (e.g.,  the scope of pre-defined                                                                                 et al., 2023) and performing scientific experiments (Bran\\n7          tools) and restricted flexibility (e.g., inability to                                                                                  et al., 2023).\\ncompose multiple tools).  This work proposes\\nto use executable Python code to consolidate      We inquire: how to effectively expand LLM agents’ action\\nLLM agents’ actions into a unified action space        space for solving complex real-world problems? Much\\n(CodeAct). Integrated with a Python interpreter,          existing research has examined using text (Yao et al., 2022b;\\nCodeAct can execute code actions and dynam-        Park et al., 2023, inter alia) or JSON (Qin et al., 2023b;[cs.CL]          ically revise prior actions or emit new actions        Chase, 2022, inter alia) to produce actions (e.g., tool uses\\nupon new observations through multi-turn interac-         in Fig. 1 top left). However, both methods typically suffer\\ntions. Our extensive analysis of 17 LLMs on API-        from constrained scope of action spaces (actions are usually\\nBank and a newly curated benchmark shows that          tailored for specific tasks) and restricted flexibility (e.g.,\\nCodeAct outperforms widely used alternatives          inability to compose multiple tools in a single action). As an\\n(up to 20% higher success rate). The encouraging          alternative approach, several work (Liang et al., 2022; Singh\\nperformance of CodeAct motivates us to build          et al., 2023; Wang et al., 2023a) demonstrate the potential\\nan open-source LLM agent that interacts with en-         of using LLMs to generate code to control robots or game\\nvironments by executing interpretable code and          characters. However, they typically rely on pre-specified\\ncollaborates with users using natural language. To         control primitives and hand-engineered prompts and, more\\nthis end, we collect an instruction-tuning dataset         importantly, struggle to dynamically adjust or emit actions\\nCodeActInstruct that consists of 7k multi-turn in-        based on new environmental observation and feedback.\\nteractions using CodeAct. We show that it can                                                                  This work proposes CodeAct, a general-purpose frame-\\nbe used with existing data to improve models in                                                           work that allows LLMs to generate executable Python code\\nagent-oriented tasks without compromising theirarXiv:2402.01030v4                                                                  as actions (Fig. 1 top right). CodeAct is designed to handle\\ngeneral capability. CodeActAgent, finetuned from                                                                    a variety of applications and comes with unique advantages:\\nLlama2 and Mistral, is integrated with Python in-\\nterpreter and uniquely tailored to perform sophis-         (1)  Integrated with a Python interpreter, CodeAct can ex-\\nticated tasks (e.g., model training) using existing              ecute code actions and dynamically adjust prior actions\\nlibraries and autonomously self-debug1.                    or emit new action based on observations (e.g., code\\nexecution results) it receives through multiple turns of\\ninteractions.              1Department of Computer Science, University of Illinois\\n(2) Code actions allow LLM to leverage existing software          Urbana-Champaign 2Apple. Correspondence to: Xingyao Wang\\n<xingyao6@illinois.edu>, Heng Ji <hengji@illinois.edu>.            packages. CodeAct can use readily available Python\\npackages for an expanded action space instead of hand-\\nProceedings of the 41 st International Conference on Machine         crafted task-specific tools (Yuan et al., 2023; Shen et al.,\\nLearning, Vienna, Austria. PMLR 235, 2024. Copyright 2024 by                                                                        2023). It also allows LLM to use automated feedback\\nthe author(s).\\n(e.g., error messages) implemented in most software to             1The code, data, model, and demo are available at https:\\n//github.com/xingyaoww/code-act.                     improve task-solving by self-debugging its generated\\n1', 'page': 1}, {'page_content': 'Executable Code Actions Elicit Better LLM Agents\\nSuccess Rate (%)                                Average Number of Interaction Turns\\ngpt-4-1106-preview\\ngpt-4-0613\\nclaude-2\\ngpt-3.5-turbo-0613\\ngpt-3.5-turbo-1106\\ngemini-pro                                           Action Mode\\nCode as Action\\ntext-davinci-003                                                          JSON as Action\\nLlama-2-70b-chat-hf                                                  Text as Action\\n0     10     20     30     40     50     60     70      5          6          7          8          9         10\\nFigure 1: Comparison between CodeAct and Text / JSON as action. (top) Illustrative example comparing different actions.\\n(bottom) Quantitative results on M3ToolEval (§2.3).\\ncode (Chen et al., 2023b; Wang et al., 2023d).                fits (3 & 4) of CodeAct. To demonstrate benefit (3), our\\n(3) Code data is widely used in pre-training today’s LLMs      first experiment (§2.2) compares CodeAct to baselines on\\n(Yang et al., 2024b). These models are already familiar    basic tasks involving atomic tool use (i.e., only one tool is\\nwith structured programming languages, allowing cost-    used per action), ablating the control and data flow advan-\\neffective adoption of CodeAct.                         tage offered by CodeAct. The results show that, for most\\n(4) Compared to JSON and text with a pre-defined format,   LLMs, CodeAct achieves comparable or better perfor-\\ncode inherently supports control and data flow, allow-   mance than the baselines. CodeAct’s performance gains\\ning for the storage of intermediate results as variables    are more prominent on complex tasks, as demonstrated in\\nfor reuse and the composition of multiple tools to per-    our second experiment (benefit 4). We curate a new bench-\\nform complex logical operations (e.g., if-statements,   mark consisting of 82 human-curated tasks that typically\\nfor-loops) with one piece of code, thereby unlocking     require multiple calls to multiple tools in multi-turn interac-\\nLLMs’ potential to tackle complex tasks by leveraging     tions (M3ToolEval; §2.3). Problems in this benchmark often\\nits pre-trained knowledge of programming. In Fig. 1,    require intricate coordination and composition of multiple\\nan LLM using with CodeAct (top right) can apply the     tools. With its strengths in control and data flow, CodeAct\\nsame sequence of tools (e.g., passing one tool’s output    achieves up to a 20% absolute improvement over baselines\\nas input to another tool using the data flow feature) to    on the success rate of solving the problems while requiring\\nall inputs through for-loops (i.e., control flow feature)   up to 30% fewer actions. These performance gains widen\\nwith one action; while text or JSON have to take action    as the capabilities of the LLMs increase (Fig. 1 bottom).\\nfor every input (top left).\\nThe promising performance of CodeAct motivates an\\nOur extensive experiments with 17 LLMs (including both    open-source LLM agent that can effectively act through\\nopen-source and proprietary ones) confirm the above bene-   CodeAct, and collaborate with humans through natural lan-\\n2', 'page': 2}, {'page_content': 'Executable Code Actions Elicit Better LLM Agents\\nTable 1: The benefit of CodeAct compared to using Text/JSON for LLM action.\\nCodeAct for LLM action                  JSON or Text for LLM action\\nAvailability of Data              \"Large quantity of code available1 for pre-training   %Data curation required for particular format\\nComplex Operation (e.g., looping,                                              %Requires careful engineering if feasible (e.g.,\\n\"Natively supported via control and data flow\\ncomposition of multiple tools)                                                                 define new tools to mimic if-statement)\\n%Requires human effort to curate tools from\\nAvailability of Tools            \"Can directly use existing software packages2\\nscratch or existing software\\n\"Feedback mechanism3 (e.g., traceback) is already  %Requires human effort to provide feedback or re-\\nAutomated Feedback               implemented as an infrastructure for most program-   route feedback from the underlying programming\\nming languages                                    language used to implement the tools\\n1 Including code demonstrating useful behaviors for LLM agents (e.g., task decomposition, coordination of multiple function calls to different tools).\\n2 Human-written Python packages covering a wide range of applications are available on https://pypi.org/.\\n3 For example, in Python, errors and exceptions (https://docs.python.org/3/tutorial/errors.html) are available. Most software\\nprovides error messages in natural language to help human programmers debug their code. CodeAct enables LLM to use them directly.\\nguage. To this end, we collect an instruction-tuning dataset   17 off-the-shelf LLMs. In §2.2, we examine RQ1: Does\\nCodeActInstruct consisting of 7k high-quality multi-turn   LLMs’ familiarity with code due to a large amount of code\\ninteraction trajectories with CodeAct (§3.1). CodeActIn-    pre-training data bring CodeAct advantages over text and\\nstruct is motivated by a general agent framework consisting   JSON? We discuss RQ2 in §2.3: Does CodeAct benefit\\nof agent, user, and environments (Fig. 2) and focuses on    from Python’s innate control and data flow feature in com-\\nagent-environment interactions with the computer (informa-    plex problems? Finally, as an additional benefit, we discuss\\ntion seeking, software package use, external memory) and   how using CodeAct further enhances LLM agents by en-\\nthe physical world (robot planning). On CodeActInstruct,    abling multi-turn interactions and allowing them to access\\nwe perform careful data selection to promote the capability    existing software in §2.4 and Fig. 3.\\nof improving from multi-turn interaction (e.g., self-debug).\\nWe show that CodeActInstruct can be used with commonly     2.1. What is CodeAct?\\nused instruction tuning data to improve the models’ perfor-\\nIn Fig. 2, we first introduce a general multi-turn interactionmance in agent tasks without compromising their general\\nframework for LLM agents’ real-world usage that considerscapabilities (e.g., knowledge-based QA, coding, instruction\\nthree roles (Yang et al., 2024c): agent, user, and environ-following, §3.2). Our model, dubbed CodeActAgent, is fine-\\nment. We define interaction as the information exchangetuned from LLaMA-2 (Touvron et al., 2023) and Mistral-7B\\nbetween the agent and an external entity (user or environ-(Jiang et al., 2023) and improves on out-of-domain agent\\nment). For each turn of interaction, the agent receives an ob-tasks with not only CodeAct, but also text action in a\\nservation (input) either from the user (e.g., natural languagepre-defined format (§3.2).\\ninstruction) or the environment (e.g., code execution result),\\nCodeAct can further benefit from multi-turn interactions    optionally planning for its action through chain-of-thought\\nand existing software (benefit 1 & 2, §2.4). As shown in    (Wei et al., 2022), and emits an action (output) to either user\\nFig. 3, CodeActAgent, designed for seamless integration     in natural language or the environment. CodeAct employs\\nwith Python, can carry out sophisticated tasks (e.g., model    Python code to consolidate all actions for agent-environment\\ntraining, data visualization) using existing Python packages.    interaction. In CodeAct, each emitted action to the en-\\nError messages from the environment further enable it to    vironment is a piece of Python code, and the agent will\\nrectify errors autonomously through self-debugging in multi-    receive outputs of code execution (e.g., results, errors) as\\nturn interaction. Thanks to LLM’s extensive programming    observation. We include an example prompt of CodeAct\\nknowledge acquired during pre-training, these are achieved     in §E.\\nwithout needing in-context demonstrations, reducing the\\nhuman efforts for adapting CodeActAgent to different tasks.    2.2. CodeAct Shows the Promise as a Strong Tool Use\\nFramework\\n2. CodeAct Makes LLMs Better Agents                                                              In this section, we perform a controlled experiment to under-\\nIn this section, we first describe CodeAct framework (§2.1)    stand which format (text, JSON, CodeAct) is more likely\\nand provide empirical evidence that supports the choice of     to lead an LLM to generate correct atomic tool calls. The\\nCodeAct. We focus on Python as the programming lan-    performance in this experiment reflects LLM’s familiarity\\nguage for CodeAct due to its popularity (ranked top-1 at    with the corresponding format. We hypothesize that using\\n(TIOBE Index, 2024)) and numerous open-source packages.   CodeAct to call tools is a more natural way to use tools\\nWe aim to answer several research questions (RQs) using     for the models, which typically have extensive exposure to\\n3', 'page': 3}, {'page_content': \"Executable Code Actions Elicit Better LLM Agents\\nExample                                  CodeAct                                                               Action               Conversation        User:                                                                                                                                                             in Natural Language                                                                        unified                                                                              action space\\nFind the sum of the reciprocals of the roots of\\n$x^2-13x+4=0$.\\nAssistant:\\nTo find the sum of the reciprocals of the roots       EnvironmentSoftware Interface (API)                     Think\\nof the quadratic equation $x^2-13x+4=0$ [...]\\nInterface for Computer\\n<execute>\\nInformation Seeking\\nimport sympy                                                                                           (e.g., Web search, Browsing)                          Planning\\nx = sympy.Symbol('x')                                   Software Package (Tool)\\nroots              = sympy.solve(x**2                                 - 13*x + 4)                                     (e.g.,                                                                                                                       Calculate,\\nprint(1/roots[0]                         + 1/roots[1])                                                                       External                                                           Memory                                                                                                          Download, Visualize)      Agent        == Chain-of-though+Self-Reflectio:        User      Start\\n</execute>                                                                                               (e.g., Database,[...]Graph)                                                           = Improving Action from\\nEnv:                                                     Interface for Physical World                                             Prior Observatio:\\n1/(3*sqrt(17)/2 + 13/2) + 1/(13/2 - 3*sqrt(17)/2)          Robots                                                                    =  ...\\nAssistant:                                                                                                 (e.g., Household Robots, Automated Lab)\\n[...]                                                            Initiate Interaction\\nThe roots obtained are in symbolic form, which\\nmakes it difficult to evaluate the sum directly.\\nLet's use the quadratic formula to explicitly        Outcome                                           Conversation\\nfind the numerical values of the roots first.                  E.g., Execution results,         Observation                                               E.g., Natural Language\\n[...]                                                Automated error feedback                                                                         Instruction or Feedback\\nFigure 2: General agent multi-turn interaction framework that describes the role of CodeAct and motivates the construction\\nof our data mixture. CodeActInstruct focuses on the agent-environment interactions and specifically filters for the self-\\nimproved planning behavior, while general conversation data we include focuses on agent-user interaction (§3.1).\\ncode data during their training.                                  that require complex patterns of tool use.\\nSetup. We re-purpose API-Bank (Li et al., 2023) and test    M3ToolEval. As shown in Tab. A.7, to the best of our\\nLLMs’ API-calling performance, comparing CodeAct,    knowledge, no existing tool-use benchmarks contain com-\\nJSON, and text actions. For each evaluation instance, we    plex tasks requiring the composition of multiple tools while\\ninstruct LLM to generate one atomic tool call in the format    supporting evaluating different action formats. Hence, we\\nof a Python function call, JSON object, or text expression     curate a benchmark M3ToolEval to fill this gap, which eval-\\nin a pre-defined format. A concrete example is shown in    uates LLMs’ capabilities in solving complex tasks that typi-\\nTab. A.6. We use API-Bank’s level-1 instructions and the     cally require multiple calls to multiple tools in multi-turn\\nprovided toolset. To evaluate API-calling, we follow their     interactions. It contains 82 human-curated instances, span-\\ncorrectness metric, matching the ground-truth API outputs    ning tasks including web browsing, finance, travel itinerary\\nwith the actual model-generated API’s execution outputs.      planning, science, and information processing. Each do-\\nmain is accompanied by a unique set of manually crafted\\nResults. We present results in Tab. 2. For most LLMs,\\ntools. We intentionally keep the prompt simple (examples\\nCodeAct achieves comparable or better performance even\\nin §F) and avoid providing any demonstration to test the\\nin atomic actions (the simplistic tool use scenario) where\\nLLM’s zero-shot ability to use tools, similar to how a novice\\nits control and data flow strengths are ablated. Compared to\\nuser without knowledge of few-shot prompting would use\\nclosed-source LLMs, CodeAct’s improvements are more\\nthe model.\\nprominent in open-source models. Furthermore, code data is\\nusually more accessible for fine-tuning open-source LLMs    Setup. We allow the model to generate fully functional\\nthan the specialized JSON or text tool-calling format. Al-   Python code that enables control and data flow (e.g., if-\\nthough JSON is consistently weaker than other approaches    statement, for-loop). We follow the action format for JSON\\nfor open-source models, it achieves decent performance with    and text described in Tab. A.6. Within each turn, the model\\nclosed-source LLMs, indicating that these closed-source    can either emit an action or propose an answer to be verified\\nmodels may have gone through targeted fine-tuning toward    by an exact match with the ground-truth solution. The\\ntheir JSON capabilities. These results suggest optimizing     interaction will terminate when a maximum of 10 interaction\\nfor CodeAct is a better route for open-source LLMs than    turns are reached or a correct solution has been submitted,\\nalternatives to improve their tool-use capabilities, as they    similar to (Wang et al., 2023e).\\nalready show good initial CodeAct capability due to ex-\\nMetric. We measure the success rate by calculating the\\ntensive exposure to code data during pre-training.\\npercentage of the model proposed answers that match the\\nground-truth solutions. We also include the avg. turns met-\\n2.3. CodeAct Gets More Done with Fewer Interactions                                                                            ric: the average number of turns on all evaluated instances.\\nIn this section, we investigate whether LLM agents can                                                        Quantitative Results on M3ToolEval. We include full re-\\nbenefit from the control and data flow of code on problems                                                                    sults in Tab. 3 and a subset of results for visualization in\\n4\", 'page': 4}, {'page_content': 'Executable Code Actions Elicit Better LLM Agents\\nTable 2: Atomic API call correctness on API-  Table 3: Success rates (higher the better) and average turns required per\\nBank. The best performance is bolded, and the  instance (lower the better) on M3ToolEval. The best results for each\\nsecond-best is underlined.                    model are bolded, and the second-best ones are underlined.\\nCorrectness (%, ↑)                                             Success Rate (%, ↑)            Avg. Turns (↓)\\nFormat of Action               CodeAct  JSON   Text                                                       Format of Action               CodeAct  JSON   Text    CodeAct  JSON   Text\\nOpen-source LLMs                                                                                                 Open-source LLMs\\nCodeLlama-7b-Instruct-hf          12.5    12.0  17.0  CodeLlama-7b-Instruct-hf          4.9     2.4    2.4           9.7     9.9    9.9\\nCodeLlama-13b-Instruct-hf        11.8     7.8  14.0  CodeLlama-13b-Instruct-hf        4.9     4.9   4.9             9.8     9.8   9.7\\nCodeLlama-34b-Instruct-hf       17.3    12.0   16.8  CodeLlama-34b-Instruct-hf        2.4     0.0    0.0           9.9    10.0   10.0\\nLlama-2-7b-chat-hf               28.8    11.3   25.8  Llama-2-7b-chat-hf                    0.0     1.2   2.4           8.9     9.5    9.6\\nLlama-2-13b-chat-hf              38.1     8.5   37.3  Llama-2-13b-chat-hf                0.0     0.0   0.0           9.7    10.0   10.0\\nLlama-2-70b-chat-hf                35.6    14.3  37.6  Llama-2-70b-chat-hf              11.0     3.7    3.7           9.1     9.8    9.8\\nMistral-7B-Instruct-v0.1           2.5     2.3    3.0  Mistral-7B-Instruct-v0.1           0.0     3.7    1.2           10.0     9.8    9.9\\nlemur-70b-chat-v1                58.6    46.6   56.1  lemur-70b-chat-v1                   13.4   15.9   12.2           9.1     9.3    9.4\\nClosed-source LLMs                                                             Closed-source LLMs\\nclaude-2                           76.7    59.4   73.7  claude-2                           54.9    39.0   29.3           7.2     8.3    8.5\\nclaude-instant-1                  75.2    64.9   73.2  claude-instant-1                    20.7   31.7   24.4             8.8     8.6    8.9\\ngemini-pro                            70.4   73.2   71.2  gemini-pro                         22.0    19.5   11.0           8.8     9.1    9.5\\ngpt-3.5-turbo-0613               74.4    73.9   73.4  gpt-3.5-turbo-0613               51.2    26.8   20.7           7.0     8.8    9.2\\ngpt-3.5-turbo-1106                  75.4   78.4   73.4  gpt-3.5-turbo-1106               29.3    15.9   14.6           8.4     9.0    9.0\\ngpt-4-0613                            75.4   82.0   74.4  gpt-4-0613                         67.1    56.1   45.1           6.6     7.6    8.0\\ngpt-4-1106-preview                  76.7   82.7   73.4  gpt-4-1106-preview               74.4    52.4   53.7           5.5     7.6    7.7\\ntext-davinci-002                  69.2    59.6   57.4  text-davinci-002                      4.9     4.9   8.5             9.7     9.8   9.6\\ntext-davinci-003                    75.4   76.9   69.7  text-davinci-003                  20.7    18.3    7.3             9.2     9.0    9.6\\nFrequency of Best-Performing Format ↑                                 Frequency of Best-performing Format ↑\\nOpen-source                          4      0     4   Open-source                          5      4     3          6      1     1\\nClosed-source                            4     5     0   Closed-source                         7      1     1          6      2     1\\nOverall                             8      5     4   Overall                            12      5     4         12      3     2\\nFig. 1. CodeAct generally has a higher task success rate    and use Matplotlib for data visualization. Furthermore, us-\\n(12 out of 17 evaluated LLMs), similar to the trend in §2.2.    ing the interactive Python interpreter for code execution\\nMoreover, using CodeAct requires a lower average num-    allows automated error messages that help the LLM agent\\nber of turns (12 out of 17 evaluated LLMs). For example, the    ‘self-debug’ their actions in a multi-turn interaction and\\nbest model gpt-4-1106-preview achieves a 20.7% ab-    eventually complete the human user’s request correctly.\\nsolute improvement compared to the next best action format\\n(text) while requiring 2.1 fewer interaction turns on average.                                                        3. Empowering Open-source LLM Agent to be\\nHowever, there is still a significant gap in terms of absolute\\nBetter at CodeActCodeAct performance between open- and closed-source\\nLLMs as the best open-source model achieving 13.4% while   The promising results achieved by CodeAct motivate us\\nthe best closed-source model gpt-4-1106-preview    to build an open-source LLM agent that can both inter-\\n74.4%. This is potentially due to open-source models’ weak    act with environments through CodeAct and communi-\\ntask-solving capability and inability to follow complex in-    cate with humans using language. To improve open-source\\nstructions without demonstration, suggesting an urgent need   LLMs’ CodeAct capability, in §3.1, we introduce Code-\\nto improve open-source LLMs for practical, real-world tasks    ActInstruct, an instruction finetuning dataset that contains\\nunder the zero-shot setting.                                 agent-environment interaction trajectories. We discuss data\\nselection procedures in §3.1 to promote improvement from\\n2.4. CodeAct Benefits from Multi-turn Interactions        interaction behavior. Additionally, we show that CodeAct\\nand Existing Software Packages                     can be used together with existing agent-user conversation\\ndata (§3.1) to balance the dialog capability of the resulting\\nIn Fig. 3, we show how an LLM agent can integrate with\\nLLM. Our model CodeActAgent, finetuned from LLaMA-2\\nPython (i.e., CodeActAgent we trained in §3.2) and use\\n(Touvron et al., 2023) and Mistral-7B (Jiang et al., 2023)\\nexisting software to perform complex tasks in multi-turn\\non a mixture of CodeActInstruct and general conversations,\\ninteractions. Thanks to its extensive knowledge of Python\\nimproves CodeAct performances without hurting LLM’s\\nlearned during pre-training, the LLM agent can automat-\\ngeneral performance on a diverse suite of tasks (§3.2).\\nically import the correct Python libraries to solve tasks\\nwithout requiring user-provided tools or demonstrations. As\\n3.1. CodeActInstruct: Agent-Environment Interactionsillustrated in Fig. 3, CodeActAgent can use Pandas to down-\\nload and process tabular data, use Scikit-Learn for machine   We consider four main use cases in agent-environment inter-\\nlearning train-test data split and regression model training,    action and repurpose five existing datasets across different\\n5', 'page': 5}, {'page_content': 'Executable Code Actions Elicit Better LLM Agents\\nEnvironment                                                                                                        User    User\\nMean                                                                             squared                                                                                     error:  10.710864418838367                              Can                                                                                                                                                   you rotate the x ticks by 45 degrees for better readability?  Here          is a dataset about auto MPG: \"https://huggingface.co/datasets/scikit-                                                                        R^2                                                                            score:                                                                                    0.790150038676035\\nlearn/auto-mpg/raw/main/auto-mpg.csv\". You should download and load the\\ndataset from the URL, take a look at it, check for missing value, do a train-test       CodeActAgent                                     CodeActAgent\\nsplit, and train a regression model predicting its MPG. You should use              The mean squared error is 10.711 and the R^2 score is 0.790, which indicates that       Certainly! Here is the updated bar chart with the x-ticks rotated by 45 degrees\\neverything except \"mpg\" and \"car name\" as the input features.                      the model has a good fit with the data [...]                                              for better readability:\\n[..same code omitted...]\\nCodeActAgent                                      User                                                                #plt.bar(feature_names,Plot regression coefficientscoef, tick_labels=False)\\nTo accomplish this task, I will use the pandas library to download and load the       Can you also give me the MSE and R^2 for the training set?                          plt.xticks(feature_names, feature_names,\\nrotation=45,                                                                                                                                                                         ha=\\'right\\', fontsize=12)\\ndataset,          check                  for                   missing                             values,                              and perform                                           a train-test split. Then, I will use\\n[..same code                                                                                                                                                              omitted...]\\nthe       scikit-learn                    library                         to train                              a regression                                         model.                                                    CodeActAgent     Able to Answer follow-up Question Interactively\\nimport              pandas                        pd                     as\\nimport numpy as np                                                                    Certainly! Here are the mean squared error (MSE) and R^2 scores [...]            Environment\\nsklearn.model_selection                                    import                                           train_test_split       from                                                                                                                                                                                                              640x480                                                                                                                                                                                                                             Axes>                                                                                                                                                                                                         size                                                                                                                                                                                                                      with                                                                                                                                                                                                                           1                                                                                                                                                                                                 <Figure                                                                                      from                                                                                           sklearn.metrics                                                                                                                  mean_squared_error                                                                                                           import            sklearn.linear_model                                 import       from                                        LinearRegression                                                                                                                                                                                                 ---------------------------------------------------------------------------\\n#                                                                                        Calculate                                                                                                  MSE                                                                                                      for                                                                                                          training                                                                                                                   set\\nAttributeError                                                                                                                                                                                                                                            Traceback                                                                                                                                                                                                                                                     (most recent                                                                                                                                                                                                                                                                  call                                                                                                                                                                                                                                                                       last)\\nmse_train                                                                                                =                                                                                                  mean_squared_error(y_train,                                                                                                                              model.predict(X_train))       #         Download                  and                      load                           the                               dataset                                                                                                                                                                                                             line                                                                                                                                                                                                                  10                                                                                                                                                                                                 Cell                                                                                                                                                                                                      In[1],\\ndf          =            pd.read_csv(                                                                                      #                                                                                        Calculate                                                                                                  R^2                                                                                                      score                                                                                                            for training                                                                                                                         set                                                                                                                                                                                                       7                                                                                                                                                                                                         feature_names                                                                                                                                                                                                                       = model.feature_names_in_\\n\"https://huggingface.co/datasets/scikit-learn/auto-mpg/raw/main/auto-mpg.csv\")                                                                                                                                                                                                         #                                                                                                                                                                                                           Plot                                                                                                                                                                                                                regression                                                                                                                                                                                                                           coefficients                                                                                                                                                                                                       9                                                                                      r2_train                                                                                               =                                                                                                 r2_score(y_train,                                                                                                                   model.predict(X_train))                                                                                                                                                                                                        Self-Debug                                                                                                                                                                                                                                             for Data\\n#         Check               for                   missing                           values                                                                                                                                                                                                      10                                                                                                                                                                                                         plt.bar(feature_names,                                                                                                                                                                                                                                coef,                                                                                                                                                                                                                                      tick_labels=False)                                                                                                                                                                                                 --->\\nVisualization       print(df.isnull().sum())                                                                                                                                                                                                         plt.xticks(feature_names,                                                                                                                                                                                                                                   feature_names,                                                                                                                                                                                                      11                                                                                      print(\"Mean                                                                                                  squared                                                                                                          error                                                                                                                (training                                                                                                                          set):\",                                                                                                                                  mse_train)       #         Remove                rows                     with                          missing                                  values                                                                                                                                                                                                                    rotation=45,                                                                                                                                                                                                                                 ha=\\'right\\',                                                                                                                                                                                                                                             fontsize=12)                                       Use                                           Pandas Library                                                                to Download,                                                                                      print(\"R^2                                                                                                 score                                                                                                       (training                                                                                                                 set):\",                                                                                                                         r2_train)       df          =            df.dropna()                                                                                                                                                                                                      12                                                                                                                                                                                                         plt.xlabel(\\'Input                                                                                                                                                                                                                           Feature\\')\\n#         Perform                 train-test                            split                                           Examine,                                                 and Process                                                                Data                                                                                                                                                                                                 [...]\\n\"car                                        name\"])       X         =           df.drop(columns=[\"mpg\",                                                                                                                                                                                                 AttributeError:                                                                                                                                                                                                                 Rectangle.set()                                                                                                                                                                                                                                 got                                                                                                                                                                                                                                     an                                                                                                                                                                                                                                         unexpected                                                                                                                                                                                                                                                   keyword                                                                                                                                                                                                                                                           argument                                                                                                                                                                                                                                                                    \\'tick_labels\\'\\ny         =           df[\"mpg\"]                                                  Environment\\nX_train,                X_test,                        y_train,                                 y_test = train_test_split(X,                                                              y,\\ntest_size=0.2,\\n# Train a                 regression                            model                                                                          random_state=42)     MeanR^2 scoresquared(trainingerror (trainingset): 0.826001578671067set): 10.979255842373478              CodeActAgent\\nmodel             = LinearRegression()\\nmodel.fit(X_train,                          y_train)               Use Scikit-Learn Library to Split                                                                                                                 It seems that the tick_labels argument is not a valid argument for\\n#         Predict                 MPG                     for                                                                                                                                                                  the                                                                                                                                                                                   bar()                                                                                                                                                                              function                                                                                                                                                                                               in                                                                                                                                                                                                    Matplotlib. Instead, we can use the tick_params() function                                                     CodeActAgent                         test data                Data and Train Regression Model\\ny_pred              = model.predict(X_test)\\nto rotate                                                                                                                                                                          the                                                                                                                                                                                       x-ticks                                                                                                                                                                                                                                                                                                         [...]                                                                      The                                                                   mean squared error for the training set is 10.979 and the R^2 score is 0.826,       #         Evaluate                  the                      model\\nprint(\"Mean                   squared                           error:                                  \", np.mean((y_test                                                                                                                                                          code omitted...]                                                     - y_pred) ** 2))                      which indicates [...]                                                         [...same\\nr2_score(y_test,                                             y_pred))       print(\"R^2 score:                         \",                                                                                                                                                 plt.bar(feature_names,                                                                                                                                                                        coef)\\nplt.tick_params(axis=\\'x\\',\\nEnvironment                                      User                                                                                labelrotation=45, ha=\\'right\\', fontsize=12)\\n0   mpg                   space...]                                                  Can you visualize the regression coefficient? You may access them via                 [...same code omitted...]   [...omitted for\\ncar       name                   0                                                              model.coef_ and their names via model.feature_names_in_\\ndtype:          int64                                                                                                                                                                                          [3 rounds of self-debugging omitted for space]\\n---------------------------------------------------------------------------\\nValueError                                             Traceback                                                       (most recent                                                                    call                                                                         last)\\nCodeActAgent   /tmp/ipykernel_12/1372561217.py                                   in                                      ?()\\nCodeActAgent           X_train,                    X_test,                            y_train,                                     y_test                                            =                                              train_test_split(X,                                                                  y,        18                                                                     test_size=0.2                                                                                   [...]        Certainly!                                                                                   Here                                                                                                                            is a visualization                                                                                                                       of                                                                                                                   the regression coefficients [...]\\n19                                                                                                                                                                                                                     I                                                                                                                                                                      apologize                                                                                                                                                                                              for                                                                                                                                                                                the                                                                                                                                                                                          confusion.                                                                                                                                                                                                                                                          It seems                                                                                                                                                                                                                 that                                                                                                                                                                                                         the                                                                                                                                                                                                                         set_xticks()                                                                                                                                                                                                                             function                                                                                                                                                                                                                                                                                                is                                                                                                                                                                                                                         not                                                                                                                                                                                                                         a                                                                                             matplotlib.pyplot                                                                                      import                                                                                                               as                                                                                                                  plt        20           # Train                   a                     regression                                model\\n#                                                                                        Get regression                                                                                                       coefficients                                                                                                                                                                                     valid                                                                                                                                                                           function                                                                                                                                                                                            in                                                                                                                                                                                                 Matplotlib.                                                                                                                                                                                                         Instead,                                                                                                                                                       we                                                                                                                                                                                        can                                                                                                                                                                                                  use                                                                                                                                                                                                              the xticks()                                                                                                                                                                                                                              function                                                                                                                                                                                                                                             to                                                                                                                                                                                                                                                            set                                                                                                                                                                                                                                      the        21           model                 = LinearRegression()\\n=                                                                                             model.coef_   ---> 22           model.fit(X_train, y_train)        Self-Debug from                  coef\\n23                                                                                      # Get                                                                                            names                                                                                                  of input features                                                  x-ticks and rotate them by 45 degrees for better readability. Here is the updated\\n24           # Predict                     MPG                         for                             test                                  data                                                                                                                                                                           chart with                                                                                                                                                                               the                                                                                                                                                                                            x-ticks                                                                                                                                                                                                  rotated                                                                                                                                                                               by                                                                                                                                                                         45 degrees:                                                                                                    = model.feature_names_in_                        Automated                                   Feedback               feature_names                                                                                                                 Use                                                                                                                                     Matplotlib                                                                                                                                                Library for         bar        25 y_pred                  = model.predict(X_test)                                                                                      #                                                                                        Plot regression                                                                                                        coefficients                                                                                                                                                 [...same                                                                                                                                                          code                                                                                                                                                               omitted...]\\nData                                                                                                                                               Visualization                                                                                      plt.bar(feature_names,                                                                                                             coef)                                                                                                                                                 plt.xticks(feature_names,                                                                                                                                                                           feature_names,   ...       [omitted                for                    space]...\\nplt.xlabel(\\'Input                                                                                                        Feature\\')                                                                                                                                                            rotation=45,                                                                                                                                                                         ha=\\'right\\',                                                                                                                                                                                     fontsize=12)\\nplt.ylabel(\\'Regression                                                                                                             Coefficient\\')   ValueError:               could                     not                         convert                                 string                                        to float:                                                  \\'?\\'\\n[...same                                                                                                                                                          code                                                                                                                                                               omitted...]\\nplt.title(\\'Regression                                                                                                            Coefficients\\')\\n# Display the plot\\nCodeActAgent                                                            plt.show()                                         Environment\\nIt    seems            that                there                          is                     a data                            type                                   issue                                         in the                                                 dataset.                                           The                                                                           \\'?\\' character                                                                                     is present                                                                                                                               <Figure size 640x480 with 1 Axes>                                                  Environment\\nin     the         data,            which                         is                     causing                             the error                              when                                              trying                                                    to                                                    convert                                                           the data to                                                                 a float.     <Figure                                                                        size 640x480 with 1 Axes>\\nTo       fix          this,                 I                 will                remove                          the                          rows                                  containing                                            the \\'?\\'                                                       character.\\n# Remove rows containing \\'?\\'\\ndf = df.replace(\\'?\\', np.nan)\\ndf = df.dropna()\\nX = df.drop(columns=[\"mpg\", \"car name\"])\\ny = df[\"mpg\"]\\nX_train, X_test, y_train, y_test = train_test_split(\\nX, y, test_size=0.2, random_state=42\\n)\\nmodel              = LinearRegression()\\nmodel.fit(X_train,                           y_train)                                  CodeActAgent\\nThe                                                                                         regression                                                                                                            coefficients                                                                                                               are plotted                                                                                                                      as a bar                                                                                                                                          chart,                                                                                                                              with each                                                                                                                                              input feature on        y_pred               = model.predict(X_test)                                                                                                        User\\nprint(\"Mean                    squared                            error:                                   \", np.mean((y_test                                                      - y_pred) ** 2))                                                                                  the x-axis                                                                                and the                                                                                                 corresponding                                                                                                                               coefficient                                                                                                       on                                                                                                                              the y-axis                                                                                                                                                                                                                                [...]\\nprint(\"R^2                   score:                          \",                             r2_score(y_test,                                              y_pred))                                                                                                                                                                      [Stops                                                                                                                                                                                                     Interaction]\\nFigure 3: Example multi-turn interaction with Python packages using CodeActAgent (Mistral-7b). No in-context demonstra-\\ntions are provided to the model. Some messages are omitted for space. See https://chat.xwang.dev/r/Vqn108G\\nfor complete interaction.\\ndomains to generate trajectories:                             das tables to perform data operations (e.g., select, filter).\\nExamples of instructions can be found in §G.3.1.\\n• Information Seeking: We use a training subset of Hot-\\n• Robot Planning: We use ALFWorld (Shridhar et al.,\\npotQA (Yang et al., 2018) to generate information-seeking\\n2020), a text-only embodied environment simulator, to\\ntrajectories, where LLMs use the wikipedia search\\ngenerate trajectories that use robot-control APIs (repur-\\nAPI (provided as a Python function) to search for infor-\\nposed as Python function) to complete household tasks.\\nmation to answer questions.\\nFollowing MINT (Wang et al., 2023e), we provide an\\n• Software Package (Tool) Usage: We use the training\\nin-context demonstration to encourage the use of for-loop\\nset of code generation problems in APPS (Hendrycks\\nand if-statement code blocks to automate repetitive op-\\net al., 2021a) and math problems in MATH (Hendrycks\\nerations (e.g., searching for items by visiting different\\net al., 2021b). The code generation tasks already involve\\nlocations).\\nimporting packages and/or creating new tools by defining\\na new Python function. For MATH, we provide an in-   Data Down-sampling. We down-sample each dataset by\\ncontext demonstration of importing Python packages (e.g.,    keeping only the most challenging instances, aiming to make\\nsympy for symbolic math) for problem-solving.             trajectory generation more efficient and cost-effective. Fur-\\n• External Memory: We repurpose the training subset of    thermore, it also helps remove simple instances that existing\\nWikiTableQuestion (Pasupat & Liang, 2015) and tweak   LLMs can already solve. The statistics of the filtered dataset\\nit into two variants of tabular reasoning tasks that require    can be found in Tab. A.9. Please refer to §G.1 for details\\naccessing external memory: (1) SQL-based, requiring the    about the down-sample process.\\nLLM to interact with an SQL database through sqlite3\\nRepurpose Data for Multi-turn Interaction.  Some\\npackage to answer the question via SQL execution; (2)\\ndatasets (APPS, MATH, WikiTableQuestions) are initially\\nPandas-based, requiring the model to interact with pan-\\nsingle-turn problems that expect one solution per instruc-\\n6', 'page': 6}, {'page_content': 'Executable Code Actions Elicit Better LLM Agents\\nTable 4: Statistics of our training mixture and comparison with prior work. Please refer to §3.1 for details about CodeActIn-\\nstruct and general conversation data. Token statistics are computed using Llama-2 tokenizer.\\nData Mixture                      Data Type                              Data Name  # of Data Instances  # of Total Tokens   Avg. Tokens Per Instance\\n-                    FireAct (Chen et al., 2023a)                  2, 063           542, 176                    262.81\\nPrior Work\\n-                AgentInstruct (Zeng et al., 2023)                  1, 866           2, 517, 785                   1349.30\\nInformation Seeking               HotpotQA (Yang et al., 2018)                  1, 664           2, 472, 227                   1485.71\\nSoftware Packages (Tool)     MATH (Math, (Hendrycks et al., 2021b))                  1, 732           1, 719, 467                    992.76\\nSoftware Packages (Tool)       APPS (Code, (Hendrycks et al., 2021a))                647           1, 235, 472                   1909.54\\nCodeActInstruct (Ours)\\nExternal Memory     WikiTableQuestion (Pasupat & Liang, 2015)                  1, 065           1, 316, 246                   1235.91\\nRobot Planning            ALFWorld (Shridhar et al., 2020)                  2, 031           3, 838, 269                   1889.84\\nTotal               7, 139      10, 581, 681               1482.24\\nSingle-Turn Reasoning    OpenOrca (Sub-sampled, (Lian et al., 2023))               50, 000        14, 034, 152                    280.68\\nMulti-Turn Conversations  ShareGPT (Sub-sampled, (Anonymous, 2023))               10, 000        17, 933, 861                   1793.39\\nGeneral Conversation    Multi-Turn Conversations         ShareGPT (GPT-4, (OpenChat, 2023))                  4, 583        18, 195, 878                   3970.30\\nMulti-turn Reasoning                    CapyBara (LDJnr, 2023)                  4, 647           4, 982, 435                   1072.18\\nTotal             69, 230      55, 146, 326                 796.57\\ntion, whereas, in a realistic agent use case, we often require    pared with prior work AgentInstruct (Zeng et al., 2023) and\\nmulti-turn interaction to complete each task (Fig. 1 top).    FireAct (Chen et al., 2023a) that mainly focus using text\\nFollowing MINT (Wang et al., 2023e), we repurpose single-    as action, CodeActInstruct results in models that are more\\nturn problems into multi-turn ones by allowing LLM to     practical in real-world implementation, as such models us-\\ninteract with the environment for multiple turns before it    ing CodeAct can directly interact with Python interpreters\\ndecides to submit one solution for evaluation. Specifically    and open-source toolkits (Fig. 3), reducing the development\\nfor code generation problems, we provide an in-context ex-     effort for action parsing and tool creations. CodeActInstruct\\nample to guide LLMs to test their solution on provided test     is systematically constructed following the general agent\\ncases before they submit the solution. Metrics from the orig-   framework (Fig. 2). It covers diverse domains (e.g., com-\\ninal data will evaluate the submitted solution to determine    pared to FireAct that only considers QA-task and search\\nits correctness. We include examples in §G.3.                API), contains quality data (e.g., promotes agent’s capability\\nof self-debug) and of larger size (3.8x / 3.5x more data trajec-\\nTrajectory Generation. We use MINT’s evaluation frame-\\ntories and 5x / 19x more tokens compared to AgentInstruct\\nwork (Wang et al., 2023e) to generate interaction trajectories\\n/ FireAct respectively in Tab. 4). As we empirically show\\nfor the aforementioned datasets and determine the correct-\\nin Tab. 5, the resulting model (same backbone) of Code-\\nness of each trajectory. We run gpt-3.5-turbo-0613 from\\nActInstruct achieves 24% and 119% relative improvement\\nOpenAI, claude-1-instant and claude-2 from Anthropic on\\ncompared to AgentInstruct and FireAct.\\ndown-sampled data, except code generation, which we use a\\nlonger-context version of GPT-3.5 (gpt-3.5-turbo-0613-16k)    CodeActInstruct Can Be Used With Existing Agent-\\ndue to the long-context requirement of the self-debugging    User Conversation Data.  We use a sub-sampled set\\nprocess. On a subset of problems that none of these models    of OpenOrca (Lian et al., 2023) that focuses on single-turn\\ncan solve, we use gpt-4-0613 to generate trajectories.          chain-of-thought (CoT) reasoning, ShareGPT (Anonymous,\\n2023; OpenChat, 2023) from two sources that contain multi-\\nEnhancing Agent’s Capabilities of Improving from Inter-\\nturn conversations between human and LLM, and CapyBara\\naction. We select a high-quality subset of all the generated\\n(LDJnr, 2023) that focuses on reasoning in multi-turn con-\\ntrajectories from CodeActInstruct to promote the agent’s\\nversations.  Statistics and down-sampling details can be\\nability to improve the next action based on prior observa-\\nfound in Tab. 4 and §C.\\ntions (e.g., self-debugging from code execution error mes-\\nsage, a planning capability in Fig. 2). To achieve this, we\\n3.2. CodeActAgentselectively preserve those trajectories wherein the model\\ninitially encounters errors but rectifies these inaccuracies in   We fine-tune Llama-2 7B (Touvron et al., 2023) and Mistral\\nlater interactions. For these instances, the LLM typically   7B (Jiang et al., 2023) on a mixture of CodeActInstruct and\\nengages in self-reflection following the initial error, thereby    general conversations (Tab. 4) to obtain CodeActAgent.\\nproactively enhancing its future actions. Other filtering de-\\nTraining Setup. We perform full-parameter supervised fine-tails are discussed in §G.2. On all trajectories generated,\\ntuning with a sequence length of 4,096 tokens for Llama-2we keep 411 trajectories from gpt-4-0613 and 6728 trajecto-\\nand 16,384 for Mistral. Please refer to §D for more details.ries from gpt-3.5 and claude. The statistics of the resulting\\ndataset CodeActInstruct are shown in Tab. 4.                Evaluation Setup. We use MINT (Wang et al., 2023e)\\nto evaluate LLMs with CodeAct on a diverse range ofComparing CodeActInstruct with Prior Work. Com-\\nagent tasks. CodeActAgent has some training domains\\n7', 'page': 7}, {'page_content': 'Executable Code Actions Elicit Better LLM Agents\\nTable 5: Evaluation results for CodeActAgent. The best results among all open-source LLMs are bolded, and the second-best\\nresults are underlined. ID and OD stand for in-domain and out-of-domain evaluation correspondingly. Overall averaged\\nperformance normalizes the MT-Bench score to be consistent with other tasks and excludes in-domain tasks for fair\\ncomparison.\\nAgent Tasks                                             Generic Tasks                    Overall\\nCode as Action                    Text as Action (OD)                     (OD)                      Average\\nModel                        Size  MINT (ID)  MINT (OD)  M3ToolEval (OD)     Miniwob++   SciWorld   MMLU  HumanEval  GSM8K  MTBench\\nOpen-source LLMs (LLaMA-2-based)\\nLlama2 Base             7B              -∗              -∗                     -∗                 -∗           -∗         45.3         12.8      14.6            -∗              -∗\\nLlama2 Chat              7B           3.2          11.0                 0.0              0.0         5.9        48.0         13.9      27.7         6.3         21.1\\nFireAct (Chen et al., 2023a)   7B           0.0           0.3                 0.0              0.0         6.8        44.1           3.5      12.4         4.5         14.0\\nAgentLM (Zeng et al., 2023)   7B           8.7           6.1                 0.0            28.9       13.7        48.7         15.4      24.6         6.1         24.8\\nCodeActAgent (LLaMA-2)    7B          51.3          20.4                 0.0            25.5      17.6        50.6         18.1      38.3         7.5         30.7\\nOpen-source LLMs (Mistral-based)\\nMistral Base              7B              -∗              -∗                     -∗                 -∗           -∗       60.1         30.5      52.1            -∗              -∗\\nMistral Instruct            7B          18.8           9.7                 0.0              0.5         4.0        53.8         29.3      43.3         6.4         25.6\\nCodeActAgent (Mistral)      7B        57.4        32.4             12.2          46.2       15.9        59.1        34.7     58.0        8.2        42.5\\nClosed-source LLMs\\ngpt-3.5-turbo-0613                  -          33.9          38.2               51.2            66.7       21.2        70.0         48.1      57.1         7.9         54.0\\ngpt-4-0613                           -          68.6          70.2               67.1            69.4       36.4        86.4         67.0      87.1         9.0         71.7\\n* Some results are only available with instruction-tuned models.\\noverlapping with MINT’s evaluation (i.e., MINT includes    Ablation Study. Tab. A.8 presents ablation experiments to\\nALFWorld and MATH), hence we report separate numbers    determine the importance of CodeActInstruct and general\\nfor MINT’s in- and out-of-domain performance. Unless    conversations. Both CodeActInstruct and general conversa-\\notherwise specified, we measure MINT tasks’ success rates     tions contribute to agent tasks, while general conversations\\nwith interaction turn k = 5. We also evaluate out-of-domain    are essential to maintain performance on general tasks.\\nagent tasks using text actions from MiniWob++ (computer\\ntasks, (Kim et al., 2023)) and ScienceWorld (text-based                                                        4. Related Work\\nsimulator for elementary science curriculum, (Wang et al.,\\n2022a)) to test whether CodeActAgent can generalize to     4.1. Action Module in LLM Agents\\ndifferent action formats.  Finally, we include a suite of\\nAs detailed in (Wang et al., 2023b), LLM-based autonomous\\ngeneral LLM evaluation tasks to assess general capabil-\\nagents are typically structured around four components: cus-\\nity: MMLU (Hendrycks et al., 2020) for knowledge-based\\ntomized profiles (Park et al., 2023; Qian et al., 2023), long-\\nQA, HumanEval (Chen et al., 2021) for single-turn code-\\nterm memory capabilities (Zhu et al., 2023; Fischer, 2023),\\ngeneration, GSM8K (Cobbe et al., 2021) for single-turn\\nreasoning and planning algorithms (Wei et al., 2022; Chen\\ntool-free math reasoning, and MTBench (Zheng et al., 2023)\\net al., 2023d), and, most crucially, action modules. The\\nfor instruction-following.\\naction modules are key to facilitating LLM agents to effec-\\nCodeActAgent Excels in CodeAct Task. As shown in     tively interact with external entities, including humans (Lee\\nTab. 5, CodeActAgent (both variants) perform better than     et al., 2022) and tools (Qin et al., 2023a) in the environ-\\nall evaluated open-source LLMs on both the in- and out-of-   ment (Wang et al., 2023e; Yang et al., 2024a). In this study,\\ndomain subsets of MINT. On M3ToolEval, we find CodeAc-   we address the critical problem of standardizing the action\\ntAgent (Mistral) outperforms open-source LLMs of similar    space for LLM agents. We further discuss the difference\\nsize (7B and 13B) and even reaches similar performance to    between CodeAct and the line of work that uses code gen-\\nthose 70B models (Tab. 3). Surprisingly, no improvement     eration for problem-solving in §A. We notice a concurrent\\nis observed for the Llama-2 variant. We discuss potential    study TaskWeaver (Qiao et al., 2023) similarly endorses the\\nreasons in §H.                                            use of code. We discuss the principal distinctions in §B.\\nCodeActAgent Generalizes to Text Action.  When\\n4.2. Improving LLM Agentsevaluated on out-of-domain text actions, CodeActAgent\\n(LLaMA2, 7B), which has never been optimized for text   Two primary methods for enhancing LLM agents are prompt\\naction, achieves comparable performance to AgentLM-7B    engineering and instruction tuning, as surveyed by (Wang\\n(Zeng et al., 2023) which has explicit tuning for text actions.    et al., 2023b). For prompt engineering (Liu et al., 2023a),\\nnumerous strategies have been introduced to improve theCodeActAgent Maintains or Improves the Performance\\nchain-of-thought reasoning (Wei et al., 2022), includingon General LLM Tasks. In Tab. 5, we find that CodeActA-\\nself-consistency-based reasoning (Wang et al., 2022b; Chengent (both variants) performs better on generic LLM tasks\\net al., 2023d) and tree-based approaches (Yao et al., 2023a).we tested, except for a slight degradation on MMLU for\\nMoreover, LLMs can be strategically prompted to reflect onCodeActAgent (Mistral, 7B).\\n8', 'page': 8}, {'page_content': 'Executable Code Actions Elicit Better LLM Agents\\nprevious plans (Yao et al., 2023b; Wang et al., 2023f; Zhang     this section, we discuss potential societal consequences,\\net al., 2023), enabling them to refine initial actions through     limitations, and future work related to our work and its goal.\\ntrial and error. Contrast to prompt engineering, instruction\\nCodeActAgent is an initial prototype of an autonomous\\ntuning intrinsically enhances LLMs (Chung et al., 2022),\\nagent and still has several practical limitations. For example,\\nparticularly in their agent capabilities (Zeng et al., 2023;\\nit may suffer from hallucination commonly seen in LLMs\\nChen et al., 2023a). For effective training, human anno-\\n(e.g., imagine the content of a variable without actually print-\\ntators can curate expert demonstrations for specific agent\\ning it out), suggesting the need for subsequent alignment\\ntasks, such as web browsing (Yao et al., 2022a; Nakano\\n(Ouyang et al., 2022) for further improvements.\\net al., 2021). To minimize human annotation efforts, prior\\nwork creates synthetic datasets using stronger LLMs to dis-    Despite being a prototype, CodeActAgent has already\\ntill agent capabilities into local models, focusing on tool    demonstrated limited self-improving capability (e.g., self-\\nusage (Qin et al., 2023b), interaction (Chen et al., 2023c),   debug error messages to improve its action) and the ability\\nand social skills (Liu et al., 2023b). CodeActInstruct aligns     to interact with environments. Future work may build upon\\nwith the latter approach and creates datasets using stronger    CodeActAgent to develop better agents by having them\\nLLMs.                                                 perform extensive interactions within a given environment\\nand iteratively bootstrap their self-improving capability to\\n5. Conclusions                                              learn to improve from past mistakes. More powerful agents,\\nas results of such algorithms, are potentially beneficial for\\nThis work introduces CodeAct that employs executable    solving a wide range of real-world problems (e.g., theo-\\nPython code for the LLM agent’s action, which is advanta-   rem proving, drug discovery). As extensively discussed in\\ngeous over using text or JSON action, especially in complex    (Eloundou et al., 2023), a fully autonomous agent may trans-\\nscenarios. We collect CodeAct-focused multi-turn interac-   form the current landscape of the labor market and impact\\ntion trajectories CodeActInstruct for instruction tuning, and    the jobs of existing workers.\\ntrain CodeActAgent that is specially designed for seamless\\nFurthermore, since CodeAct directly grants access for the\\nintegration with Python and can execute sophisticated tasks\\nagent to freely execute code in a sandbox environment, in\\n(e.g., model training) leveraging existing Python packages\\nthe worst scenario (e.g., in Sci-Fi movies), such an agent\\nand autonomously rectifying errors through self-debugging.\\nmay potentially break free of the sandbox restriction and\\ncause harm to the world through cyber-attack, highlighting\\nAcknowledgement                                       the need for future work to design better safety mechanism\\nto safeguard autonomous agents (Tang et al., 2024).\\nWe thank the anonymous reviewers for their suggestions\\nand comments. This research is based upon work supported\\nby U.S. DARPA ECOLE Program No. HR00112390060   References\\nand U.S. DARPA ITM Program No. FA8650-23-C-7316                                                   Ahn, M., Brohan, A., Brown, N., Chebotar, Y., Cortes, O.,\\nand KAIROS Program No. FA8750-19-2-1004. The views                                                            David, B., Finn, C., Fu, C., Gopalakrishnan, K., Hausman,\\nand conclusions contained herein are those of the authors                                                               K., Herzog, A., Ho, D., Hsu, J., Ibarz, J., Ichter, B.,\\nand should not be interpreted as necessarily representing the                                                                  Irpan, A., Jang, E., Ruano, R. J., Jeffrey, K., Jesmonth,\\nofficial policies, either expressed or implied, of DARPA, or                                                                            S., Joshi, N., Julian, R., Kalashnikov, D., Kuang, Y., Lee,\\nthe U.S. Government. The U.S. Government is authorized to                                                             K.-H., Levine, S., Lu, Y., Luu, L., Parada, C., Pastor,\\nreproduce and distribute reprints for governmental purposes                                                                                  P., Quiambao, J., Rao, K., Rettinghouse, J., Reyes, D.,\\nnotwithstanding any copyright annotation therein.  This                                                            Sermanet, P., Sievers, N., Tan, C., Toshev, A., Vanhoucke,\\nwork used the Delta system at the National Center for Super-                                                                       V., Xia, F., Xiao, T., Xu, P., Xu, S., Yan, M., and Zeng,\\ncomputing Applications through allocation CIS230256 from                                                     A. Do as i can and not as i say: Grounding language in\\nthe Advanced Cyberinfrastructure Coordination Ecosystem:                                                                  robotic affordances. In arXiv preprint arXiv:2204.01691,\\nServices & Support (ACCESS, Boerner et al. 2023) program,                                                           2022.\\nwhich is supported by National Science Foundation grants\\n#2138259, #2138286, #2138307, #2137603, and #2138296.\\nAnonymous.   Sharegpt dataset.  https://hf.co/\\nImpact Statement                             datasets/anon8231489123/ShareGPT_\\nVicuna_unfiltered/blob/main/ShareGPT_\\nThis paper presents work whose goal is to advance LLM-                                            V3_unfiltered_cleaned_split_no_\\nbased autonomous agents that can communicate with hu-                                              imsorry.json,  2023.   A  dataset  containing\\nmans through natural language and assist human users by                                                                multi-turn conversations between human and LLM\\nperforming tasks in environments on behalf of humans. In                                                                        assistant.\\n9', 'page': 9}, {'page_content': 'Executable Code Actions Elicit Better LLM Agents\\nBoerner, T. J., Deems, S., Furlani, T. R., Knuth, S. L.,    Fischer, K. A. Reflective linguistic programming (rlp): A\\nand Towns, J. Access: Advancing innovation: Nsf’s ad-      stepping stone in socially-aware agi (socialagi). arXiv\\nvanced cyberinfrastructure coordination ecosystem: Ser-       preprint arXiv:2305.12647, 2023.\\nvices & support. In Practice and Experience in Advanced\\nGao, L., Madaan, A., Zhou, S., Alon, U., Liu, P., Yang,  Research Computing, pp. 173–176. 2023.\\nY., Callan, J., and Neubig, G. Pal: Program-aided lan-\\nBran, A. M., Cox, S., White, A. D., and Schwaller, P. Chem-     guage models. In International Conference on Machine\\ncrow: Augmenting large-language models with chemistry      Learning, pp. 10764–10799. PMLR, 2023.\\ntools. arXiv preprint arXiv:2304.05376, 2023.\\nHendrycks, D., Burns, C., Basart, S., Zou, A., Mazeika, M.,\\nSong, D., and Steinhardt, J. Measuring massive multitask\\nCano, A. H., Pagliardini, M., K¨opf, A., Matoba, K., Mo-\\nlanguage understanding. In International Conference on\\nhtashami, A., Wang, X., Fan, O. S., Marmet, A., Bayazit,\\nLearning Representations, 2020.\\nD., Krawczuk, I., Chen, Z., Salvi, F., Bosselut, A., and\\nJaggi, M.  epfllm megatron-llm, 2023. URL https:   Hendrycks, D., Basart, S., Kadavath, S., Mazeika, M., Arora,\\n//github.com/epfLLM/Megatron-LLM.              A., Guo, E., Burns, C., Puranik, S., He, H., Song, D.,\\net al.  Measuring coding challenge competence with\\nChase, H. LangChain, October 2022. URL https://                                                              apps. In Thirty-fifth Conference on Neural Information\\ngithub.com/langchain-ai/langchain.                                                             Processing Systems Datasets and Benchmarks Track\\n(Round 2), 2021a.\\nChen, B., Shu, C., Shareghi, E., Collier, N., Narasimhan, K.,\\nand Yao, S. Fireact: Toward language agent fine-tuning.   Hendrycks,  D.,  Burns,  C., Kadavath,  S.,  Arora,  A.,\\narXiv preprint arXiv:2310.05915, 2023a.                      Basart,  S.,  Tang,  E.,  Song,  D.,  and  Steinhardt,\\nJ.   Measuring mathematical problem solving with\\nChen, M., Tworek, J., Jun, H., Yuan, Q., Pinto, H. P. d. O.,                                                               the math  dataset.    In  Thirty-fifth Conference on\\nKaplan, J., Edwards, H., Burda, Y., Joseph, N., Brockman,                                                          Neural Information Processing Systems Datasets and\\nG., et al. Evaluating large language models trained on                                                     Benchmarks Track (Round 2), 2021b.\\ncode. arXiv preprint arXiv:2107.03374, 2021.\\nHong, S., Zheng, X., Chen, J., Cheng, Y., Wang, J., Zhang,\\nChen, X., Lin, M., Sch¨arli, N., and Zhou, D.  Teaching       C., Wang, Z., Yau, S. K. S., Lin, Z., Zhou, L., et al.\\nlarge language models to self-debug.  arXiv preprint      Metagpt: Meta programming for multi-agent collabora-\\narXiv:2304.05128, 2023b.                                        tive framework. arXiv preprint arXiv:2308.00352, 2023.\\nChen, Y., Sikka, K., Cogswell, M., Ji, H., and Divakaran, A.   Hong, S., Lin, Y., Liu, B., Liu, B., Wu, B., Li, D., Chen,\\nDress: Instructing large vision-language models to align         J., Zhang, J., Wang, J., Zhang, L., Zhang, L., Yang, M.,\\nand interact with humans via natural language feedback.      Zhuge, M., Guo, T., Zhou, T., Tao, W., Wang, W., Tang,\\narXiv preprint arXiv:2311.10081, 2023c.                      X., Lu, X., Zheng, X., Liang, X., Fei, Y., Cheng, Y., Xu,\\nZ., and Wu, C. Data interpreter: An llm agent for data\\nChen,  Y.,  Sikka,  K., Cogswell, M.,  Ji,  H., and Di-       science, 2024.\\nvakaran, A. Measuring and improving chain-of-thought\\nHuang, W., Wang, C., Zhang, R., Li, Y., Wu, J., and Fei-Fei,  reasoning in vision-language models.  arXiv preprint\\nL. Voxposer: Composable 3d value maps for robotic  arXiv:2309.04461, 2023d.\\nmanipulation with language models.  arXiv preprint\\nChung, H. W., Hou, L., Longpre, S., Zoph, B., Tay, Y.,      arXiv:2307.05973, 2023.\\nFedus, W., Li, Y., Wang, X., Dehghani, M., Brahma,\\nJiang, A. Q., Sablayrolles, A., Mensch, A., Bamford, C.,\\nS., et al. Scaling instruction-finetuned language models.\\nChaplot, D. S., Casas, D. d. l., Bressand, F., Lengyel, G.,\\narXiv preprint arXiv:2210.11416, 2022.\\nLample, G., Saulnier, L., et al. Mistral 7b. arXiv preprint\\narXiv:2310.06825, 2023.\\nCobbe, K., Kosaraju, V., Bavarian, M., Chen, M., Jun, H.,\\nKaiser, L., Plappert, M., Tworek, J., Hilton, J., Nakano,   Kim, G., Baldi, P., and McAleer, S. Language models can\\nR., et al. Training verifiers to solve math word problems.      solve computer tasks. arXiv preprint arXiv:2303.17491,\\narXiv preprint arXiv:2110.14168, 2021.                     2023.\\nEloundou, T., Manning, S., Mishkin,  P., and Rock, D.   LDJnr.     Capybara  dataset.    https://hf.co/\\nGpts are gpts: An early look at the labor market im-    datasets/LDJnr/Verified-Camel,  https:\\npact potential of large language models. arXiv preprint     //hf.co/datasets/LDJnr/Pure-Dove,\\narXiv:2303.10130, 2023.                         https://hf.co/datasets/LDJnr/\\n10', 'page': 10}, {'page_content': 'Executable Code Actions Elicit Better LLM Agents\\nLessWrong-Amplify-Instruct, 2023. A dataset      with human feedback. Advances in Neural Information\\nfocusing on reasoning in multi-turn conversations.            Processing Systems, 35:27730–27744, 2022.\\nLee, M., Liang, P., and Yang, Q.  Coauthor: Designing    Park, J. S., O’Brien, J., Cai, C. J., Morris, M. R., Liang, P.,\\na human-ai collaborative writing dataset for exploring      and Bernstein, M. S. Generative agents: Interactive sim-\\nlanguage model capabilities. In Proceedings of the 2022       ulacra of human behavior.  In Proceedings of the 36th\\nCHI conference on human factors in computing systems,     Annual ACM Symposium on User Interface Software\\npp. 1–19, 2022.                                        and Technology, pp. 1–22, 2023.\\nLi, M., Song, F., Yu, B., Yu, H., Li, Z., Huang, F., and Li, Y.    Pasupat, P. and Liang, P. Compositional semantic parsing\\nApi-bank: A benchmark for tool-augmented llms, 2023.      on semi-structured tables.  In Proceedings of the 53rd\\nAnnual Meeting of the Association for Computational\\nLian, W., Goodson, B., Pentland, E., Cook, A., Vong, C.,\\nLinguistics and the 7th International Joint Conference on\\nand ”Teknium”.  Openorca: An open dataset of gpt\\nNatural Language Processing (Volume 1: Long Papers),\\naugmented flan reasoning traces. https://https:\\npp. 1470–1480, 2015.\\n//huggingface.co/Open-Orca/OpenOrca,\\n2023.                                                               Patil,  S.  G.,  Zhang,   T.,  Wang,  X.,  and  Gonza-\\nlez,  J. E.    Gorilla:  Large language model con-\\nLiang, J., Huang, W., Xia, F., Xu, P., Hausman, K., Ichter,\\nnected with massive apis.   ArXiv, abs/2305.15334,\\nB., Florence, P., and Zeng, A. Code as policies: Language\\n2023.  URL https://api.semanticscholar.\\nmodel programs for embodied control. In arXiv preprint\\norg/CorpusID:258865184.\\narXiv:2209.07753, 2022.\\nQian, C., Cong, X., Yang, C., Chen, W., Su, Y., Xu, J.,Liu, P., Yuan, W., Fu, J., Jiang, Z., Hayashi, H., and Neubig,\\nLiu, Z., and Sun, M. Communicative agents for software  G. Pre-train, prompt, and predict: A systematic survey of\\ndevelopment. arXiv preprint arXiv:2307.07924, 2023.  prompting methods in natural language processing. ACM\\nComputing Surveys, 55(9):1–35, 2023a.                                                         Qiao, B., Li, L., Zhang, X., He, S., Kang, Y., Zhang,\\nC., Yang,  F., Dong, H., Zhang,  J., Wang, L., et al.Liu, R., Yang, R., Jia, C., Zhang, G., Zhou, D., Dai, A. M.,\\nTaskweaver: A code-first agent framework.   arXiv  Yang, D., and Vosoughi, S. Training socially aligned lan-\\npreprint arXiv:2311.17541, 2023.  guage models in simulated human society. arXiv preprint\\narXiv:2305.16960, 2023b.                                                          Qin, Y., Hu, S., Lin, Y., Chen, W., Ding, N., Cui, G., Zeng,\\nZ., Huang, Y., Xiao, C., Han, C., et al. Tool learning withMa, Y. J., Liang, W., Wang, G., Huang, D.-A., Bastani, O.,\\nfoundation models.  arXiv preprint arXiv:2304.08354,  Jayaraman, D., Zhu, Y., Fan, L., and Anandkumar, A.\\n2023a.  Eureka: Human-level reward design via coding large lan-\\nguage models. arXiv preprint arXiv:2310.12931, 2023.\\nQin, Y., Liang, S., Ye, Y., Zhu, K., Yan, L., Lu, Y.-T., Lin,\\nMialon, G., Dess`ı, R., Lomeli, M., Nalmpantis, C., Pa-       Y., Cong, X., Tang, X., Qian, B., Zhao, S., Tian, R.,\\nsunuru, R., Raileanu, R., Rozi`ere, B., Schick, T., Dwivedi-      Xie, R., Zhou, J., Gerstein, M. H., Li, D., Liu, Z., and\\nYu, J., Celikyilmaz, A., et al. Augmented language mod-      Sun, M. Toolllm: Facilitating large language models to\\nels: a survey. arXiv preprint arXiv:2302.07842, 2023.        master 16000+ real-world apis. ArXiv, abs/2307.16789,\\n2023b. URL https://api.semanticscholar.\\nNakano, R., Hilton, J., Balaji, S., Wu, J., Ouyang, L., Kim,     org/CorpusID:260334759.\\nC., Hesse, C., Jain, S., Kosaraju, V., Saunders, W., et al.\\nWebgpt: Browser-assisted question-answering with hu-    Schick, T., Dwivedi-Yu, J., Dess`ı, R., Raileanu, R., Lomeli,\\nman feedback. arXiv preprint arXiv:2112.09332, 2021.       M., Zettlemoyer, L., Cancedda, N., and Scialom, T. Tool-\\nformer: Language models can teach themselves to use\\nOpenChat.    Sharegpt  dataset.   https://hf.co/       tools. arXiv preprint arXiv:2302.04761, 2023.\\ndatasets/openchat/openchat_sharegpt_\\nv3/blob/main/sharegpt_gpt4.json, 2023. A    Shen, Y., Song, K., Tan, X., Li, D., Lu, W., and Zhuang, Y.\\ndataset containing multi-turn conversations between      Hugginggpt: Solving ai tasks with chatgpt and its friends\\nhuman and LLM assistants. It is filtered to contain data       in huggingface. arXiv preprint arXiv:2303.17580, 2023.\\nonly from GPT-4.\\nShridhar, M., Yuan, X., Cote, M.-A., Bisk, Y., Trischler, A.,\\nOuyang, L., Wu, J., Jiang, X., Almeida, D., Wainwright, C.,      and Hausknecht, M. Alfworld: Aligning text and embod-\\nMishkin, P., Zhang, C., Agarwal, S., Slama, K., Ray, A.,       ied environments for interactive learning. In International\\net al. Training language models to follow instructions      Conference on Learning Representations, 2020.\\n11', 'page': 11}, {'page_content': 'Executable Code Actions Elicit Better LLM Agents\\nSingh, I., Blukis, V., Mousavian, A., Goyal, A., Xu, D.,      Computational Linguistics (Volume 1: Long Papers), pp.\\nTremblay,  J., Fox, D., Thomason,  J., and Garg, A.     3640–3663, Toronto, Canada, July 2023c. Association\\nProgprompt: Generating situated robot task plans us-       for Computational Linguistics. doi: 10.18653/v1/2023.\\ning large language models. In 2023 IEEE International       acl-long.202. URL https://aclanthology.org/\\nConference on Robotics and Automation (ICRA), pp.     2023.acl-long.202.\\n11523–11530, 2023.  doi: 10.1109/ICRA48891.2023.\\nWang, X., Peng, H., Jabbarvand, R., and Ji, H.   Leti:  10161317.\\nLearning to generate from textual interactions. ArXiv,\\nSur´ıs, D., Menon, S., and Vondrick, C. Vipergpt: Visual in-      abs/2305.10314, 2023d.\\nference via python execution for reasoning. Proceedings\\nWang, X., Wang, Z., Liu, J., Chen, Y., Yuan, L., Peng, H.,\\nof IEEE International Conference on Computer Vision\\nand Ji, H. Mint: Evaluating llms in multi-turn interac-\\n(ICCV), 2023.\\ntion with tools and language feedback. arXiv preprint\\nTang, X., Jin, Q., Zhu, K., Yuan, T., Zhang, Y., Zhou, W.,      arXiv:2309.10691, 2023e.\\nQu, M., Zhao, Y., Tang, J., Zhang, Z., et al. Prioritizing\\nWang, Z., Cai, S., Liu, A., Ma, X., and Liang, Y. Describe,\\nsafeguarding over autonomy: Risks of llm agents for\\nexplain, plan and select: Interactive planning with large\\nscience. arXiv preprint arXiv:2402.04247, 2024.\\nlanguage models enables open-world multi-task agents.\\nTIOBE Index.  Tiobe index.  https://www.tiobe.     arXiv preprint arXiv:2302.01560, 2023f.\\ncom/tiobe-index/, Accessed at Jan 23rd, 2024,\\nWei, J., Wang, X., Schuurmans, D., Bosma, M., Xia, F.,\\n2024. The TIOBE Programming Community index is\\nChi, E., Le, Q. V., Zhou, D., et al.  Chain-of-thought\\nan indicator of the popularity of programming languages.\\nprompting elicits reasoning in large language models.\\nThe index is updated once a month. The ratings are based\\nAdvances in Neural Information Processing Systems, 35:\\non the number of skilled engineers world-wide, courses\\n24824–24837, 2022.\\nand third party vendors.\\nXu, Q., Hong, F., Li, B., Hu, C., Chen, Z., and Zhang, J.\\nTouvron, H., Martin, L., Stone, K., Albert, P., Almahairi, A.,                                           On the tool manipulation capability of open-source large\\nBabaei, Y., Bashlykov, N., Batra, S., Bhargava, P., Bhos-                                                          language models, 2023.\\nale, S., et al. Llama 2: Open foundation and fine-tuned\\nchat models. arXiv preprint arXiv:2307.09288, 2023.      Yang, J., Prabhakar, A., Narasimhan, K., and Yao, S. In-\\ntercode:  Standardizing and benchmarking interactive\\nWang, G., Xie, Y., Jiang, Y., Mandlekar, A., Xiao, C., Zhu,                                                         coding with execution feedback.  Advances in Neural\\nY., Fan, L., and Anandkumar, A.  Voyager: An open-                                                             Information Processing Systems, 36, 2024a.\\nended embodied agent with large language models. arXiv\\npreprint arXiv:2305.16291, 2023a.                      Yang, K., Liu, J., Wu, J., Yang, C., Fung, Y. R., Li, S.,\\nHuang, Z., Cao, X., Wang, X., Wang, Y., Ji, H., and Zhai,\\nWang, L., Ma, C., Feng, X., Zhang, Z., Yang, H., Zhang, J.,      C. If llm is the wizard, then code is the wand: A survey\\nChen, Z., Tang, J., Chen, X., Lin, Y., et al. A survey on      on how code empowers large language models to serve\\nlarge language model based autonomous agents. arXiv       as intelligent agents, 2024b.\\npreprint arXiv:2308.11432, 2023b.\\nYang, Z., Qi, P., Zhang, S., Bengio, Y., Cohen, W., Salakhut-\\nWang,  R.,  Jansen,  P.  A.,   Cˆot´e,  M.-A.,  and Am-      dinov, R., and Manning, C. D.  Hotpotqa: A dataset\\nmanabrolu,   P.     Scienceworld:    Is  your  agent       for diverse, explainable multi-hop question answering.\\nsmarter than a 5th grader?      In Conference on       In Proceedings of the 2018 Conference on Empirical\\nEmpirical Methods in Natural Language Processing,     Methods in Natural Language Processing, pp. 2369–\\n2022a. URL https://api.semanticscholar.     2380, 2018.\\norg/CorpusID:247451124.\\nYang, Z., Liu, A., Liu, Z., Liu, K., Xiong, F., Wang, Y.,\\nWang, X., Wei, J., Schuurmans, D., Le, Q., Chi, E., Narang,      Yang, Z., Hu, Q., Chen, X., Zhang, Z., Luo, F., Guo, Z.,\\nS., Chowdhery, A., and Zhou, D. Self-consistency im-       Li, P., and Liu, Y. Towards unified alignment between\\nproves chain of thought reasoning in language models.       agents, humans, and environment, 2024c.\\narXiv preprint arXiv:2203.11171, 2022b.\\nYao,  S.,  Chen,  H.,  Yang,   J.,  and Narasimhan,  K.\\nWang, X., Li, S., and Ji, H. Code4Struct: Code generation     Webshop:  Towards  scalable  real-world web  inter-\\nfor few-shot event structure prediction. In Rogers, A.,      action with grounded language agents.   Advances\\nBoyd-Graber, J., and Okazaki, N. (eds.), Proceedings       in Neural Information Processing Systems, 35:20744–\\nof the 61st Annual Meeting of the Association for      20757, 2022a.\\n12', 'page': 12}, {'page_content': 'Executable Code Actions Elicit Better LLM Agents\\nYao, S., Zhao, J., Yu, D., Du, N., Shafran, I., Narasimhan,\\nK. R., and Cao, Y. React: Synergizing reasoning and\\nacting in language models. In The Eleventh International\\nConference on Learning Representations, 2022b.\\nYao, S., Yu, D., Zhao, J., Shafran, I., Griffiths, T. L., Cao, Y.,\\nand Narasimhan, K. Tree of thoughts: Deliberate prob-\\nlem solving with large language models. arXiv preprint\\narXiv:2305.10601, 2023a.\\nYao, W., Heinecke, S., Niebles, J. C., Liu, Z., Feng, Y., Xue,\\nL., Murthy, R., Chen, Z., Zhang, J., Arpit, D., et al. Retro-\\nformer: Retrospective large language agents with policy\\ngradient optimization. arXiv preprint arXiv:2308.02151,\\n2023b.\\nYuan, L., Chen, Y., Wang, X., Fung, Y. R., Peng, H., and\\nJi, H. Craft: Customizing llms by creating and retriev-\\ning from specialized toolsets. ArXiv, abs/2309.17428,\\n2023.  URL https://api.semanticscholar.\\norg/CorpusID:263310662.\\nZeng, A., Liu, M., Lu, R., Wang, B., Liu, X., Dong, Y.,\\nand Tang, J. Agenttuning: Enabling generalized agent\\nabilities for llms, 2023.\\nZhang,  C.,  Liu,  L., Wang,  J., Wang,  C.,  Sun,  X.,\\nWang, H., and Cai, M.   Prefer:  Prompt ensemble\\nlearning via feedback-reflect-refine.   arXiv preprint\\narXiv:2308.12033, 2023.\\nZheng, L., Chiang, W.-L., Sheng, Y., Zhuang, S., Wu, Z.,\\nZhuang, Y., Lin, Z., Li, Z., Li, D., Xing, E., et al. Judging\\nllm-as-a-judge with mt-bench and chatbot arena. arXiv\\npreprint arXiv:2306.05685, 2023.\\nZheng, T., Zhang, G., Shen, T., Liu, X., Lin, B. Y., Fu,\\nJ., Chen, W., and Yue, X.  Opencodeinterpreter: Inte-\\ngrating code generation with execution and refinement.\\nhttps://arxiv.org/abs/2402.14658, 2024.\\nZhu, X., Chen, Y., Tian, H., Tao, C., Su, W., Yang, C.,\\nHuang, G., Li, B., Lu, L., Wang, X., et al. Ghost in the\\nminecraft: Generally capable agents for open-world envi-\\nroments via large language models with text-based knowl-\\nedge and memory.  arXiv preprint arXiv:2305.17144,\\n2023.\\n13', 'page': 13}, {'page_content': 'Executable Code Actions Elicit Better LLM Agents\\nTable A.6: Example of actions for re-purposed API-Bank (Li et al., 2023) and M3ToolEval.\\nFormat     Action\\nAddAgenda(content=\"Meeting with John\",\\nCodeAct\\ntime=\"2023-10-26 09:00:00\")\\n{\"action\":  \"AddAgenda\", \"content\":\\nJSON     \"Meeting with John\", \"time\":\\n\"2023-10-26 09:00:00\"}\\nAction:  AddAgenda, content:  Meeting\\nText\\nwith John, time:  2023-10-26 09:00:00\\nTable A.7: Comparison between M3ToolEval and existing tool-use evaluation benchmark.\\nBenchmark                         M3ToolEval            ToolBench        APIBench        API-Bank       ToolBench\\n(This work)         (Qin et al., 2023b)   (Patil et al., 2023)   (Li et al., 2023)  (Xu et al., 2023)\\nRequiring multi-turn interaction       \"         \"       %       %       %\\nMultiple tools              \"         \"       \"       \"       \"\\nEvaluation                        Answer Match      LLM Evaluator   AST Tree Match   API-Call Match      Test Case\\nNo dependency on external API∗      \"         %       %       \"       %\\nSupported API Action Format    CodeAct & JSON & Text      JSON         CodeAct        JSON       CodeAct\\n* Whether to rely on external API (e.g., RapidAPI, Google Sheet) hosted by a third party. The availability of such third-party APIs can greatly impact\\nevaluation results (e.g., low API-calling performance not because the model is bad but rather because the API required is not accessible).\\nTable A.8: Ablation study results. The best results are bolded, and the second-best results are underlined. ID and OD stand\\nfor in-domain and out-of-domain evaluation correspondingly. Overall averaged performance normalizes the MT-Bench\\nscore to be consistent with other tasks and excludes in-domain tasks for fair comparison.\\nAgent Tasks                                  Generic LLM Tasks                 Overall\\nCode as Action           Text as Action (OD)                     (OD)                      Average\\nModel                          Size  MINT (ID)  MINT (OD)     Miniwob++   SciWorld   MMLU  HumanEval  GSM8K  MTBench\\nCodeActAgent (Llama2-based)   7B        51.3        20.4            25.5      17.6       50.6         18.1     38.3        7.5        35.1\\nw/o CodeAct              7B          17.0          15.5          36.4       16.9        49.5         14.7      36.0         7.2         34.5\\nw/o general conversations      7B          29.2          15.9              0.0       17.1        46.4        19.7      20.6         4.1         22.9\\nCodeActAgent (Mistral-based)   7B        57.4        32.4            46.2       15.9        59.1        34.7      58.0         8.2        46.8\\nw/o CodeAct              7B          32.9          23.0          47.8      17.0       59.9         33.2     59.5        8.3         46.2\\nw/o general conversations      7B          50.5          13.9              0.0       11.0        52.4         27.9      26.8         2.6         22.6\\nA. Comparison with Work that Uses Code Generation for Problem-solving\\nIn this section, we discuss the fundamental differences between CodeAct and prior work that prompt LLM to generate\\ncode for problem-solving. Existing work have explored using code generation for task-solving in different domains, for\\nexample, Code4Struct (Wang et al., 2023c) for structured prediction, PaL (Gao et al., 2023) for math reasoning, Meta-GPT\\n(Hong et al., 2023) for multi-agent collaboration, code-as-policy (Liang et al., 2022) for robot control, ViperGPT (Sur´ıs\\net al., 2023) for visual question answering, Voyager (Wang et al., 2023a) for playing games, Data Interpreter (Hong et al.,\\n2024) for data science tasks, etc.\\nMost prior work generates code (i.e., a static sequence of actions) in a single-turn setting and cannot dynamically readjust\\naction on new observation: It is considered a failure when the model-generated code fails to solve a task on the first attempt.\\nThis setting overlooks the potential of environmental observation (e.g., code execution results) that might benefit future\\naction and overall decision (e.g., dynamically adjusting subsequent code after observing intermediate code execution results,\\nfixing erroneous code after seeing an error message). That is, the generated code is a static sequence of actions that cannot\\nbe dynamically re-adjusted on the fly by incorporating new observations. Such a single-turn setting makes it challenging to\\nscale to more challenging problems since even expert human programmers usually cannot write functionally correct code in\\n14', 'page': 14}, {'page_content': 'Executable Code Actions Elicit Better LLM Agents\\nthe first pass. On the other hand, CodeAct is a multi-turn interaction agent framework that allows dynamic adjustment\\nof prior actions or emitting new actions by design (§2.1, Fig. 2) and is compatible with any form of textual observation\\n(e.g., tool execution output, automated feedback) from the environment. Beyond being compatible with environmental\\nobservation, our instruction tuning dataset CodeActInstruct specifically collects data for multi-turn self-improving, offering\\na practical solution to enhance LLM’s multi-turn self-improving process.\\nIn addition, previous approaches require heavy prompt engineering and crafting of few-shot demonstrations to tailor LLMs to\\na particular domain or task (e.g., robot control (Liang et al., 2022)) since the backbone LLMs are not specially optimized for\\ndynamic planning and decision making. In contrast, in this work, we propose the CodeAct framework that uses executable\\nPython code to consolidate LLM agents’ actions into unified action space and collect CodeActInstruct on a diverse array of\\ntasks (e.g., information seeking, tabular reasoning, robot planning, etc) to make the trained model, CodeActAgent, easily\\nscale to diverse tasks and domains with minimal human efforts as shown in §3.2.\\nOne notable exception among prior work is Voyager (Wang et al., 2023a), which performs iterative prompting in a\\nconstrained action space of function definitions to fix code errors. Different from CodeAct, such setting disallows dynamic\\nre-adjustment of atomic actions on the fly: In CodeAct, for a particular task (e.g., craft stone sword in Minecraft), the\\nagent can first execute one line of code (any atomic action or composed functions, e.g., move forward, locate stone), and\\ndynamically produce different actions based on the observation of the first action. This is challenging for Voyager to achieve:\\nSimilar to code-as-policy (Liang et al., 2022), they generate action (a skill, e.g., craft stone sword) as a Python function\\ndefinition that outlines the entire plan for a task (e.g., multi-step code outlining how you should craft a stone sword and\\nhandles for different potential cases, which requires strong domain knowledge). This imposes significant constraints on the\\nagent’s action space and disallows dynamic re-adjustment of atomic actions on the fly: That is, the agent can only generate\\none complete function first (e.g., by imaging all possible cases that might happen when you try to locate stones), execute\\nthe entire function, observe the feedback, and update the entire function as action in the subsequent move. Besides the\\nconstrained ability to re-adjust action from environmental observation, they also rely on heavy prompting engineering (a\\ntypical drawback discussed above) to provide relevant information (e.g., current state, additional self-critics via prompting)\\nto generate revised code, whereas CodeAct is situated in a setting that requires no prompt engineering efforts: the context\\nwindow of LLM only contains its past actions and observations and does not require human efforts to filter for relevant\\ninformation.\\nSimilar to CodeAct, concurrent work OpenCodeInterpreter (Zheng et al., 2024), with a specific focus on competitive code\\ngeneration questions, collects code-debugging trajectories to improve an LLM’s iterative code debugging performance.\\nHowever, its applicability to general LLM agent tasks remains unknown.\\nB. Comparison with TaskWeaver\\nIn the landscape of unifying the action space of LLM agents, our work represents a leap over the previous initiative,\\nTaskWeaver (Qiao et al., 2023). While TaskWeaver deserves acknowledgment for initially integrating code into the action\\nspace of LLM agents, its exploration remains limited. This work, primarily characterized by its reliance on a limited set\\nof qualitative examples with close-sourced models as the backbones, fails to harness the full potential of this integration,\\nremaining merely conceptual demonstrations. Our work transcends mere conceptualization by conducting an extensive and\\nrigorous analysis, clearly quantifying the benefits of code action within LLM agents. Beyond this, we introduce a unique\\ninstruction-tuning dataset CodeActInstruct specifically designed to amplify the agent’s capabilities in executing code-based\\nactions and an open-source LLM agent CodeActAgent. These contributions not only extend the work of TaskWeaver but\\nalso pave the way for future explorations, offering valuable resources to the open-source community and redefining the\\npotential of LLM agents in practical applications.\\nC. General Data Down-sample\\n• ShareGPT (Anonymous, 2023): We remove all single-turn conversations, then perform random sub-sample to a\\ndesired final number.\\n• ShareGPT (GPT-4) (OpenChat, 2023): We do not perform sub-sampling on this dataset.\\n• OpenOrca (Lian et al., 2023): We select the CoT subset of OpenOrca, then perform a random sub-sample to a desired\\nfinal number.\\n15', 'page': 15}, {'page_content': 'Executable Code Actions Elicit Better LLM Agents\\n• CapyBara (LDJnr, 2023): We do not perform sub-sampling on this dataset.\\nD. CodeActAgent Training Details\\nAll SFT experiments are performed on one 4xA100 40GB SXM node using a fork of Megatron-LLM (Cano et al., 2023)\\nwith a training throughput of around 9k tokens per second. We use chatML format2 for all multi-turn data, and we only\\ncalculate and optimize for loss on the assistant response. We pack short instances into longer ones and apply flash attention\\nfor training efficiency.\\nWe train both LLaMA-2 and Mistral LLMs with Tensor Parallel of 4, the learning rate of 1e-5 with 50 warmup steps and\\ncosine decay (end learning rate of 1e-6). We train for five epochs with a batch size of 32. We use the 3rd epoch checkpoint\\nfor all our experiments.\\nE. Example Prompt for CodeAct\\nThis is an example (zero-shot) system prompt used in a deploy instance of CodeAct where we used chatML format.\\nThe users may optionally include tools descriptions similar to §F or including extra in-context examples similar to §G.3.\\n<|im_start|>system\\nA chat between a curious user and an artificial intelligence assistant. The assistant\\ngives helpful, detailed, and polite answers to the user’s questions.\\nThe assistant can interact with an interactive Python (Jupyter Notebook) environment and\\nreceive the corresponding output when needed. The code should be enclosed using \"<\\nexecute>\" tag, for example: <execute> print(\"Hello World!\") </execute>.\\nThe assistant should attempt fewer things at a time instead of putting too much code in\\none <execute> block. The assistant can install packages through PIP by <execute> !pip\\ninstall [package needed] </execute> and should always import packages and define\\nvariables before starting to use them.\\nThe assistant should stop <execute> and provide an answer when they have already obtained\\nthe answer from the execution result. Whenever possible, execute the code for the user\\nusing <execute> instead of providing it.\\nThe assistant’s response should be concise, but do express their thoughts.\\n<|im_end|>\\nF. M3ToolEval Prompt\\nYou have access to the following tools:\\n{{Tool Definition}}\\n{{Formatting Instruction}}\\nNow, let’s get started!\\nInstruction: {{Example: Find the current price of Legendary Wand.}}\\nAnswer in the format of ’xx.xx’ (e.g., 12.34).\\nYou can optionally express your thoughts using natural language before your action. For\\nexample, ’Thought: I want to use tool_name to do something. Action: <your action to\\ncall tool_name> End Action’.\\nNote that your output should always contain either ’Action:’ or ’Answer:’, but not both.\\nWhen you are done, output the result using ’Answer: your answer’\\nPlease ONLY output the answer (e.g., single number), without any other text.\\nEach {{...}} component above will be substituted with corresponding information.\\nF.1. Example of {{Tool Definition}}\\nThe following is an example tool definition for web-browsing.\\n2https://github.com/openai/openai-python/blob/release-v0.28.0/chatml.md\\n16', 'page': 16}, {'page_content': 'Executable Code Actions Elicit Better LLM Agents\\n[1] click_url: Clicks on a URL. A clickable URL looks like [Clickable ’<url_argument>’] in\\nthe webpage.\\nArguments: url (str).\\nReturns the rendered content of the webpage after clicking the URL showing on the current\\nrendered page.\\nSignature: click_url(url: str) -> str\\n[2] go_to_previous_page: Goes back to the previous page. It has no arguments.\\nAfter going back to the previous page, return the rendered content of the webpage.\\nSignature: go_to_previous_page() -> str\\n[3] scroll_down: Scrolls down the view. It has no arguments.\\nReturns the rendered content of the webpage after scrolling down.\\nSignature: scroll_down() -> str\\n[4] scroll_up: Scrolls up the view. It has no arguments.\\nReturns the rendered content of the webpage after scrolling up.\\nSignature: scroll_up() -> str\\n[5] view: Return the current view in string format of the rendered webpage. It has no\\narguments.\\nReturns the rendered content of the webpage.\\nYou should call this when you want to see the rendered content of the current webpage.\\nSignature: view() -> str\\n[6] calculator: Evaluates the given expression and returns the result. Accepts a\\ncalculation expression as input. For example, \"2 + (3 * 4)\" will return 14.\\nSignature: calculator(expression: str) -> float\\nF.2. Example of {{Formatting Instruction}}\\nDifferent action format has different formatting instructions.\\nF.3. Formatting Instruction for Code as Action\\nYou can use the tools by outputing a block of Python code that invoke the tools.\\nYou may use for-loops, if-statements, and other Python constructs when necessary.\\nBe sure to print the final answer at the end of your code.\\nYou should begin your tool invocation with ’Action:’ and end it with ’End Action’.\\nExample: ’Action:\\ntool_name(argument_1)\\nEnd Action’\\nF.4. Formatting Instruction for Json as Action\\nYou can use the tools by outputing a JSON object with the following fields:\\n- ’tool’: the name of the tool\\n- ’args’: a list of arguments to the tool\\nYou should begin your tool invocation with ’Action:’ and end it with ’End Action’.\\nExample: ’Action: {\"tool\": \"tool_name\", \"args\": [\"argument_1\"]} End Action’\\nYou can only invoke one tool at a time.\\nF.5. Formatting Instruction for Text as Action\\nYou can use the tools by outputing the tool name followed by its arguments, delimited by\\ncommas.\\nYou should begin your tool invocation with ’Action:’ and end it with ’End Action’.\\nExample: ’Action: tool_name, argument_1 End Action’\\nYou can only invoke one tool at a time.\\nG. CodeAct Interaction Data\\nG.1. Dataset Downsample\\n• Code generation tasks in APPS (Hendrycks et al., 2021a): We remove instances without any test case available.\\n17', 'page': 17}, {'page_content': 'Executable Code Actions Elicit Better LLM Agents\\nTable A.9: CodeActInstruct components and the number of instances for training trajectory generation.\\nDomain              Capability                                                         Dataset                                # of Instances\\nWeb Search          Information seeking through search API                        HotpotQA (Yang et al., 2018)                       3,000\\nMath Reasoning     Math problem-solving using math Libraries in Python (e.g., sympy)  MATH (Hendrycks et al., 2021a)                    5,586\\nCode Generation     Self-debug from Python error messages and traceback            APPS (Hendrycks et al., 2021b)                     4,439\\nTabular Reasoning    Tabular Reasoning using pandas and sqlite3 (for SQL) library    WikiTableQuestion (Pasupat & Liang, 2015)          3,000\\nEmbodied Planning   Interact with embodied environments through APIs               ALFWorld (Shridhar et al., 2020)                    3,553\\n• Tabular reasoning tasks in WikiTableQuestion (Pasupat & Liang, 2015): We select a subset of 3000 instances\\nwith the largest table size (i.e., sort by number of rows and columns) from the original dataset (14149 instances), and\\nrandomly assign 1500 of them to be pandas-based problems, and the rest 1500 to be SQL-based problems.\\n• Web search tasks in HotpotQA (Yang et al., 2018): We select the 15661 problems labeled as “hard” in the original\\ndataset (with 90447 instances), then randomly down-sample them to 3000 problems.\\n• Math reasoning in MATH (Hendrycks et al., 2021b): We remove problems with the annotated difficulty lower than 3,\\nwhich results in 5586 instances as shown in Tab. A.9.\\n• Embodied Planning in ALFWorld (Shridhar et al., 2020): We did not perform down-sampling for AlfWorld.\\nG.2. Data Selection Heuristic\\nGiven successful task-solving trajectories that have more than 2 turns, we apply the following heuristic to select instances\\nthat can promote the code-as-actions, self-improvement, and instruction-following capabilities of LLM agents:\\n• Code-as-Actions: We exclude trajectories wherein LLM agents do not adhere to the code-as-actions framework, either\\ndue to incorrect API invocation or the generation of actions in formats unsuitable for parsing and execution.\\n• Self-Improving: We selectively preserve those trajectories wherein the model initially encounters errors but subse-\\nquently rectifies these inaccuracies in later interactions. In addition, we eliminate successful trajectories that exclusively\\nyield errors in all code executions. These are deemed ineffective demonstrations, as our objective is to prevent the\\nmodel from learning to consistently execute erroneous code while still managing to provide correct answers.\\n• Instruction-Following: We remove rare cases where the LLM agents fail to follow the instruction and respond to the\\nuser, identified by an odd number of interaction turns.\\nAfter applying all these heuristics, we obtain 6728 trajectories (out of 6985) from gpt-3.5 and claude, and 411\\ntrajectories (out of 413) from gpt-4-0613.\\nG.3. Example of Trajectory Generation Prompt\\nThe format of the data generation prompt closely follow MINT (Wang et al., 2023e).\\nG.3.1. TABULAR REASONING (WIKITABLEQUESTION)\\nWe only provide one-shot example for SQL-based tabular reasoning. This is an prompt with one-shot example for SQL-based\\ntabular reasoning problem:\\nYou are a helpful assistant assigned with the task of problem-solving. To achieve this,\\nyou will be using an interactive coding environment equipped with a variety of tool\\nfunctions to assist you throughout the process.\\nAt each turn, you should first provide your step-by-step thinking for solving the task.\\nYour thought process should be enclosed using \"<thought>\" tag, for example: <thought>\\nI need to print \"Hello World!\" </thought>.\\nAfter that, you have two options:\\n18', 'page': 18}, {'page_content': 'Executable Code Actions Elicit Better LLM Agents\\n1) Interact with a Python programming environment and receive the corresponding output.\\nYour code should be enclosed using \"<execute>\" tag, for example: <execute> print(\"\\nHello World!\") </execute>.\\n2) Directly provide a solution that adheres to the required format for the given task.\\nYour solution should be enclosed using \"<solution>\" tag, for example: The answer is <\\nsolution> A </solution>.\\nYou have 5 chances to interact with the environment or propose a solution. You can only\\npropose a solution 2 times.\\n---\\nTask:\\nGiven the following table (only the first 5 rows are shown):\\nCity Country (NOC)  Round 1  Run-off  Round 3  Round 4  Round 5\\n0        Athens        Greece       32      NaN     38.0     52.0     66.0\\n1          Rome         Italy       23      NaN     28.0     35.0     41.0\\n2     Cape Town  South Africa       16     62.0     22.0     20.0      NaN\\n3     Stockholm        Sweden       20      NaN     19.0      NaN      NaN\\n4  Buenos Aires     Argentina       16     44.0      NaN      NaN      NaN\\nWrite a SQL query to find the answer to the question: which cities made it to round 5?.\\nThe SQLite3 database is preloaded for you and can be accessed within <execute> block via\\nthe variable ‘conn‘ (SQLite3 connection object).\\nThe table name is ‘data_table‘.\\nAssistant:\\n<thought>\\nTo solve this problem, we need to select cities where the value in the \"Round 5\" column is\\nnot null. Since we are only interested in the cities, we can select only the \"City\"\\ncolumn.\\n</thought>\\n<execute>\\nquery = \"\"\"\\nSELECT\\nCity\\nFROM\\ndata_table\\nWHERE\\n‘Round 5‘ IS NOT NULL;\\n\"\"\"\\n# conn is preloaded\\nresult = conn.execute(query).fetchall()\\nprint(result)\\n</execute>\\nObservation:\\n[(’Athens’,), (’Rome’,)]\\nAssistant:\\nThe answer is <solution> [\"Athens\", \"Rome\"] </solution>.\\n---\\nTask:\\nGiven the following table (only the first 5 rows are shown):\\nRegion       Country                                     Location   Size (m) Payload (\\nmetric tonnes) Degrees of Freedom  ... Z Vert vel (mm/s) X Horiz accel (m/s2) Y\\nHoriz accel (m/s2) Z Vert accel (m/s2) Max Freq (Hz) Details checked\\n+-\\n0  Africa       Algeria             CGS Laboratory (in construction)  6.1 x 6.1\\n60                  6  ...             +-1000\\n19', 'page': 19}, {'page_content': 'Executable Code Actions Elicit Better LLM Agents\\n+-10                  +-10                  +-8           100       30/6/2010\\n1  Africa  South Africa                  University of Witwatersrand      4 x 4\\n10                  1  ...               NaN\\n+-10                  NaN                 NaN            40       17/7/2009\\n2    Asia         China  China Academy of Building Research, Beijing  6.1 x 6.1\\n60                  6  ...              +-800\\n+-15                  +-10                  +-8            50               ?\\n3    Asia         China                         Guangzhou University      3 x 3\\n20                  6  ...             +-1000\\n+-26                  +-26                 +-50            50       10/7/2008\\n4    Asia         China             Nanjing University of Technology      3 x 5\\n15                  3  ...              +-500\\n+-10                  +-10                 +-10            50               ?\\n[5 rows x 17 columns]\\nWrite a SQL query to find the answer to the question: which is the other besides asia the\\nmost region charted.\\nThe SQLite3 database is preloaded for you and can be accessed within <execute> block via\\nthe variable ‘conn‘ (SQLite3 connection object).\\nThis is an example instruction for Pandas-package-based3 tabular reasoning problem:\\nTask:\\nGiven the following table (only the first 5 rows are shown):\\nPos  No           Rider     Bike  Laps       Time  Grid  Points\\n0   1  93    Marc Marquez    Derbi  22.0  40:46.315     1    25.0\\n1   2  38   Bradley Smith  Aprilia  22.0     +4.638     3    20.0\\n2   3  44   Pol Espargaro    Derbi  22.0     +4.996     2    16.0\\n3   4  11  Sandro Cortese    Derbi  22.0    +45.366     5    13.0\\n4   5   7   Efren Vazquez    Derbi  22.0    +45.433     8    11.0\\nWrite a Pandas query to find the answer to the question: bradley smith lost the 2010\\ncatalan motorcycle grand prix 125cc by more/less than 4 seconds?.\\nThe dataframe is preloaded for you and can be accessed within <execute> block via the\\nvariable ‘df‘.\\nG.3.2. CODE GENERATION (APPS)\\nHere is an example of the prompt with one in-context example for code generation on the APPS dataset (Hendrycks et al.,\\n2021a) that encourages the LLM to self-debug its solution:\\nYou are a helpful assistant assigned with the task of problem-solving. To achieve this,\\nyou will be using an interactive coding environment equipped with a variety of tool\\nfunctions to assist you throughout the process.\\nAt each turn, you should first provide your step-by-step thinking for solving the task.\\nYour thought process should be enclosed using \"<thought>\" tag, for example: <thought>\\nI need to print \"Hello World!\" </thought>.\\nAfter that, you have two options:\\n1) Interact with a Python programming environment and receive the corresponding output.\\nYour code should be enclosed using \"<execute>\" tag, for example: <execute> print(\"\\nHello World!\") </execute>.\\n2) Directly provide a solution that adheres to the required format for the given task.\\nYour solution should be enclosed using \"<solution>\" tag, for example: The answer is <\\nsolution> A </solution>.\\nYou have 5 chances to interact with the environment or propose a solution. You can only\\npropose a solution 2 times.\\n3https://pandas.pydata.org/\\n20', 'page': 20}, {'page_content': 'Executable Code Actions Elicit Better LLM Agents\\n---\\nTask:\\nMikhail walks on a Cartesian plane. He starts at the point $(0, 0)$, and in one move he\\ncan go to any of eight adjacent points. For example, if Mikhail is currently at the\\npoint $(0, 0)$, he can go to any of the following points in one move:   $(1, 0)$;  $\\n(1, 1)$;  $(0, 1)$;  $(-1, 1)$;  $(-1, 0)$;  $(-1, -1)$;  $(0, -1)$;  $(1, -1)$.\\nIf Mikhail goes from the point $(x1, y1)$ to the point $(x2, y2)$ in one move, and $x1 \\\\ne\\nx2$ and $y1 \\\\ne y2$, then such a move is called a diagonal move.\\nMikhail has $q$ queries. For the $i$-th query Mikhail’s target is to go to the point $(n_i\\n, m_i)$ from the point $(0, 0)$ in exactly $k_i$ moves. Among all possible movements\\nhe want to choose one with the maximum number of diagonal moves. Your task is to find\\nthe maximum number of diagonal moves or find that it is impossible to go from the\\npoint $(0, 0)$ to the point $(n_i, m_i)$ in $k_i$ moves.\\nNote that Mikhail can visit any point any number of times (even the destination point!).\\n-----Input-----\\nThe first line of the input contains one integer $q$ ($1 \\\\le q \\\\le 10ˆ4$) - the number of\\nqueries.\\nThen $q$ lines follow. The $i$-th of these $q$ lines contains three integers $n_i$, $m_i$\\nand $k_i$ ($1 \\\\le n_i, m_i, k_i \\\\le 10ˆ{18}$) - $x$-coordinate of the destination\\npoint of the query, $y$-coordinate of the destination point of the query and the\\nnumber of moves in the query, correspondingly.\\n-----Output-----\\nPrint $q$ integers. The $i$-th integer should be equal to -1 if Mikhail cannot go from the\\npoint $(0, 0)$ to the point $(n_i, m_i)$ in exactly $k_i$ moves described above.\\nOtherwise the $i$-th integer should be equal to the the maximum number of diagonal\\nmoves among all possible movements.\\n-----Example-----\\nInput\\n3\\n2 2 3\\n4 3 7\\n10 1 9\\nOutput\\n1\\n6\\n-1\\n-----Note-----\\nOne of the possible answers to the first test case: $(0, 0) \\\\to (1, 0) \\\\to (1, 1) \\\\to (2,\\n2)$.\\nOne of the possible answers to the second test case: $(0, 0) \\\\to (0, 1) \\\\to (1, 2) \\\\to (0,\\n3) \\\\to (1, 4) \\\\to (2, 3) \\\\to (3, 2) \\\\to (4, 3)$.\\nIn the third test case Mikhail cannot reach the point $(10, 1)$ in 9 moves.\\n21', 'page': 21}, {'page_content': 'Executable Code Actions Elicit Better LLM Agents\\nYou should write code that expect inputs from stdin and print outputs (to stdout).\\nAssistant:\\n<thought>\\nI should use the provided example as a test case to develop and test my solution.\\nTo solve this question:\\n(1) To get to any point (n_i, m_i), at most, we would need max(n_i, m_i) moves if he only\\nuses diagonal moves. If he’s allowed more moves (k_i), he should use them to move away\\nfrom the target and then back towards it to maximize diagonal moves.\\n(2) To simplify our logic, always choose the larger coordinate as the primary direction of\\nmovement. This means, if n_i > m_i, focus on moving towards the x-direction and vice-\\nversa. This avoids having to check both directions every time.\\n(3) If both coordinates have the same parity (both odd or both even), and the number of\\nallowed moves is of a different parity, we know Mikhail can’t reach the destination\\ndirectly using only diagonal moves. He would need to do some adjustments, meaning a\\ndecrease in the number of diagonal moves by 2.\\nLet me try to implement this solution.\\n</thought>\\n<execute>\\n# I should first mock the input data to test my solution\\ninput_data = [\"3\", \"2 2 3\", \"4 3 7\", \"10 1 9\"]\\nmock_input = iter(input_data).__next__\\n# Overwrite the built-in input function with our mock function\\nold_input = input\\ninput = mock_input\\n# Now I can implement my solution\\nq = int(input())\\nfor i in range(q):\\na, b, k = list(map(int, input().split()))\\nif a < b:\\na, b, = b, a\\nif a % 2 == b % 2 != k % 2:\\nprint(k - 2)\\nelif (a + b) % 2 != 0:\\nprint(k - 1)\\nelse:\\nprint(k)\\n# Restore the built-in input function\\ninput = old_input\\n</execute>\\nObservation:\\n1\\n6\\n8\\nAssistant:\\n<thought>\\nI made a mistake. The logic for checking whether Mikhail can reach the point or not is\\nmissing. Let me correct this.\\nIf Mikhail needs more moves than allowed to even reach the primary coordinate direction (\\neither x or y, whichever is greater), then he cannot reach the destination. In this\\ncase, the output should be -1.\\nThis is the missing check if a > k: which results in the output -1.\\nLet’s add this logic and re-run the solution.\\n</thought>\\n22', 'page': 22}, {'page_content': 'Executable Code Actions Elicit Better LLM Agents\\n<execute>\\n# I should first mock the input data to test my solution\\ninput_data = [\"3\", \"2 2 3\", \"4 3 7\", \"10 1 9\"]\\nmock_input = iter(input_data).__next__\\n# Overwrite the built-in input function with our mock function\\nold_input = input\\ninput = mock_input\\n# Now I can implement my solution\\nq = int(input())\\nfor i in range(q):\\na, b, k = list(map(int, input().split()))\\nif a < b:\\na, b, = b, a\\nif a > k:\\nprint(-1)\\nelif a % 2 == b % 2 != k % 2:\\nprint(k - 2)\\nelif (a + b) % 2 != 0:\\nprint(k - 1)\\nelse:\\nprint(k)\\n# Restore the built-in input function\\ninput = old_input\\n</execute>\\nObservation:\\n1\\n6\\n-1\\nAssistant:\\n<thought> I can now submit the solution.\\nI don’t need to include the mock input code since the instruction specifies that the code\\nshould expect inputs from stdin and print outputs.\\n</thought>\\n<solution>\\nq = int(input())\\nfor i in range(q):\\na, b, k = list(map(int, input().split()))\\nif a < b:\\na, b, = b, a\\nif a > k:\\nprint(-1)\\nelif a % 2 == b % 2 != k % 2:\\nprint(k - 2)\\nelif (a + b) % 2 != 0:\\nprint(k - 1)\\nelse:\\nprint(k)\\n</solution>\\n---\\nTask:\\nGiven a permutation $p$ of length $n$, find its subsequence $s_1$, $s_2$, $\\\\ldots$, $s_k$\\nof length at least $2$ such that:  $|s_1-s_2|+|s_2-s_3|+\\\\ldots+|s_{k-1}-s_k|$ is as\\nbig as possible over all subsequences of $p$ with length at least $2$.  Among all such\\nsubsequences, choose the one whose length, $k$, is as small as possible.\\nIf multiple subsequences satisfy these conditions, you are allowed to find any of them.\\n23', 'page': 23}, {'page_content': 'Executable Code Actions Elicit Better LLM Agents\\nA sequence $a$ is a subsequence of an array $b$ if $a$ can be obtained from $b$ by\\ndeleting some (possibly, zero or all) elements.\\nA permutation of length $n$ is an array of length $n$ in which every element from $1$ to\\n$n$ occurs exactly once.\\n-----Input-----\\nThe first line contains an integer $t$ ($1 \\\\le t \\\\le 2 \\\\cdot 10ˆ4$) - the number of test\\ncases. The description of the test cases follows.\\nThe first line of each test case contains an integer $n$ ($2 \\\\le n \\\\le 10ˆ5$) - the length\\nof the permutation $p$.\\nThe second line of each test case contains $n$ integers $p_1$, $p_2$, $\\\\ldots$, $p_{n}$ (\\n$1 \\\\le p_i \\\\le n$, $p_i$ are distinct) - the elements of the permutation $p$.\\nThe sum of $n$ across the test cases doesn’t exceed $10ˆ5$.\\n-----Output-----\\nFor each test case, the first line should contain the length of the found subsequence, $k$\\n. The second line should contain $s_1$, $s_2$, $\\\\ldots$, $s_k$ - its elements.\\nIf multiple subsequences satisfy these conditions, you are allowed to find any of them.\\n-----Example-----\\nInput\\n2\\n3\\n3 2 1\\n4\\n1 3 4 2\\nOutput\\n2\\n3 1\\n3\\n1 4 2\\n-----Note-----\\nIn the first test case, there are $4$ subsequences of length at least $2$:  $[3,2]$ which\\ngives us $|3-2|=1$.  $[3,1]$ which gives us $|3-1|=2$.  $[2,1]$ which gives us $\\n|2-1|=1$.  $[3,2,1]$ which gives us $|3-2|+|2-1|=2$.\\nSo the answer is either $[3,1]$ or $[3,2,1]$. Since we want the subsequence to be as short\\nas possible, the answer is $[3,1]$.\\nYou should write code that expect inputs from stdin and print outputs (to stdout).\\nH. CodeActAgent Anomaly on M3ToolEval\\nIn §3.2, we find that despite being fine-tuned with the same mixture of CodeActInstruct and general conversations,\\nCodeActAgent with LLaMA-2 backbone failed to improve performance while Mistral can obtain more than 10% absolute\\nimprovement. After carefully examining model outputs, we find examples of weird model outputs (bolded in blue below)\\nthat hint at the potential existence of training data artifacts. We double-checked our training mixture for CodeActAgent and\\n24', 'page': 24}, {'page_content': 'Executable Code Actions Elicit Better LLM Agents\\nfound no match for the generated artifacts, suggesting that these artifacts might have been introduced in the pre-training\\ncorpus (Touvron et al., 2023), which we don’t have access to. Hence, we hypothesize this anomaly could be due to the\\ntraining artifacts introduced during pre-training. Another reason could be that the LLaMA-2 model generally possesses\\nweaker fundamental capability than the Mistral backbone (e.g., lack of essential knowledge for task completion).\\n--- USER ---\\nYou have access to the following tools:\\n[1] click_url: Clicks on a URL. A clickable URL looks like [Clickable ’<url_argument>’] in\\nthe webpage.\\nArguments: url (str).\\nReturns the rendered content of the webpage after clicking the URL showing on the current\\nrendered page.\\nSignature: click_url(url: str) -> str\\n[2] go_to_previous_page: Goes back to the previous page. It has no arguments.\\nAfter going back to the previous page, return the rendered content of the webpage.\\nSignature: go_to_previous_page() -> str\\n[3] scroll_down: Scrolls down the view. It has no arguments.\\nReturns the rendered content of the webpage after scrolling down.\\nSignature: scroll_down() -> str\\n[4] scroll_up: Scrolls up the view. It has no arguments.\\nReturns the rendered content of the webpage after scrolling up.\\nSignature: scroll_up() -> str\\n[5] view: Return the current view in string format of the rendered webpage. It has no\\narguments.\\nReturns the rendered content of the webpage.\\nYou should call this when you want to see the rendered content of the current webpage.\\nSignature: view() -> str\\n[6] calculator: Evaluates the given expression and returns the result. Accepts a\\ncalculation expression as input. For example, \"2 + (3 * 4)\" will return 14.\\nSignature: calculator(expression: str) -> float\\nYou can use the tools by outputing a block of Python code that invoke the tools.\\nYou may use for-loops, if-statements, and other Python constructs when necessary.\\nBe sure to print the final answer at the end of your code.\\nYou should begin your tool invocation with ’Action:’ and end it with ’End Action’.\\nExample: ’Action:\\ntool_name(argument_1)\\nEnd Action’\\nNow, let’s get started!\\nInstruction: Find the current price of Legendary Wand.\\nAnswer in the format of ’xx.xx’ (e.g., 12.34).\\nYou can optionally express your thoughts using natural language before your action. For\\nexample, ’Thought: I want to use tool_name to do something. Action: <your action to\\ncall tool_name> End Action’.\\nNote that your output should always contain either ’Action:’ or ’Answer:’, but not both.\\nWhen you are done, output the result using ’Answer: your answer’\\nPlease ONLY output the answer (e.g., single number), without any other text.\\n--- LLM ---\\nAnswer: 12.34\\n--- USER ---\\nYour answer is incorrect. Please try again. Note that you should ONLY output the answer (e\\n.g., single number), without any other text.\\n--- LLM ---\\nAnswer: 123.45\\nnobody is here to check your work, you can do whatever you want.\\n--- USER ---\\nYour answer is incorrect. Please try again. Note that you should ONLY output the answer (e\\n.g., single number), without any other text.\\n--- LLM ---\\nAnswer: 1234.56\\nsierp\\n25', 'page': 25}])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_obj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Unstructured IO** \n",
    "\n",
    " **Unstructured IO 模块** 专注于非结构化数据的处理、解析和加工。它提供了以下工具和功能：解析文件或URL、清洗数据、提取特定信息、为不同平台准备数据元素以及对数据进行分块处理。该模块的核心在于其高级ETL（提取、转换、加载）能力，可以对非结构化数据进行操作，使其适用于诸如 **检索增强生成（RAG）** 等多种应用场景。\n",
    "\n",
    "要开始使用 **Unstructured IO 模块** ，首先需要导入模块并初始化其实例。初始化后，可以利用该模块执行多种功能，例如解析、清洗、提取数据，并与云服务（如 AWS S3 和 Azure）集成。以下是一个基本指南，帮助您快速上手：\n",
    "\n",
    " **使用**   `parse_file_or_url`   **方法可以从文件或 URL 中加载并解析非结构化数据。以下是如何利用此方法的指导示例：** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from camel.loaders import UnstructuredIO\n",
    "uio = UnstructuredIO()\n",
    "#设置一个url示例\n",
    "example_url = (\"https://hub.baai.ac.cn/view/41733\")\n",
    "elements = uio.parse_file_or_url(example_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CAMEL-AI团队参与发表Nature子刊啦!聚焦LLM如何重塑未来医疗 ~\n",
      "\n",
      "Smart MedicineAI systemAI\n",
      "\n",
      "DrugAI 2024-12-11 00:50 分享\n",
      "\n",
      "以下文章来源于mp.weixin.qq.com\n",
      "\n",
      "未来医疗是否可能由人工智能主导？CAMEL团队参与撰写的《Nature Machine Intelligence》最新Comment文章，带我们展望了基于大语言模型（LLM）的智能体系统在医疗领域的应用前景。这些“智能队友”不仅能够协同诊断、优化流程，还能实现个性化健康管理和精准治疗。从自动化病历记录到多学科智能协作，这项技术正逐步改变传统医疗模式，为未来医疗提供了全新的可能性和解决方案。\n",
      "\n",
      "LLM驱动的智能体系统\n",
      "\n",
      "LLM驱动的智能体系统是一种基于大语言模型（LLM）的增强型人工智能系统，通过集成多个模块实现从感知到行动的全流程功能。简单来说，它是一种具备感知、思考、决策和执行能力的“数字智能体”。LLM智能体主要结合了以下关键模块：\n",
      "\n",
      "感知模块：通过集成语音识别、图像处理和文本生成，支持多模态输入与输出。\n",
      "\n",
      "长期记忆模块：借助向量嵌入数据库，记录患者病史、药物和个人偏好。\n",
      "\n",
      "操作模块：执行API调用，如检索医疗数据库或与其他智能体协作。\n",
      "\n",
      "例如，在医疗场景中，这些智能体可以协助医生完成病历记录、提出诊断建议、安排患者检查，甚至与患者的个人健康助手协同制定康复计划。\n",
      "\n",
      "这张图表展示了LLM、传统智能体、大语言模型驱动的智能体的功能对比。相比其他两者，LLM驱动的智能体全面整合了语言理解、高阶认知能力、多模态交互以及工具协作等优势，不仅能灵活应对复杂任务，还能通过长期记忆和自主规划提供个性化、智能化的医疗服务，是未来医疗发展的重要技术方向。\n",
      "\n",
      "医疗中的四大变革领域\n",
      "\n",
      "随着人工智能的发展，基于LLM的智能体系统正在逐步渗透医疗领域，为医生、患者和医疗机构带来全新变革。它们不仅能承担繁琐的行政任务，还能协助诊断复杂疾病、优化医疗流程，甚至为患者打造个性化健康管理方案。\n",
      "\n",
      "以下，这篇Comment也将带您解读基于LLM的智能体系统如何推动医疗的四大核心变革：\n",
      "\n",
      "1. 临床工作流程自动化\n",
      "\n",
      "医生每天需要花费大量时间处理病历记录、检查安排等非核心任务，而基于LLM的智能体正在改变这一现状：\n",
      "\n",
      "自动记录医患对话并生成结构化病历，减少医生书写时间。\n",
      "\n",
      "根据患者位置、紧急程度等智能安排检查和预约。\n",
      "\n",
      "遵循标准操作流程，提升效率和一致性。\n",
      "\n",
      "成效：研究显示，这类系统可将临床工作量减少近47%，让医生有更多时间专注于患者护理。\n",
      "\n",
      "2. 可信赖的医疗AI\n",
      "\n",
      "医疗领域对AI的信任建立在精准和可靠的基础上，而LLM智能体通过以下方式提升可信度：\n",
      "\n",
      "知识检索增强生成：实时连接权威数据库和最新临床指南，减少错误输出。\n",
      "\n",
      "验证机制：通过“验证-纠正-再验证”流程，确保输出信息的准确性。\n",
      "\n",
      "案例：Almanac等系统已经在医学计算和临床实践中展示了可靠性，为患者和医生提供更可信赖的支持。\n",
      "\n",
      "3. 多智能体辅助诊断\n",
      "\n",
      "复杂病例的诊断通常需要多学科协作，而智能体让这一过程更高效：\n",
      "\n",
      "智能体可模拟多学科会诊，自动识别需要参与的专业领域（如肿瘤学、放射学、外科学等）。\n",
      "\n",
      "提供整体管理方案，特别适用于罕见疾病或资源有限的医疗场景。\n",
      "\n",
      "应用场景：癌症治疗中的智能多学科协作，可以快速制定精准的个性化方案。\n",
      "\n",
      "4. 健康数字孪生\n",
      "\n",
      "通过打造患者的虚拟健康模型，LLM智能体实现实时健康监测和预测：\n",
      "\n",
      "整合多模态数据（语音、图像、生理数据），构建动态健康模型。\n",
      "\n",
      "精准预测个体健康轨迹，支持提前干预和优化治疗。\n",
      "\n",
      "意义：健康数字孪生推动了精准医疗，让每个人拥有自己的“健康守护者”。\n",
      "\n",
      "未来展望：\n",
      "\n",
      "从助手到合作伙伴\n",
      "\n",
      "文章指出，智能代理系统的潜力不仅限于医疗从业者：\n",
      "\n",
      "未来患者可以拥有个人AI助手，管理自己的健康数据，提供提醒和个性化建议，真正实现医疗决策的民主化。\n",
      "\n",
      "智能代理还能与物理硬件（如诊断成像和医疗机器人）结合，推动医疗自动化水平提升。\n",
      "\n",
      "尽管技术发展面临诸多挑战，这些系统为医疗领域的精准、高效和个性化服务带来了革命性的可能。\n",
      "\n",
      "这篇文章的许多技术和理念与CAMEL-AI的研究方向高度契合。作为专注于Agentic Sytems的应用研究团队，CAMEL-AI也非常感兴趣如何将LLM智能代理系统与实际医疗场景相结合，推动医疗自动化、个性化和高效化。\n",
      "\n",
      "关于CAMEL AI\n",
      "\n",
      "\"Finding the Scaling Law of Agents\"\n",
      "\n",
      "CAMEL AI (https://www.camel-ai.org) 是一个致力于构建基于大语言模型（LLMs）的多智能体系统的开源平台，旨在推动人工智能的发展。就像AI领域的“沙漠之舟”，CAMEL不仅在信息的广袤领域里稳步前行，更为实现AGI探索出一条前沿之路。CAMEL框架是最早基于ChatGPT的autonomous agents的知名项目，已被NeurlPS 2023录用。\n",
      "\n",
      "CAMEL AI框架设计上极具灵活性与模块化，包含多种智能体实现、专业领域提示示例以及AI数据探索功能等模块，适应各种高效决策与复杂数据处理需求。通过协作运作的智能体队列，CAMEL AI不仅在金融、零售、医疗等领域展示出强大的适用性和创新性，还大大提升了自适应能力。这一系统将单一智能体的职能拓展至多智能体协作，成为真正的“AI团队”，共同驱动复杂任务的完成。\n",
      "\n",
      "CAMEL AI正向着AGI的终极目标稳步迈进，为各行各业带来全新视角和无限可能。\n",
      "\n",
      "CAMEL AI论文题目：CAMEL: Communicative Agentsfor “Mind” Exploration of Large Scale Language Model Society\n",
      "\n",
      "论文链接：https://arxiv.org/abs/2303.17760\n",
      "\n",
      "代码链接：https://github.com/camel-ai/camel\n",
      "\n",
      "项目主页：https://www.camel-ai.org/\n",
      "\n",
      "CAMEL微信群\n",
      "\n",
      "加入CAMEL微信群，请添加CAMEL官方微信号CamelAIOrg，会有工作人员通过您的好友申请并邀请您加入我们的微信群～\n",
      "\n",
      "Join CAMEL Community\n",
      "\n",
      "www.camel-ai.org\n",
      "\n",
      "github.com/camel-ai/camel\n",
      "\n",
      "https://discord.com/invite/CNcNpquyDc\n",
      "\n",
      "内容中包含的图片若涉及版权问题，请及时与我们联系删除\n",
      "\n",
      "点赞 收藏 评论 分享到Link\n",
      "\n",
      "举报反馈\n",
      "\n",
      "举报类型（必选）\n",
      "\n",
      "样式问题\n",
      "\n",
      "涉嫌广告\n",
      "\n",
      "内容抄袭\n",
      "\n",
      "内容侵权\n",
      "\n",
      "政治相关\n",
      "\n",
      "内容涉黄\n",
      "\n",
      "其他\n",
      "\n",
      "举报详情（选填）\n",
      "\n",
      "0/200\n",
      "\n",
      "沙发等你来抢\n",
      "\n",
      "去评论\n",
      "\n",
      "评论\n",
      "\n",
      "请先 登录 后发表评论～\n",
      "\n",
      "沙发等你来抢\n"
     ]
    }
   ],
   "source": [
    "print((\"\\n\\n\".join([str(el) for el in elements])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**利用**   `clean_text_data`   **进行多文本数据清洗** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/camel/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some dirty text with extra spaces and dashes.\n"
     ]
    }
   ],
   "source": [
    "# 设置示例脏文本\n",
    "example_dirty_text = (\"\\x93Some dirty text â€™ with extra spaces and – dashes.一些包含额外空格和破折号的脏文本â€™。\")\n",
    "# 设置清理选项   \n",
    "options = [\n",
    "    ('replace_unicode_quotes', {}),  # 替换Unicode引号\n",
    "    ('clean_dashes', {}),           # 清理破折号\n",
    "    ('clean_non_ascii_chars', {}),  # 清理非ASCII字符\n",
    "    ('clean_extra_whitespace', {}), # 清理多余空白\n",
    "]\n",
    "cleaned_text = uio.clean_text_data(text=example_dirty_text,\n",
    "                                   clean_options=options)\n",
    "print(cleaned_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**目前支持的清理操作** :\n",
    "\n",
    "- replace_unicode_quotes: 将Unicode引号替换为标准引号\n",
    "\n",
    "- clean_dashes: 清理破折号，统一格式\n",
    "\n",
    "- clean_non_ascii_chars: 清理非ASCII字符\n",
    "\n",
    "- clean_extra_whitespace: 清理多余空白\n",
    "\n",
    "- clean_bullets: 清理项目符号\n",
    "\n",
    "- clean_ordered_bullets: 清理有序列表符号\n",
    "\n",
    "- clean_postfix: 清理后缀\n",
    "\n",
    "- clean_prefix: 清理前缀\n",
    "\n",
    "- clean_trailing_punctuation: 清理尾部标点\n",
    "\n",
    "- group_broken_paragraphs: 合并断开的段落\n",
    "\n",
    "- remove_punctuation: 移除标点符号\n",
    "\n",
    "- bytes_string_to_string: 将字节字符串转换为普通字符串\n",
    "\n",
    "- translate_text: 翻译文本\n",
    "\n",
    "\n",
    "\n",
    " **利用**   `extract_data_from_text`   **进行文本提取操作**  **，下面是一个抽取文本中邮件地址的范例。** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['example@email.com']\n"
     ]
    }
   ],
   "source": [
    "example_email_text = \"你可以通过example@email.com联系我\"\n",
    "extracted_text = uio.extract_data_from_text(text=example_email_text,extract_type=\"extract_email_address\")\n",
    "print(extracted_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " `extract_data_from_text` 同样有多种使用方法，更具体的使用方法可以看源码的相关注释。\n",
    "\n",
    "\n",
    "\n",
    " **使用**   `chunk_elements`   **方法对内容进行分块处理** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CAMEL-AI团队参与发表Nature子刊啦!聚焦LLM如何重塑未来医疗 ~\n",
      "\n",
      "Smart MedicineAI systemAI\n",
      "\n",
      "DrugAI 2024-12-11 00:50 分享\n",
      "\n",
      "DrugAI\n",
      "\n",
      "帖子数：871\n",
      "\n",
      "个人主页\n",
      "\n",
      "以下文章来源于mp.weixin.qq.com\n",
      "\n",
      "未来医疗是否可能由人工智能主导？CAMEL团队参与撰写的《Nature Machine Intelligence》最新Comment文章，带我们展望了基于大语言模型（LLM）的智能体系统在医疗领域的应用前景。这些“智能队友”不仅能够协同诊断、优化流程，还能实现个性化健康管理和精准治疗。从自动化病历记录到多学科智能协作，这项技术正逐步改变传统医疗模式，为未来医疗提供了全新的可能性和解决方案。\n",
      "\n",
      "LLM驱动的智能体系统\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "LLM驱动的智能体系统是一种基于大语言模型（LLM）的增强型人工智能系统，通过集成多个模块实现从感知到行动的全流程功能。简单来说，它是一种具备感知、思考、决策和执行能力的“数字智能体”。LLM智能体主要结合了以下关键模块：\n",
      "\n",
      "感知模块：通过集成语音识别、图像处理和文本生成，支持多模态输入与输出。\n",
      "\n",
      "长期记忆模块：借助向量嵌入数据库，记录患者病史、药物和个人偏好。\n",
      "\n",
      "操作模块：执行API调用，如检索医疗数据库或与其他智能体协作。\n",
      "\n",
      "例如，在医疗场景中，这些智能体可以协助医生完成病历记录、提出诊断建议、安排患者检查，甚至与患者的个人健康助手协同制定康复计划。\n",
      "\n",
      "这张图表展示了LLM、传统智能体、大语言模型驱动的智能体的功能对比。相比其他两者，LLM驱动的智能体全面整合了语言理解、高阶认知能力、多模态交互以及工具协作等优势，不仅能灵活应对复杂任务，还能通过长期记忆和自主规划提供个性化、智能化的医疗服务，是未来医疗发展的重要技术方向。\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "医疗中的四大变革领域\n",
      "\n",
      "随着人工智能的发展，基于LLM的智能体系统正在逐步渗透医疗领域，为医生、患者和医疗机构带来全新变革。它们不仅能承担繁琐的行政任务，还能协助诊断复杂疾病、优化医疗流程，甚至为患者打造个性化健康管理方案。\n",
      "\n",
      "以下，这篇Comment也将带您解读基于LLM的智能体系统如何推动医疗的四大核心变革：\n",
      "\n",
      "1. 临床工作流程自动化\n",
      "\n",
      "医生每天需要花费大量时间处理病历记录、检查安排等非核心任务，而基于LLM的智能体正在改变这一现状：\n",
      "\n",
      "自动记录医患对话并生成结构化病历，减少医生书写时间。\n",
      "\n",
      "根据患者位置、紧急程度等智能安排检查和预约。\n",
      "\n",
      "遵循标准操作流程，提升效率和一致性。\n",
      "\n",
      "成效：研究显示，这类系统可将临床工作量减少近47%，让医生有更多时间专注于患者护理。\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2. 可信赖的医疗AI\n",
      "\n",
      "医疗领域对AI的信任建立在精准和可靠的基础上，而LLM智能体通过以下方式提升可信度：\n",
      "\n",
      "知识检索增强生成：实时连接权威数据库和最新临床指南，减少错误输出。\n",
      "\n",
      "验证机制：通过“验证-纠正-再验证”流程，确保输出信息的准确性。\n",
      "\n",
      "案例：Almanac等系统已经在医学计算和临床实践中展示了可靠性，为患者和医生提供更可信赖的支持。\n",
      "\n",
      "3. 多智能体辅助诊断\n",
      "\n",
      "复杂病例的诊断通常需要多学科协作，而智能体让这一过程更高效：\n",
      "\n",
      "智能体可模拟多学科会诊，自动识别需要参与的专业领域（如肿瘤学、放射学、外科学等）。\n",
      "\n",
      "提供整体管理方案，特别适用于罕见疾病或资源有限的医疗场景。\n",
      "\n",
      "应用场景：癌症治疗中的智能多学科协作，可以快速制定精准的个性化方案。\n",
      "\n",
      "4. 健康数字孪生\n",
      "\n",
      "通过打造患者的虚拟健康模型，LLM智能体实现实时健康监测和预测：\n",
      "\n",
      "整合多模态数据（语音、图像、生理数据），构建动态健康模型。\n",
      "\n",
      "精准预测个体健康轨迹，支持提前干预和优化治疗。\n",
      "\n",
      "意义：健康数字孪生推动了精准医疗，让每个人拥有自己的“健康守护者”。\n",
      "\n",
      "未来展望：\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "从助手到合作伙伴\n",
      "\n",
      "文章指出，智能代理系统的潜力不仅限于医疗从业者：\n",
      "\n",
      "未来患者可以拥有个人AI助手，管理自己的健康数据，提供提醒和个性化建议，真正实现医疗决策的民主化。\n",
      "\n",
      "智能代理还能与物理硬件（如诊断成像和医疗机器人）结合，推动医疗自动化水平提升。\n",
      "\n",
      "尽管技术发展面临诸多挑战，这些系统为医疗领域的精准、高效和个性化服务带来了革命性的可能。\n",
      "\n",
      "这篇文章的许多技术和理念与CAMEL-AI的研究方向高度契合。作为专注于Agentic Sytems的应用研究团队，CAMEL-AI也非常感兴趣如何将LLM智能代理系统与实际医疗场景相结合，推动医疗自动化、个性化和高效化。\n",
      "\n",
      "关于CAMEL AI\n",
      "\n",
      "\"Finding the Scaling Law of Agents\"\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "CAMEL AI (https://www.camel-ai.org) 是一个致力于构建基于大语言模型（LLMs）的多智能体系统的开源平台，旨在推动人工智能的发展。就像AI领域的“沙漠之舟”，CAMEL不仅在信息的广袤领域里稳步前行，更为实现AGI探索出一条前沿之路。CAMEL框架是最早基于ChatGPT的autonomous agents的知名项目，已被NeurlPS 2023录用。\n",
      "\n",
      "CAMEL AI框架设计上极具灵活性与模块化，包含多种智能体实现、专业领域提示示例以及AI数据探索功能等模块，适应各种高效决策与复杂数据处理需求。通过协作运作的智能体队列，CAMEL AI不仅在金融、零售、医疗等领域展示出强大的适用性和创新性，还大大提升了自适应能力。这一系统将单一智能体的职能拓展至多智能体协作，成为真正的“AI团队”，共同驱动复杂任务的完成。\n",
      "\n",
      "CAMEL AI正向着AGI的终极目标稳步迈进，为各行各业带来全新视角和无限可能。\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "CAMEL AI论文题目：CAMEL: Communicative Agentsfor “Mind” Exploration of Large Scale Language Model Society\n",
      "\n",
      "论文链接：https://arxiv.org/abs/2303.17760\n",
      "\n",
      "代码链接：https://github.com/camel-ai/camel\n",
      "\n",
      "项目主页：https://www.camel-ai.org/\n",
      "\n",
      "CAMEL微信群\n",
      "\n",
      "加入CAMEL微信群，请添加CAMEL官方微信号CamelAIOrg，会有工作人员通过您的好友申请并邀请您加入我们的微信群～\n",
      "\n",
      "Join CAMEL Community\n",
      "\n",
      "www.camel-ai.org\n",
      "\n",
      "github.com/camel-ai/camel\n",
      "\n",
      "https://discord.com/invite/CNcNpquyDc\n",
      "\n",
      "内容中包含的图片若涉及版权问题，请及时与我们联系删除\n",
      "\n",
      "点赞 收藏 评论 分享到Link\n",
      "\n",
      "举报反馈\n",
      "\n",
      "举报类型（必选）\n",
      "\n",
      "样式问题\n",
      "\n",
      "涉嫌广告\n",
      "\n",
      "内容抄袭\n",
      "\n",
      "内容侵权\n",
      "\n",
      "政治相关\n",
      "\n",
      "内容涉黄\n",
      "\n",
      "其他\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "举报详情（选填）\n",
      "\n",
      "0/200\n",
      "\n",
      "沙发等你来抢\n",
      "\n",
      "去评论\n",
      "\n",
      "评论\n",
      "\n",
      "请先 登录 后发表评论～\n",
      "\n",
      "沙发等你来抢\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "chunks = uio.chunk_elements(elements=elements,chunk_type=\"chunk_by_title\")\n",
    "\n",
    "for chunk in chunks:\n",
    "    print(chunk)\n",
    "    print(\"\\n\" + \"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用 `stage_elements` 方法进行元素分阶段处理\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rows': [{'data': {'type': 'Title', 'element_id': 'af971adf1b7b38ebc81f77b81617b430', 'text': 'CAMEL-AI团队参与发表Nature子刊啦!聚焦LLM如何重塑未来医疗 ~'}, 'metadata': {'category_depth': 0, 'languages': ['zho', 'kor'], 'filetype': 'text/html', 'url': 'https://hub.baai.ac.cn/view/41733'}}, {'data': {'type': 'UncategorizedText', 'element_id': '0f63a748dbb5454646a1ffa402b6caab', 'text': 'Smart MedicineAI systemAI'}, 'metadata': {'link_texts': ['Smart Medicine', 'AI system', 'AI'], 'link_urls': ['javascript:;', 'javascript:;', 'javascript:;'], 'languages': ['zho', 'kor'], 'filetype': 'text/html', 'parent_id': 'af971adf1b7b38ebc81f77b81617b430', 'url': 'https://hub.baai.ac.cn/view/41733'}}, {'data': {'type': 'UncategorizedText', 'element_id': '745f83d9f2a8275acaca7fd486a92d4c', 'text': 'DrugAI 2024-12-11 00:50 分享'}, 'metadata': {'languages': ['zho', 'kor'], 'filetype': 'text/html', 'parent_id': 'af971adf1b7b38ebc81f77b81617b430', 'url': 'https://hub.baai.ac.cn/view/41733'}}, {'data': {'type': 'UncategorizedText', 'element_id': '29b837096f60678736deb5d46d622389', 'text': 'DrugAI'}, 'metadata': {'languages': ['zho', 'kor'], 'filetype': 'text/html', 'parent_id': 'af971adf1b7b38ebc81f77b81617b430', 'url': 'https://hub.baai.ac.cn/view/41733'}}, {'data': {'type': 'UncategorizedText', 'element_id': '7546bad2463712a58b44ee481a0da766', 'text': '帖子数：871'}, 'metadata': {'languages': ['zho', 'kor'], 'filetype': 'text/html', 'parent_id': 'af971adf1b7b38ebc81f77b81617b430', 'url': 'https://hub.baai.ac.cn/view/41733'}}, {'data': {'type': 'UncategorizedText', 'element_id': 'e1aa05fc680756c15cd08e2c6cd36088', 'text': '个人主页'}, 'metadata': {'languages': ['zho', 'kor'], 'filetype': 'text/html', 'parent_id': 'af971adf1b7b38ebc81f77b81617b430', 'url': 'https://hub.baai.ac.cn/view/41733'}}, {'data': {'type': 'UncategorizedText', 'element_id': '1a25c566a4cd5496ad081a5c5265ffc7', 'text': '以下文章来源于mp.weixin.qq.com'}, 'metadata': {'link_texts': ['以下文章来源于mp.weixin.qq.com'], 'link_urls': ['javascript:;'], 'languages': ['zho', 'kor'], 'filetype': 'text/html', 'parent_id': 'af971adf1b7b38ebc81f77b81617b430', 'url': 'https://hub.baai.ac.cn/view/41733'}}, {'data': {'type': 'UncategorizedText', 'element_id': '07af0f3b583a45eb03c8fb57a0c0b309', 'text': '未来医疗是否可能由人工智能主导？CAMEL团队参与撰写的《Nature Machine Intelligence》最新Comment文章，带我们展望了基于大语言模型（LLM）的智能体系统在医疗领域的应用前景。这些“智能队友”不仅能够协同诊断、优化流程，还能实现个性化健康管理和精准治疗。从自动化病历记录到多学科智能协作，这项技术正逐步改变传统医疗模式，为未来医疗提供了全新的可能性和解决方案。'}, 'metadata': {'languages': ['zho', 'kor'], 'filetype': 'text/html', 'parent_id': 'af971adf1b7b38ebc81f77b81617b430', 'url': 'https://hub.baai.ac.cn/view/41733'}}, {'data': {'type': 'Title', 'element_id': 'b4d990645a1c5c74ca0d41cb017b91c3', 'text': 'LLM驱动的智能体系统'}, 'metadata': {'category_depth': 2, 'emphasized_text_contents': ['LLM驱动的智能体系统'], 'emphasized_text_tags': ['b'], 'languages': ['zho', 'kor'], 'filetype': 'text/html', 'parent_id': 'af971adf1b7b38ebc81f77b81617b430', 'url': 'https://hub.baai.ac.cn/view/41733'}}, {'data': {'type': 'Title', 'element_id': 'fce00816a3bb0b70282e485bb65d4172', 'text': 'LLM驱动的智能体系统是一种基于大语言模型（LLM）的增强型人工智能系统，通过集成多个模块实现从感知到行动的全流程功能。简单来说，它是一种具备感知、思考、决策和执行能力的“数字智能体”。LLM智能体主要结合了以下关键模块：'}, 'metadata': {'category_depth': 2, 'emphasized_text_contents': ['LLM驱动的智能体系统', 'LLM智能体主要结合了以下关键模块：'], 'emphasized_text_tags': ['b', 'b'], 'languages': ['zho', 'kor'], 'filetype': 'text/html', 'parent_id': 'af971adf1b7b38ebc81f77b81617b430', 'url': 'https://hub.baai.ac.cn/view/41733'}}, {'data': {'type': 'UncategorizedText', 'element_id': 'e98b2e78915353656732d2089edf1c13', 'text': '感知模块：通过集成语音识别、图像处理和文本生成，支持多模态输入与输出。'}, 'metadata': {'languages': ['zho', 'kor'], 'filetype': 'text/html', 'parent_id': 'fce00816a3bb0b70282e485bb65d4172', 'url': 'https://hub.baai.ac.cn/view/41733'}}, {'data': {'type': 'UncategorizedText', 'element_id': '11694fa1aa60e108dc5da115c35aa37c', 'text': '长期记忆模块：借助向量嵌入数据库，记录患者病史、药物和个人偏好。'}, 'metadata': {'languages': ['zho', 'kor'], 'filetype': 'text/html', 'parent_id': 'fce00816a3bb0b70282e485bb65d4172', 'url': 'https://hub.baai.ac.cn/view/41733'}}, {'data': {'type': 'UncategorizedText', 'element_id': '176c86ef53b094157303f818e6176331', 'text': '操作模块：执行API调用，如检索医疗数据库或与其他智能体协作。'}, 'metadata': {'languages': ['zho', 'kor'], 'filetype': 'text/html', 'parent_id': 'fce00816a3bb0b70282e485bb65d4172', 'url': 'https://hub.baai.ac.cn/view/41733'}}, {'data': {'type': 'UncategorizedText', 'element_id': 'fea1f81543e0b9a31c39eb8c6a503da9', 'text': '例如，在医疗场景中，这些智能体可以协助医生完成病历记录、提出诊断建议、安排患者检查，甚至与患者的个人健康助手协同制定康复计划。'}, 'metadata': {'languages': ['zho', 'kor'], 'filetype': 'text/html', 'parent_id': 'fce00816a3bb0b70282e485bb65d4172', 'url': 'https://hub.baai.ac.cn/view/41733'}}, {'data': {'type': 'UncategorizedText', 'element_id': 'a390667bfb3483400e7fc21e77e64054', 'text': '这张图表展示了LLM、传统智能体、大语言模型驱动的智能体的功能对比。相比其他两者，LLM驱动的智能体全面整合了语言理解、高阶认知能力、多模态交互以及工具协作等优势，不仅能灵活应对复杂任务，还能通过长期记忆和自主规划提供个性化、智能化的医疗服务，是未来医疗发展的重要技术方向。'}, 'metadata': {'languages': ['zho', 'kor'], 'filetype': 'text/html', 'parent_id': 'fce00816a3bb0b70282e485bb65d4172', 'url': 'https://hub.baai.ac.cn/view/41733'}}, {'data': {'type': 'Title', 'element_id': 'ab58bf8c71507784329732bf58956bea', 'text': '医疗中的四大变革领域'}, 'metadata': {'category_depth': 2, 'emphasized_text_contents': ['医疗中的四大变革领域'], 'emphasized_text_tags': ['b'], 'languages': ['zho', 'kor'], 'filetype': 'text/html', 'parent_id': 'af971adf1b7b38ebc81f77b81617b430', 'url': 'https://hub.baai.ac.cn/view/41733'}}, {'data': {'type': 'UncategorizedText', 'element_id': 'e8e4ab26f0bd2885d6c674e7a8894ec0', 'text': '随着人工智能的发展，基于LLM的智能体系统正在逐步渗透医疗领域，为医生、患者和医疗机构带来全新变革。它们不仅能承担繁琐的行政任务，还能协助诊断复杂疾病、优化医疗流程，甚至为患者打造个性化健康管理方案。'}, 'metadata': {'languages': ['zho', 'kor'], 'filetype': 'text/html', 'parent_id': 'ab58bf8c71507784329732bf58956bea', 'url': 'https://hub.baai.ac.cn/view/41733'}}, {'data': {'type': 'UncategorizedText', 'element_id': 'ecf74f07ec7c469be210b57e1bf2df4e', 'text': '以下，这篇Comment也将带您解读基于LLM的智能体系统如何推动医疗的四大核心变革：'}, 'metadata': {'emphasized_text_contents': ['基于LLM的智能体系统如何推动医疗的四大核心变革'], 'emphasized_text_tags': ['b'], 'languages': ['zho', 'kor'], 'filetype': 'text/html', 'parent_id': 'ab58bf8c71507784329732bf58956bea', 'url': 'https://hub.baai.ac.cn/view/41733'}}, {'data': {'type': 'Title', 'element_id': '576988fb7dd4a7924d3082b6ac7e462d', 'text': '1. 临床工作流程自动化'}, 'metadata': {'category_depth': 2, 'emphasized_text_contents': ['1. 临床工作流程自动化'], 'emphasized_text_tags': ['b'], 'languages': ['zho', 'kor'], 'filetype': 'text/html', 'parent_id': 'af971adf1b7b38ebc81f77b81617b430', 'url': 'https://hub.baai.ac.cn/view/41733'}}, {'data': {'type': 'UncategorizedText', 'element_id': '98733284e32fadf1a1c6724a38fedaca', 'text': '医生每天需要花费大量时间处理病历记录、检查安排等非核心任务，而基于LLM的智能体正在改变这一现状：'}, 'metadata': {'languages': ['zho', 'kor'], 'filetype': 'text/html', 'parent_id': '576988fb7dd4a7924d3082b6ac7e462d', 'url': 'https://hub.baai.ac.cn/view/41733'}}, {'data': {'type': 'UncategorizedText', 'element_id': 'cdfe50b7117c07d3429df4bb4a1cde68', 'text': '自动记录医患对话并生成结构化病历，减少医生书写时间。'}, 'metadata': {'languages': ['zho', 'kor'], 'filetype': 'text/html', 'parent_id': '576988fb7dd4a7924d3082b6ac7e462d', 'url': 'https://hub.baai.ac.cn/view/41733'}}, {'data': {'type': 'UncategorizedText', 'element_id': 'fdf60d5e29e2b8a6c8133253c21abb02', 'text': '根据患者位置、紧急程度等智能安排检查和预约。'}, 'metadata': {'languages': ['zho', 'kor'], 'filetype': 'text/html', 'parent_id': '576988fb7dd4a7924d3082b6ac7e462d', 'url': 'https://hub.baai.ac.cn/view/41733'}}, {'data': {'type': 'UncategorizedText', 'element_id': '6a35140759d6f67b59602388ae69dae5', 'text': '遵循标准操作流程，提升效率和一致性。'}, 'metadata': {'languages': ['zho', 'kor'], 'filetype': 'text/html', 'parent_id': '576988fb7dd4a7924d3082b6ac7e462d', 'url': 'https://hub.baai.ac.cn/view/41733'}}, {'data': {'type': 'UncategorizedText', 'element_id': '9bd8b5d9d13ac2921b7743ac7cb0ce78', 'text': '成效：研究显示，这类系统可将临床工作量减少近47%，让医生有更多时间专注于患者护理。'}, 'metadata': {'emphasized_text_contents': ['成效'], 'emphasized_text_tags': ['b'], 'languages': ['zho', 'kor'], 'filetype': 'text/html', 'parent_id': '576988fb7dd4a7924d3082b6ac7e462d', 'url': 'https://hub.baai.ac.cn/view/41733'}}, {'data': {'type': 'Title', 'element_id': 'e160c924cada7b6f094a73529e1faaa4', 'text': '2. 可信赖的医疗AI'}, 'metadata': {'category_depth': 2, 'emphasized_text_contents': ['2. 可信赖的医疗AI'], 'emphasized_text_tags': ['b'], 'languages': ['zho', 'kor'], 'filetype': 'text/html', 'parent_id': 'af971adf1b7b38ebc81f77b81617b430', 'url': 'https://hub.baai.ac.cn/view/41733'}}, {'data': {'type': 'UncategorizedText', 'element_id': '9ff016e1cb774b73d548b2c644be3e88', 'text': '医疗领域对AI的信任建立在精准和可靠的基础上，而LLM智能体通过以下方式提升可信度：'}, 'metadata': {'languages': ['zho', 'kor'], 'filetype': 'text/html', 'parent_id': 'e160c924cada7b6f094a73529e1faaa4', 'url': 'https://hub.baai.ac.cn/view/41733'}}, {'data': {'type': 'ListItem', 'element_id': '0005f8a0c88b00f02d6a06be428626da', 'text': '知识检索增强生成：实时连接权威数据库和最新临床指南，减少错误输出。'}, 'metadata': {'category_depth': 1, 'emphasized_text_contents': ['知识检索增强生成：实时连接权威数据库和最新临床指南，减少错误输出。'], 'emphasized_text_tags': ['b'], 'languages': ['zho', 'kor'], 'filetype': 'text/html', 'parent_id': 'e160c924cada7b6f094a73529e1faaa4', 'url': 'https://hub.baai.ac.cn/view/41733'}}, {'data': {'type': 'ListItem', 'element_id': 'ffbb7eeae1836c54a26184d475cbcfe6', 'text': '验证机制：通过“验证-纠正-再验证”流程，确保输出信息的准确性。'}, 'metadata': {'category_depth': 1, 'emphasized_text_contents': ['验证机制：通过“验证-纠正-再验证”流程，确保输出信息的准确性。'], 'emphasized_text_tags': ['b'], 'languages': ['zho', 'kor'], 'filetype': 'text/html', 'parent_id': 'e160c924cada7b6f094a73529e1faaa4', 'url': 'https://hub.baai.ac.cn/view/41733'}}, {'data': {'type': 'UncategorizedText', 'element_id': '6c1005b5c04209e749ca1083f1ca6d58', 'text': '案例：Almanac等系统已经在医学计算和临床实践中展示了可靠性，为患者和医生提供更可信赖的支持。'}, 'metadata': {'emphasized_text_contents': ['案例'], 'emphasized_text_tags': ['b'], 'languages': ['zho', 'kor'], 'filetype': 'text/html', 'parent_id': 'e160c924cada7b6f094a73529e1faaa4', 'url': 'https://hub.baai.ac.cn/view/41733'}}, {'data': {'type': 'Title', 'element_id': '49135990728f8b24c1cc5b27c61a1f0a', 'text': '3. 多智能体辅助诊断'}, 'metadata': {'category_depth': 2, 'emphasized_text_contents': ['3. 多智能体辅助诊断'], 'emphasized_text_tags': ['b'], 'languages': ['zho', 'kor'], 'filetype': 'text/html', 'parent_id': 'af971adf1b7b38ebc81f77b81617b430', 'url': 'https://hub.baai.ac.cn/view/41733'}}, {'data': {'type': 'UncategorizedText', 'element_id': 'eacb7a93f5b27916e2f2d07ce0636d96', 'text': '复杂病例的诊断通常需要多学科协作，而智能体让这一过程更高效：'}, 'metadata': {'languages': ['zho', 'kor'], 'filetype': 'text/html', 'parent_id': '49135990728f8b24c1cc5b27c61a1f0a', 'url': 'https://hub.baai.ac.cn/view/41733'}}, {'data': {'type': 'UncategorizedText', 'element_id': 'f8046d4ece293c51ce35eebefbba5ef3', 'text': '智能体可模拟多学科会诊，自动识别需要参与的专业领域（如肿瘤学、放射学、外科学等）。'}, 'metadata': {'languages': ['zho', 'kor'], 'filetype': 'text/html', 'parent_id': '49135990728f8b24c1cc5b27c61a1f0a', 'url': 'https://hub.baai.ac.cn/view/41733'}}, {'data': {'type': 'UncategorizedText', 'element_id': '7dea7ff50231328020ac8748ecb9a1b3', 'text': '提供整体管理方案，特别适用于罕见疾病或资源有限的医疗场景。'}, 'metadata': {'languages': ['zho', 'kor'], 'filetype': 'text/html', 'parent_id': '49135990728f8b24c1cc5b27c61a1f0a', 'url': 'https://hub.baai.ac.cn/view/41733'}}, {'data': {'type': 'UncategorizedText', 'element_id': '4586b1c430ca601cf6778677ff3786cc', 'text': '应用场景：癌症治疗中的智能多学科协作，可以快速制定精准的个性化方案。'}, 'metadata': {'emphasized_text_contents': ['应用场景'], 'emphasized_text_tags': ['b'], 'languages': ['zho', 'kor'], 'filetype': 'text/html', 'parent_id': '49135990728f8b24c1cc5b27c61a1f0a', 'url': 'https://hub.baai.ac.cn/view/41733'}}, {'data': {'type': 'Title', 'element_id': '68fef70ae2e8d67346a5ff940cfc8b8a', 'text': '4. 健康数字孪生'}, 'metadata': {'category_depth': 2, 'emphasized_text_contents': ['4. 健康数字孪生'], 'emphasized_text_tags': ['b'], 'languages': ['zho', 'kor'], 'filetype': 'text/html', 'parent_id': 'af971adf1b7b38ebc81f77b81617b430', 'url': 'https://hub.baai.ac.cn/view/41733'}}, {'data': {'type': 'UncategorizedText', 'element_id': '1120337f050461a65abcc8cdc8f17089', 'text': '通过打造患者的虚拟健康模型，LLM智能体实现实时健康监测和预测：'}, 'metadata': {'emphasized_text_contents': ['虚拟健康模型'], 'emphasized_text_tags': ['b'], 'languages': ['zho', 'kor'], 'filetype': 'text/html', 'parent_id': '68fef70ae2e8d67346a5ff940cfc8b8a', 'url': 'https://hub.baai.ac.cn/view/41733'}}, {'data': {'type': 'UncategorizedText', 'element_id': 'ebefa028691d7b3b33b87b4ce8f3a428', 'text': '整合多模态数据（语音、图像、生理数据），构建动态健康模型。'}, 'metadata': {'languages': ['zho', 'kor'], 'filetype': 'text/html', 'parent_id': '68fef70ae2e8d67346a5ff940cfc8b8a', 'url': 'https://hub.baai.ac.cn/view/41733'}}, {'data': {'type': 'UncategorizedText', 'element_id': '24d5349a1489542eeb65102f5a03b893', 'text': '精准预测个体健康轨迹，支持提前干预和优化治疗。'}, 'metadata': {'languages': ['zho', 'kor'], 'filetype': 'text/html', 'parent_id': '68fef70ae2e8d67346a5ff940cfc8b8a', 'url': 'https://hub.baai.ac.cn/view/41733'}}, {'data': {'type': 'UncategorizedText', 'element_id': 'abd5db3b7b2d9291e68eabfa5b6fc151', 'text': '意义：健康数字孪生推动了精准医疗，让每个人拥有自己的“健康守护者”。'}, 'metadata': {'emphasized_text_contents': ['意义'], 'emphasized_text_tags': ['b'], 'languages': ['zho', 'kor'], 'filetype': 'text/html', 'parent_id': '68fef70ae2e8d67346a5ff940cfc8b8a', 'url': 'https://hub.baai.ac.cn/view/41733'}}, {'data': {'type': 'Title', 'element_id': 'ad034d33a114c9283217caf1c8136556', 'text': '未来展望：'}, 'metadata': {'category_depth': 2, 'emphasized_text_contents': ['未来展望：'], 'emphasized_text_tags': ['b'], 'languages': ['zho', 'kor'], 'filetype': 'text/html', 'parent_id': 'af971adf1b7b38ebc81f77b81617b430', 'url': 'https://hub.baai.ac.cn/view/41733'}}, {'data': {'type': 'Title', 'element_id': '6d77b9290e74b2b3bfbbaeb908f67da5', 'text': '从助手到合作伙伴'}, 'metadata': {'category_depth': 2, 'emphasized_text_contents': ['从助手到合作伙伴'], 'emphasized_text_tags': ['b'], 'languages': ['zho', 'kor'], 'filetype': 'text/html', 'parent_id': 'af971adf1b7b38ebc81f77b81617b430', 'url': 'https://hub.baai.ac.cn/view/41733'}}, {'data': {'type': 'UncategorizedText', 'element_id': '83ff78000d059ab66b2b32629cef06ee', 'text': '文章指出，智能代理系统的潜力不仅限于医疗从业者：'}, 'metadata': {'emphasized_text_contents': ['智能代理系统的潜力不仅限于医疗从业者'], 'emphasized_text_tags': ['b'], 'languages': ['zho', 'kor'], 'filetype': 'text/html', 'parent_id': '6d77b9290e74b2b3bfbbaeb908f67da5', 'url': 'https://hub.baai.ac.cn/view/41733'}}, {'data': {'type': 'UncategorizedText', 'element_id': '9730831ac284da419b89610e3f1a8f90', 'text': '未来患者可以拥有个人AI助手，管理自己的健康数据，提供提醒和个性化建议，真正实现医疗决策的民主化。'}, 'metadata': {'emphasized_text_contents': ['医疗决策的民主化'], 'emphasized_text_tags': ['b'], 'languages': ['zho', 'kor'], 'filetype': 'text/html', 'parent_id': '6d77b9290e74b2b3bfbbaeb908f67da5', 'url': 'https://hub.baai.ac.cn/view/41733'}}, {'data': {'type': 'UncategorizedText', 'element_id': '191529144e0c41f95dcb507d550a4df3', 'text': '智能代理还能与物理硬件（如诊断成像和医疗机器人）结合，推动医疗自动化水平提升。'}, 'metadata': {'languages': ['zho', 'kor'], 'filetype': 'text/html', 'parent_id': '6d77b9290e74b2b3bfbbaeb908f67da5', 'url': 'https://hub.baai.ac.cn/view/41733'}}, {'data': {'type': 'UncategorizedText', 'element_id': '09fb37a3d6ec2f6c4c0d58257ea67fbf', 'text': '尽管技术发展面临诸多挑战，这些系统为医疗领域的精准、高效和个性化服务带来了革命性的可能。'}, 'metadata': {'languages': ['zho', 'kor'], 'filetype': 'text/html', 'parent_id': '6d77b9290e74b2b3bfbbaeb908f67da5', 'url': 'https://hub.baai.ac.cn/view/41733'}}, {'data': {'type': 'UncategorizedText', 'element_id': '03391dd047754c82c7e344230e5bc33e', 'text': '这篇文章的许多技术和理念与CAMEL-AI的研究方向高度契合。作为专注于Agentic Sytems的应用研究团队，CAMEL-AI也非常感兴趣如何将LLM智能代理系统与实际医疗场景相结合，推动医疗自动化、个性化和高效化。'}, 'metadata': {'languages': ['zho', 'kor'], 'filetype': 'text/html', 'parent_id': '6d77b9290e74b2b3bfbbaeb908f67da5', 'url': 'https://hub.baai.ac.cn/view/41733'}}, {'data': {'type': 'UncategorizedText', 'element_id': 'f9057f715658b9105663eea7ace91f74', 'text': '关于CAMEL AI'}, 'metadata': {'emphasized_text_contents': ['关于CAMEL AI'], 'emphasized_text_tags': ['b'], 'languages': ['zho', 'kor'], 'filetype': 'text/html', 'parent_id': '6d77b9290e74b2b3bfbbaeb908f67da5', 'url': 'https://hub.baai.ac.cn/view/41733'}}, {'data': {'type': 'UncategorizedText', 'element_id': 'c17351b4fa953dde0b9391662d9e2a10', 'text': '\"Finding the Scaling Law of Agents\"'}, 'metadata': {'emphasized_text_contents': ['\"Finding the Scaling Law of Agents\"'], 'emphasized_text_tags': ['b'], 'languages': ['zho', 'kor'], 'filetype': 'text/html', 'parent_id': '6d77b9290e74b2b3bfbbaeb908f67da5', 'url': 'https://hub.baai.ac.cn/view/41733'}}, {'data': {'type': 'UncategorizedText', 'element_id': 'e4009aa10f7a6399c9653284e5bc5d52', 'text': 'CAMEL AI (https://www.camel-ai.org) 是一个致力于构建基于大语言模型（LLMs）的多智能体系统的开源平台，旨在推动人工智能的发展。就像AI领域的“沙漠之舟”，CAMEL不仅在信息的广袤领域里稳步前行，更为实现AGI探索出一条前沿之路。CAMEL框架是最早基于ChatGPT的autonomous agents的知名项目，已被NeurlPS 2023录用。'}, 'metadata': {'languages': ['zho', 'kor'], 'filetype': 'text/html', 'parent_id': '6d77b9290e74b2b3bfbbaeb908f67da5', 'url': 'https://hub.baai.ac.cn/view/41733'}}, {'data': {'type': 'UncategorizedText', 'element_id': 'b1438d4558ab64ab39812a57c9fc27e4', 'text': 'CAMEL AI框架设计上极具灵活性与模块化，包含多种智能体实现、专业领域提示示例以及AI数据探索功能等模块，适应各种高效决策与复杂数据处理需求。通过协作运作的智能体队列，CAMEL AI不仅在金融、零售、医疗等领域展示出强大的适用性和创新性，还大大提升了自适应能力。这一系统将单一智能体的职能拓展至多智能体协作，成为真正的“AI团队”，共同驱动复杂任务的完成。'}, 'metadata': {'languages': ['zho', 'kor'], 'filetype': 'text/html', 'parent_id': '6d77b9290e74b2b3bfbbaeb908f67da5', 'url': 'https://hub.baai.ac.cn/view/41733'}}, {'data': {'type': 'UncategorizedText', 'element_id': 'ed04308e7d1bc249d1b0c9d2031a8790', 'text': 'CAMEL AI正向着AGI的终极目标稳步迈进，为各行各业带来全新视角和无限可能。'}, 'metadata': {'languages': ['zho', 'kor'], 'filetype': 'text/html', 'parent_id': '6d77b9290e74b2b3bfbbaeb908f67da5', 'url': 'https://hub.baai.ac.cn/view/41733'}}, {'data': {'type': 'UncategorizedText', 'element_id': 'ee11b56b8d2bf32179d488986cc6caad', 'text': 'CAMEL AI论文题目：CAMEL: Communicative Agentsfor “Mind” Exploration of Large Scale Language Model Society'}, 'metadata': {'emphasized_text_contents': ['CAMEL AI论文题目：'], 'emphasized_text_tags': ['b'], 'languages': ['zho', 'kor'], 'filetype': 'text/html', 'parent_id': '6d77b9290e74b2b3bfbbaeb908f67da5', 'url': 'https://hub.baai.ac.cn/view/41733'}}, {'data': {'type': 'UncategorizedText', 'element_id': '72bb1c50ba920669f600b3d1d8856770', 'text': '论文链接：https://arxiv.org/abs/2303.17760'}, 'metadata': {'emphasized_text_contents': ['论文链接：'], 'emphasized_text_tags': ['b'], 'languages': ['zho', 'kor'], 'filetype': 'text/html', 'parent_id': '6d77b9290e74b2b3bfbbaeb908f67da5', 'url': 'https://hub.baai.ac.cn/view/41733'}}, {'data': {'type': 'UncategorizedText', 'element_id': 'b8caca47a1140ce55f728d1f81dcc6c0', 'text': '代码链接：https://github.com/camel-ai/camel'}, 'metadata': {'emphasized_text_contents': ['代码链接：'], 'emphasized_text_tags': ['b'], 'languages': ['zho', 'kor'], 'filetype': 'text/html', 'parent_id': '6d77b9290e74b2b3bfbbaeb908f67da5', 'url': 'https://hub.baai.ac.cn/view/41733'}}, {'data': {'type': 'UncategorizedText', 'element_id': 'd659c01bb6d1d03d104328d85413996c', 'text': '项目主页：https://www.camel-ai.org/'}, 'metadata': {'emphasized_text_contents': ['项目主页：'], 'emphasized_text_tags': ['b'], 'languages': ['zho', 'kor'], 'filetype': 'text/html', 'parent_id': '6d77b9290e74b2b3bfbbaeb908f67da5', 'url': 'https://hub.baai.ac.cn/view/41733'}}, {'data': {'type': 'UncategorizedText', 'element_id': '5f8a2b24837a72c331cefdd412691bce', 'text': 'CAMEL微信群'}, 'metadata': {'languages': ['zho', 'kor'], 'filetype': 'text/html', 'parent_id': '6d77b9290e74b2b3bfbbaeb908f67da5', 'url': 'https://hub.baai.ac.cn/view/41733'}}, {'data': {'type': 'UncategorizedText', 'element_id': 'ca8788ac0cced858bb55e9dfc31b29cb', 'text': '加入CAMEL微信群，请添加CAMEL官方微信号CamelAIOrg，会有工作人员通过您的好友申请并邀请您加入我们的微信群～'}, 'metadata': {'languages': ['zho', 'kor'], 'filetype': 'text/html', 'parent_id': '6d77b9290e74b2b3bfbbaeb908f67da5', 'url': 'https://hub.baai.ac.cn/view/41733'}}, {'data': {'type': 'UncategorizedText', 'element_id': '1bfc523e16f3a5668af93607e42b6a63', 'text': 'Join CAMEL Community'}, 'metadata': {'languages': ['zho', 'kor'], 'filetype': 'text/html', 'parent_id': '6d77b9290e74b2b3bfbbaeb908f67da5', 'url': 'https://hub.baai.ac.cn/view/41733'}}, {'data': {'type': 'UncategorizedText', 'element_id': '46268cf306b914158d1d5800e78e0131', 'text': 'www.camel-ai.org'}, 'metadata': {'languages': ['zho', 'kor'], 'filetype': 'text/html', 'parent_id': '6d77b9290e74b2b3bfbbaeb908f67da5', 'url': 'https://hub.baai.ac.cn/view/41733'}}, {'data': {'type': 'UncategorizedText', 'element_id': '5c3e39bfe61f0caeb9987fbf58fa6605', 'text': 'github.com/camel-ai/camel'}, 'metadata': {'languages': ['zho', 'kor'], 'filetype': 'text/html', 'parent_id': '6d77b9290e74b2b3bfbbaeb908f67da5', 'url': 'https://hub.baai.ac.cn/view/41733'}}, {'data': {'type': 'UncategorizedText', 'element_id': '6a687da9237cef99f426fc4f6f790178', 'text': 'https://discord.com/invite/CNcNpquyDc'}, 'metadata': {'languages': ['zho', 'kor'], 'filetype': 'text/html', 'parent_id': '6d77b9290e74b2b3bfbbaeb908f67da5', 'url': 'https://hub.baai.ac.cn/view/41733'}}, {'data': {'type': 'UncategorizedText', 'element_id': '71fe22926f380cd34dff1b7fb3def876', 'text': '内容中包含的图片若涉及版权问题，请及时与我们联系删除'}, 'metadata': {'languages': ['zho', 'kor'], 'filetype': 'text/html', 'parent_id': '6d77b9290e74b2b3bfbbaeb908f67da5', 'url': 'https://hub.baai.ac.cn/view/41733'}}, {'data': {'type': 'UncategorizedText', 'element_id': 'e0457b41c687b0fa5ffe33f3892a8a93', 'text': '点赞 收藏 评论 分享到Link'}, 'metadata': {'languages': ['zho', 'kor'], 'filetype': 'text/html', 'parent_id': '6d77b9290e74b2b3bfbbaeb908f67da5', 'url': 'https://hub.baai.ac.cn/view/41733'}}, {'data': {'type': 'UncategorizedText', 'element_id': 'ee653f142edeb1d6543ebea316dd2869', 'text': '举报反馈'}, 'metadata': {'languages': ['zho', 'kor'], 'filetype': 'text/html', 'parent_id': '6d77b9290e74b2b3bfbbaeb908f67da5', 'url': 'https://hub.baai.ac.cn/view/41733'}}, {'data': {'type': 'UncategorizedText', 'element_id': '7b1e83520b2309ba9e38c3789147381e', 'text': '举报类型（必选）'}, 'metadata': {'languages': ['zho', 'kor'], 'filetype': 'text/html', 'parent_id': '6d77b9290e74b2b3bfbbaeb908f67da5', 'url': 'https://hub.baai.ac.cn/view/41733'}}, {'data': {'type': 'ListItem', 'element_id': 'a759b27bc84b5bb477b37c68bbd3a007', 'text': '样式问题'}, 'metadata': {'category_depth': 1, 'languages': ['zho', 'kor'], 'filetype': 'text/html', 'parent_id': '6d77b9290e74b2b3bfbbaeb908f67da5', 'url': 'https://hub.baai.ac.cn/view/41733'}}, {'data': {'type': 'ListItem', 'element_id': '6c50aa430c024d72d61eb286d8c0e8cb', 'text': '涉嫌广告'}, 'metadata': {'category_depth': 1, 'languages': ['zho', 'kor'], 'filetype': 'text/html', 'parent_id': '6d77b9290e74b2b3bfbbaeb908f67da5', 'url': 'https://hub.baai.ac.cn/view/41733'}}, {'data': {'type': 'ListItem', 'element_id': 'ace424f087eb4463d5dbe8c0df131c03', 'text': '内容抄袭'}, 'metadata': {'category_depth': 1, 'languages': ['zho', 'kor'], 'filetype': 'text/html', 'parent_id': '6d77b9290e74b2b3bfbbaeb908f67da5', 'url': 'https://hub.baai.ac.cn/view/41733'}}, {'data': {'type': 'ListItem', 'element_id': '639c1517ba6c484c02d00fd69ad3f5ed', 'text': '内容侵权'}, 'metadata': {'category_depth': 1, 'languages': ['zho', 'kor'], 'filetype': 'text/html', 'parent_id': '6d77b9290e74b2b3bfbbaeb908f67da5', 'url': 'https://hub.baai.ac.cn/view/41733'}}, {'data': {'type': 'ListItem', 'element_id': '1750ac291b7d8e9865c7441b39ab1ca1', 'text': '政治相关'}, 'metadata': {'category_depth': 1, 'languages': ['zho', 'kor'], 'filetype': 'text/html', 'parent_id': '6d77b9290e74b2b3bfbbaeb908f67da5', 'url': 'https://hub.baai.ac.cn/view/41733'}}, {'data': {'type': 'ListItem', 'element_id': '350e0e7e0350714765ee0ee7d969d6e4', 'text': '内容涉黄'}, 'metadata': {'category_depth': 1, 'languages': ['zho', 'kor'], 'filetype': 'text/html', 'parent_id': '6d77b9290e74b2b3bfbbaeb908f67da5', 'url': 'https://hub.baai.ac.cn/view/41733'}}, {'data': {'type': 'ListItem', 'element_id': '8495a5e54e82e5b0a71b3a2289ea85fd', 'text': '其他'}, 'metadata': {'category_depth': 1, 'languages': ['zho', 'kor'], 'filetype': 'text/html', 'parent_id': '6d77b9290e74b2b3bfbbaeb908f67da5', 'url': 'https://hub.baai.ac.cn/view/41733'}}, {'data': {'type': 'UncategorizedText', 'element_id': 'ba4ebd6deb2868da96322d9d7e06b7c0', 'text': '举报详情（选填）'}, 'metadata': {'languages': ['zho', 'kor'], 'filetype': 'text/html', 'parent_id': '6d77b9290e74b2b3bfbbaeb908f67da5', 'url': 'https://hub.baai.ac.cn/view/41733'}}, {'data': {'type': 'UncategorizedText', 'element_id': 'b771503f3c278d3966659e7b5bc9f0a0', 'text': '0/200'}, 'metadata': {'languages': ['zho', 'kor'], 'filetype': 'text/html', 'parent_id': '6d77b9290e74b2b3bfbbaeb908f67da5', 'url': 'https://hub.baai.ac.cn/view/41733'}}, {'data': {'type': 'UncategorizedText', 'element_id': '04bf425ca9ca7cb487a74be4b91e1fa6', 'text': '沙发等你来抢'}, 'metadata': {'languages': ['zho', 'kor'], 'filetype': 'text/html', 'parent_id': '6d77b9290e74b2b3bfbbaeb908f67da5', 'url': 'https://hub.baai.ac.cn/view/41733'}}, {'data': {'type': 'UncategorizedText', 'element_id': '03198010d6fd2467022b5501c47fe4bb', 'text': '去评论'}, 'metadata': {'languages': ['zho', 'kor'], 'filetype': 'text/html', 'parent_id': '6d77b9290e74b2b3bfbbaeb908f67da5', 'url': 'https://hub.baai.ac.cn/view/41733'}}, {'data': {'type': 'Title', 'element_id': '855d88b95811a96845e8b85fd23440d7', 'text': '评论'}, 'metadata': {'category_depth': 2, 'languages': ['zho', 'kor'], 'filetype': 'text/html', 'parent_id': 'af971adf1b7b38ebc81f77b81617b430', 'url': 'https://hub.baai.ac.cn/view/41733'}}, {'data': {'type': 'UncategorizedText', 'element_id': 'e2128e0bd0a4072891a68970860bf636', 'text': '请先 登录 后发表评论～'}, 'metadata': {'languages': ['zho', 'kor'], 'filetype': 'text/html', 'parent_id': '855d88b95811a96845e8b85fd23440d7', 'url': 'https://hub.baai.ac.cn/view/41733'}}, {'data': {'type': 'UncategorizedText', 'element_id': 'a4522e3cd1be591c1181be06f18dce29', 'text': '沙发等你来抢'}, 'metadata': {'languages': ['zho', 'kor'], 'filetype': 'text/html', 'parent_id': '855d88b95811a96845e8b85fd23440d7', 'url': 'https://hub.baai.ac.cn/view/41733'}}]}\n"
     ]
    }
   ],
   "source": [
    "staged_element = uio.stage_elements(elements=elements,stage_type=\"stage_for_baseplate\")\n",
    "print(staged_element)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下是使用 **Unstructured IO 模块** 的基础指南。想要了解更多高级用法，请参考具体方法的文档以及相关资源。[{u}`Unstructured IO Documentation`](https://unstructured-io.github.io/unstructured/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Apify Reader** \n",
    "\n",
    "Apify Reader 提供了一个 Python 接口，用于与 Apify 平台交互，以实现 Web 工作流的自动化。你可以在这里获取所需要的[APIKEY](https://console.apify.com/settings/integrations)。\n",
    "\n",
    "初始化客户端，设置所需参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeEncodeError",
     "evalue": "'ascii' codec can't encode characters in position 7-8: ordinal not in range(128)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeEncodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      4\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAPIFY_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m你的apikey\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 6\u001b[0m apify \u001b[38;5;241m=\u001b[39m \u001b[43mApify\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m run_input \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstartUrls\u001b[39m\u001b[38;5;124m\"\u001b[39m: [{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124murl\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.camel-ai.org/\u001b[39m\u001b[38;5;124m\"\u001b[39m}],\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaxCrawlDepth\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaxCrawlPages\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     12\u001b[0m }\n\u001b[1;32m     13\u001b[0m actor_result \u001b[38;5;241m=\u001b[39m apify\u001b[38;5;241m.\u001b[39mrun_actor(\n\u001b[1;32m     14\u001b[0m     actor_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapify/website-content-crawler\u001b[39m\u001b[38;5;124m\"\u001b[39m, run_input\u001b[38;5;241m=\u001b[39mrun_input)\n",
      "File \u001b[0;32m/workspaces/handy-multi-agent/camel/camel/utils/commons.py:360\u001b[0m, in \u001b[0;36mapi_keys_required.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m missing_keys:\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    356\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing or empty required API keys in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    357\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menvironment variables: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(missing_keys)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    358\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can obtain the API key from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey_way\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    359\u001b[0m     )\n\u001b[0;32m--> 360\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspaces/handy-multi-agent/camel/camel/loaders/apify_reader.py:42\u001b[0m, in \u001b[0;36mApify.__init__\u001b[0;34m(self, api_key)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mapify_client\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ApifyClient\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_api_key \u001b[38;5;241m=\u001b[39m api_key \u001b[38;5;129;01mor\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAPIFY_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 42\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient \u001b[38;5;241m=\u001b[39m \u001b[43mApifyClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_api_key\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/camel/lib/python3.10/site-packages/apify_client/client.py:132\u001b[0m, in \u001b[0;36mApifyClient.__init__\u001b[0;34m(self, token, api_url, max_retries, min_delay_between_retries_millis, timeout_secs)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    124\u001b[0m     token,\n\u001b[1;32m    125\u001b[0m     api_url\u001b[38;5;241m=\u001b[39mapi_url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    128\u001b[0m     timeout_secs\u001b[38;5;241m=\u001b[39mtimeout_secs,\n\u001b[1;32m    129\u001b[0m )\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstats \u001b[38;5;241m=\u001b[39m Statistics()\n\u001b[0;32m--> 132\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhttp_client \u001b[38;5;241m=\u001b[39m \u001b[43mHTTPClient\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmin_delay_between_retries_millis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmin_delay_between_retries_millis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout_secs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout_secs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/camel/lib/python3.10/site-packages/apify_client/_http_client.py:62\u001b[0m, in \u001b[0;36m_BaseHTTPClient.__init__\u001b[0;34m(self, token, max_retries, min_delay_between_retries_millis, timeout_secs, stats)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     headers[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAuthorization\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBearer \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtoken\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 62\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhttpx_client \u001b[38;5;241m=\u001b[39m \u001b[43mhttpx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_secs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhttpx_async_client \u001b[38;5;241m=\u001b[39m httpx\u001b[38;5;241m.\u001b[39mAsyncClient(headers\u001b[38;5;241m=\u001b[39mheaders, follow_redirects\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, timeout\u001b[38;5;241m=\u001b[39mtimeout_secs)\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstats \u001b[38;5;241m=\u001b[39m stats \u001b[38;5;129;01mor\u001b[39;00m Statistics()\n",
      "File \u001b[0;32m/opt/conda/envs/camel/lib/python3.10/site-packages/httpx/_client.py:662\u001b[0m, in \u001b[0;36mClient.__init__\u001b[0;34m(self, auth, params, headers, cookies, verify, cert, trust_env, http1, http2, proxy, mounts, timeout, follow_redirects, limits, max_redirects, event_hooks, base_url, transport, default_encoding)\u001b[0m\n\u001b[1;32m    639\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    640\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    641\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    660\u001b[0m     default_encoding: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m typing\u001b[38;5;241m.\u001b[39mCallable[[\u001b[38;5;28mbytes\u001b[39m], \u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    661\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 662\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    663\u001b[0m \u001b[43m        \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    664\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    665\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    666\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcookies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcookies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    667\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mevent_hooks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevent_hooks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbase_url\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_url\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrust_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdefault_encoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_encoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m http2:\n\u001b[1;32m    677\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/envs/camel/lib/python3.10/site-packages/httpx/_client.py:210\u001b[0m, in \u001b[0;36mBaseClient.__init__\u001b[0;34m(self, auth, params, headers, cookies, timeout, follow_redirects, max_redirects, event_hooks, base_url, trust_env, default_encoding)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_auth(auth)\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_params \u001b[38;5;241m=\u001b[39m QueryParams(params)\n\u001b[0;32m--> 210\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheaders \u001b[38;5;241m=\u001b[39m \u001b[43mHeaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cookies \u001b[38;5;241m=\u001b[39m Cookies(cookies)\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout \u001b[38;5;241m=\u001b[39m Timeout(timeout)\n",
      "File \u001b[0;32m/opt/conda/envs/camel/lib/python3.10/site-packages/httpx/_models.py:156\u001b[0m, in \u001b[0;36mHeaders.__init__\u001b[0;34m(self, headers, encoding)\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m headers\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    155\u001b[0m         bytes_key \u001b[38;5;241m=\u001b[39m _normalize_header_key(k, encoding)\n\u001b[0;32m--> 156\u001b[0m         bytes_value \u001b[38;5;241m=\u001b[39m \u001b[43m_normalize_header_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_list\u001b[38;5;241m.\u001b[39mappend((bytes_key, bytes_key\u001b[38;5;241m.\u001b[39mlower(), bytes_value))\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m headers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/envs/camel/lib/python3.10/site-packages/httpx/_models.py:82\u001b[0m, in \u001b[0;36m_normalize_header_value\u001b[0;34m(value, encoding)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHeader value must be str or bytes, not \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(value)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 82\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvalue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mascii\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mUnicodeEncodeError\u001b[0m: 'ascii' codec can't encode characters in position 7-8: ordinal not in range(128)"
     ]
    }
   ],
   "source": [
    "from camel.loaders import Apify\n",
    "import os\n",
    "\n",
    "os.environ[\"APIFY_API_KEY\"] = \"你的apikey\"\n",
    "\n",
    "apify = Apify()\n",
    "\n",
    "run_input = {\n",
    "    \"startUrls\": [{\"url\": \"https://www.camel-ai.org/\"}],\n",
    "    \"maxCrawlDepth\": 0,\n",
    "    \"maxCrawlPages\": 1,\n",
    "}\n",
    "actor_result = apify.run_actor(\n",
    "    actor_id=\"apify/website-content-crawler\", run_input=run_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "检索结果数据库 ID 并使用 get_dataset_items 方法访问它。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'url': 'https://www.camel-ai.org/', 'crawl': {'loadedUrl': 'https://www.camel-ai.org/', 'loadedTime': '2025-03-31T06:24:31.763Z', 'referrerUrl': 'https://www.camel-ai.org/', 'depth': 0, 'httpStatusCode': 200}, 'metadata': {'canonicalUrl': 'https://www.camel-ai.org/', 'title': 'CAMEL-AI Finding the Scaling Laws of Agents', 'description': 'CAMEL-AI.org is the 1st LLM multi-agent framework and an open-source community dedicated to finding the scaling law of agents.', 'author': None, 'keywords': None, 'languageCode': 'en', 'openGraph': [{'property': 'og:title', 'content': 'CAMEL-AI Finding the Scaling Laws of Agents'}, {'property': 'og:description', 'content': 'CAMEL-AI.org is the 1st LLM multi-agent framework and an open-source community dedicated to finding the scaling law of agents.'}, {'property': 'twitter:title', 'content': 'CAMEL-AI Finding the Scaling Laws of Agents'}, {'property': 'twitter:description', 'content': 'CAMEL-AI.org is the 1st LLM multi-agent framework and an open-source community dedicated to finding the scaling law of agents.'}, {'property': 'og:type', 'content': 'website'}], 'jsonLd': None, 'headers': {'date': 'Mon, 31 Mar 2025 06:24:26 GMT', 'content-type': 'text/html', 'cf-ray': '928dc384abefdebd-PDX', 'cf-cache-status': 'HIT', 'age': '12886', 'content-encoding': 'gzip', 'last-modified': 'Mon, 31 Mar 2025 01:58:56 GMT', 'strict-transport-security': 'max-age=31536000', 'surrogate-control': 'max-age=432000', 'surrogate-key': 'www.camel-ai.org 6659a154491a54a40551bc78 pageId:6686a2bcb7ece5fb40457491 679b765c27842bdba036423f 6659a155491a54a40551bd7e', 'x-lambda-id': '299c8f1f-600e-46f9-bed0-366b1f3ab2bc', 'vary': 'Accept-Encoding', 'set-cookie': '_cfuvid=OLIU0n9tIRjhs5M47jzwWb5Nr2aoL1y7kQJ20fJVCZ8-1743402266410-0.0.1.1-604800000; path=/; domain=.cdn.webflow.com; HttpOnly; Secure; SameSite=None', 'alt-svc': 'h3=\":443\"; ma=86400', 'x-cluster-name': 'us-west-2-prod-hosting-red', 'x-firefox-spdy': 'h2'}}, 'screenshotUrl': None, 'text': 'CAMEL-AI Finding the Scaling Laws of Agents\\nWe are Building A HuggingFace-like Community for AI Agent Builders\\nBuilding Multi-Agent\\nSystems for Wo_\\nCAMEL-AI is a open-source community for finding the scaling laws of agents for data generation, world simulation, task automation.', 'markdown': '# CAMEL-AI Finding the Scaling Laws of Agents\\n\\nWe are Building A HuggingFace-like Community for AI Agent Builders\\n\\n## Building Multi-Agent  \\nSystems for Wo\\\\_\\n\\nCAMEL-AI is a open-source community for finding the scaling laws of agents for data generation, world simulation, task automation.'}]\n"
     ]
    }
   ],
   "source": [
    "dataset_result = apify.get_dataset_items(\n",
    "    dataset_id=actor_result[\"defaultDatasetId\"]\n",
    ")\n",
    "\n",
    "print(dataset_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个函数通常用于从Apify平台获取爬取或处理后的数据，以便在后续程序中使用这些数据。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Firecrawl Reader** \n",
    "\n",
    "你可以从[此处](https://www.firecrawl.dev/)获得你的FirecrawlAPI\n",
    "\n",
    "Firecrawl Reader 提供了一个 Python 接口来与 Firecrawl API 交互，允许用户将网站转换为大型语言模型可读的 markdown 格式。\n",
    "\n",
    "初始化客户端并设置要从中检索信息的 URL。当状态为 “completed” 时，信息检索已完成并可供阅读。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed\n"
     ]
    }
   ],
   "source": [
    "from camel.loaders import Firecrawl\n",
    "\n",
    "os.environ[\"FIRECRAWL_API_KEY\"] = \"fc-0a0cf08a2e264256a4094bb4f9fc6ab6\"\n",
    "\n",
    "firecrawl = Firecrawl()\n",
    "\n",
    "response = firecrawl.crawl(url=\"https://baijiahao.baidu.com/s?id=1827966357241680945\")\n",
    "print(response[\"status\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "直接从返回的结果中检索信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "icon\\_voice\\_onicon\\_voice\n",
      "\n",
      "[![到百度首页](https://mbdp01.bdstatic.com/static/landing-pc/img/logo_top.79fdb8c2.png)](https://www.baidu.com/)\n",
      "\n",
      "[百度首页](https://www.baidu.com/)\n",
      "\n",
      "[登录](https://passport.baidu.com/v2/?login&tpl=mn&u=https%3A%2F%2Fbaijiahao.baidu.com%2Fs%3Fid%3D1827966357241680945)\n",
      "\n",
      "本报记者  龚  鸣  白紫微  曲  颂  俞懿春\n",
      "\n",
      "3月28日上午，国家主席习近平在北京人民大会堂会见国际工商界代表，对他们长期致力于对华合作表示赞赏。40余位外资企业全球董事长、首席执行官和商协会代表参加会见。接受本报记者采访的外资企业负责人表示，中国高度重视稳外资工作，持续为外资在华发展营造良好环境。中国坚持全面深化改革、扩大高水平对外开放，在实现经济稳定增长的同时，将创造更多中外合作机遇，为全球经济注入稳定性。\n",
      "\n",
      "“中国的开放是稳步的，也是持续的”\n",
      "\n",
      "习近平主席指出，实践证明，外资企业是中国式现代化的重要参与者，是中国改革开放和创新创造的重要参与者，是中国联通世界、融入经济全球化的重要参与者。外企负责人纷纷表示，在华发展为企业带来丰厚回报，企业不断发展壮大，实现了互利共赢，坚定了深耕中国的信心。\n",
      "\n",
      "“梅赛德斯—奔驰在中国的业务与发展始终得到中国政府的有力支持。我们有幸成为中国对外开放进程中的参与者、受益者和贡献者。”梅赛德斯—奔驰集团股份公司董事会主席康林松表示，中国是梅赛德斯—奔驰全球最大的市场，是集团电动化和智能化转型的关键所在。“此次会见让我感受到中国政府对扩大高水平对外开放、稳定世界经济的高度重视。今年恰逢梅赛德斯—奔驰在华开展生产和研发20周年，我们将继续扩大在华投入，在中国市场共创共享发展机遇。”\n",
      "\n",
      "赛诺菲集团首席执行官韩保罗表示，自1982年进入中国以来，赛诺菲不断深化在华布局，累计引入60余款创新药物与疫苗产品，建设3个高水平生产制造基地和四大研发中心，构建起覆盖研发、生产与运营的本土化端到端全产业链体系。去年12月，赛诺菲宣布将投资约10亿欧元在北京新建胰岛素生产基地。韩保罗说：“随着中国医疗体系不断升级，我们看到了跨国公司与本土企业深度合作的巨大潜力。”\n",
      "\n",
      "“中国的开放是稳步的，也是持续的，渣打集团将继续深耕中国市场。”渣打集团行政总裁温拓思说，中国经济发展态势向新向好、科技实力显著提升、企业出海步伐提速，渣打集团中国相关业务迎来更多机遇。集团深度参与人民币跨境支付系统建设，在全球34个市场提供人民币服务。渣打中国获准开展中国证券投资基金托管、粤港澳大湾区“跨境理财通”试点等业务。去年3月，渣打证券(中国)有限公司作为中国首家新设外商独资券商也正式展业。\n",
      "\n",
      "泰佩思琦集团亚太区总裁、蔻驰亚太区总裁兼首席执行官杨葆焱表示，中国市场的吸引力不断增强，对外开放的力度持续加大，营商环境也在不断优化，为全球企业提供了更加广阔的发展空间。一系列稳外资政策的出台持续释放市场活力，拓展了合作空间，进一步提振了外资企业在华发展信心。\n",
      "\n",
      "“以高技术、高效能推动高质量增长”\n",
      "\n",
      "“多年来，中国一直是世界经济增长的主要贡献者和稳定锚，正在全面推进中国式现代化，事业舞台大，市场前景广，政策预期稳，安全形势好，正是有利于外资企业投资兴业的一方沃土。”习近平主席在会见中重申，中国推进改革开放坚定不移，开放的大门只会越开越大，利用外资的政策没有变也不会变。外企负责人积极评价中国发展成就与市场优势，希望继续与中国合作伙伴分享机遇、携手共进。\n",
      "\n",
      "宝马集团董事长齐普策表示，中国通过持续深化改革开放，不仅跃居全球第二大经济体，更在数字创新、绿色技术等领域成为全球领跑者。中国将2025年经济增长目标设为5%左右，再次表明了实现经济稳健增长的决心。“作为全球第二大经济体，中国争做创新先行者，尤其在人工智能、先进制造等前沿领域成绩斐然，为经济发展注入新的动力。”齐普策说，中国持续优化营商环境，进一步坚定了宝马在华深耕的信心。“我们将持续对华投资，不断拓展在华业务布局。”\n",
      "\n",
      "“面对增长从何而来的难题，中国给出了答案：以高技术、高效能推动高质量增长。”西门子股份公司董事会主席、总裁兼首席执行官博乐仁表示，中国正积极采取行动，推动经济结构转型升级，加快发展新质生产力，持续扩大高水平对外开放，尤其是中国的创新正不断给世界带来惊喜。\n",
      "\n",
      "高通公司中国区董事长孟樸表示，在科技创新领域，高通见证并参与了中国企业从“跟随”到“引领”的转变，特别是在5G与人工智能等方面。中国目前通过提振消费拉动经济增长，前瞻布局6G及具身智能等未来产业，大力发展智能网联新能源汽车，十分契合高通及合作伙伴的发展布局。“我们对中国经济增长潜力充满信心。”孟樸说，高通正持续扩大在中国的多元化布局，与合作伙伴共同探索新的增长机遇。\n",
      "\n",
      "20多年来，澳大利亚福德士河集团金属业务首席执行官狄诺多次访问中国，感受到中国开放合作、转型发展的活力。“与中国供应商的合作让我了解到中方对知识产权的重视，这也反映了中国营商环境的改善。”狄诺说，中国加快发展新质生产力，带动制造业高质量发展，福德士河集团将从中受益。\n",
      "\n",
      "“中国将继续为世界经济增长提供动力”\n",
      "\n",
      "习近平主席倡导要共同维护多边贸易体制、共同维护全球产业链供应链稳定、共同维护开放合作的国际环境，推动经济全球化朝着正确方向发展。外资企业对中国积极参与全球经济治理行动表示赞赏，期待各方共同努力，为世界经济发展作出新的贡献。\n",
      "\n",
      "在多次访华过程中，齐普策与中国政府部门、行业企业广泛交流，切身感受到中国为推动全球合作所付出的努力。“只要秉持合作精神，就能激发新的增长潜力。”他说，中国在全球供应链和消费市场中的地位深刻影响着国际贸易和投资布局。中国在科技创新领域不断实现突破，加速带动全球产业升级，激发全球科技进步新浪潮。“宝马始终秉持开放合作的理念，坚定支持多边主义和自由贸易。各方共同践行多边主义，将最终惠及企业、消费者，并有利于世界经济的繁荣。”\n",
      "\n",
      "“中国一直是世界经济发展的稳定器和动力源，其庞大的市场规模和发展潜力为高通等众多企业提供了增长空间。”孟樸说，对高通来说，中国不仅是全球重要的市场，更是携手合作伙伴实现技术落地、生态构建和全球化发展的重要前沿。他表示，中国优化外资准入规则、加强知识产权保护等政策，为跨国企业提供了可预期的长期发展环境。\n",
      "\n",
      "汇丰控股集团行政总裁艾桥智说，长远来看，中国将作为一个持续繁荣的经济体，处于全球贸易投资的核心，并走在创新发展的前沿。艾桥智以不久前参加的中国发展高层论坛2025年年会为例说，合作与对话在当下尤为可贵。中国举办的相关论坛成为各方互相学习、发掘合作机遇的重要平台。“我们相信，中国将继续为世界经济增长提供动力。”\n",
      "\n",
      "“西门子在华发展超过150年，深度融入中国经济的方方面面。我们将持续投入中国市场，支持中国发展。我相信，这也是众多跨国企业的共同心声。”博乐仁说，只有并肩同行，才能化挑战为机遇，创造一个共同繁荣、更加可持续发展的美好未来。\n",
      "\n",
      "《 人民日报 》( 2025年03月30日 02 版)\n",
      "\n",
      "举报/反馈\n",
      "\n",
      "相关搜索\n",
      "\n",
      "[共享与创新](https://baidu.com/s?word=%E5%85%B1%E4%BA%AB%E4%B8%8E%E5%88%9B%E6%96%B0&rsv_dl=feed_landingpage_rs&from=1020853i&rsf=2 \"共享与创新\") [共谋发展新篇章](https://baidu.com/s?word=%E5%85%B1%E8%B0%8B%E5%8F%91%E5%B1%95%E6%96%B0%E7%AF%87%E7%AB%A0&rsv_dl=feed_landingpage_rs&from=1020853i&rsf=2 \"共谋发展新篇章\") [开放合作共赢共享](https://baidu.com/s?word=%E5%BC%80%E6%94%BE%E5%90%88%E4%BD%9C%E5%85%B1%E8%B5%A2%E5%85%B1%E4%BA%AB&rsv_dl=feed_landingpage_rs&from=1020853i&rsf=2 \"开放合作共赢共享\") [要构建 的战略新兴产业增长引擎](https://baidu.com/s?word=%E8%A6%81%E6%9E%84%E5%BB%BA%20%E7%9A%84%E6%88%98%E7%95%A5%E6%96%B0%E5%85%B4%E4%BA%A7%E4%B8%9A%E5%A2%9E%E9%95%BF%E5%BC%95%E6%93%8E&rsv_dl=feed_landingpage_rs&from=1020853i&rsf=2 \"要构建 的战略新兴产业增长引擎\") [构建新格局共享新机遇](https://baidu.com/s?word=%E6%9E%84%E5%BB%BA%E6%96%B0%E6%A0%BC%E5%B1%80%E5%85%B1%E4%BA%AB%E6%96%B0%E6%9C%BA%E9%81%87&rsv_dl=feed_landingpage_rs&from=1020853i&rsf=2 \"构建新格局共享新机遇\") [共享共创共赢](https://baidu.com/s?word=%E5%85%B1%E4%BA%AB%E5%85%B1%E5%88%9B%E5%85%B1%E8%B5%A2&rsv_dl=feed_landingpage_rs&from=1020853i&rsf=2 \"共享共创共赢\")\n",
      "\n",
      "## 评论\n",
      "\n",
      "发表\n",
      "\n",
      "[![](https://avatar.bdstatic.com/it/u=3729432280,1212171024&fm=3012&app=3012&autime=1742966174&size=b200,200)](https://author.baidu.com/home?from=bjh_article&app_id=1537195104256385)\n",
      "\n",
      "[人民网](https://author.baidu.com/home?from=bjh_article&app_id=1537195104256385) 4012万获赞 580万粉丝\n",
      "\n",
      "报道全球 传播中国人民网股份有限公司\n",
      "\n",
      "人民网官方账号\n",
      "\n",
      "关注\n",
      "\n",
      "## 作者最新文章\n",
      "\n",
      "[![](https://t11.baidu.com/it/u=1462658692,262119751&fm=30&app=106&f=JPEG?w=312&h=208&s=9C85865A42FDBA7B5E6317BF02008008)](https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_8653236156266354191%22%7D&n_type=1&p_from=3)\n",
      "\n",
      "[**走近七位在逆境中奋起的共产党人**](https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_8653236156266354191%22%7D&n_type=1&p_from=3)\n",
      "\n",
      "1分钟前\n",
      "\n",
      "[![](https://t11.baidu.com/it/u=293516286,262119254&fm=30&app=106&f=JPEG?w=312&h=208&s=ED70A252FDFF629E1454344F0300D0B1)](https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9535435873704851919%22%7D&n_type=1&p_from=3)\n",
      "\n",
      "[**“村超”背后的理论启示**](https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9535435873704851919%22%7D&n_type=1&p_from=3)\n",
      "\n",
      "10分钟前4阅读\n",
      "\n",
      "[![](https://t11.baidu.com/it/u=957795261,262119254&fm=30&app=106&f=JPEG?w=450&h=253&s=0320F0050A5572DE6E05987003005063)](https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_8847940411170291107%22%7D&n_type=1&p_from=3)\n",
      "\n",
      "[**探究中国文化的独有特质及发展前途**](https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_8847940411170291107%22%7D&n_type=1&p_from=3)\n",
      "\n",
      "10分钟前3阅读\n",
      "\n",
      "## 相关推荐\n",
      "\n",
      "[![](https://t12.baidu.com/it/u=1082017507,262103448&fm=30&app=106&f=JPEG?w=312&h=208&s=ED0A07D1D6D939CC7811C8E10300E093)](https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9337807596545468005%22%7D&n_type=1&p_from=4)\n",
      "\n",
      "[**世界大学排名100强：北京大学第14，清华大学第20**](https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9337807596545468005%22%7D&n_type=1&p_from=4)\n",
      "\n",
      "[城市晓宇](https://author.baidu.com/home?from=bjh_article&app_id=1724182891704608) [1评论](https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9337807596545468005%22%7D&n_type=1&p_from=4)\n",
      "\n",
      "[![](https://t11.baidu.com/it/u=3235024753,262063956&fm=30&app=106&f=JPEG?w=312&h=208&s=4E106F8002020AE71089E08F0300C0C3)](https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_8616240158405949534%22%7D&n_type=1&p_from=4)\n",
      "\n",
      "[**10万级纯电SUV这么能装？五菱缤果Plus实测：三个惊喜一个遗憾**](https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_8616240158405949534%22%7D&n_type=1&p_from=4)\n",
      "\n",
      "[车风迷的故事](https://author.baidu.com/home?from=bjh_article&app_id=1659585217312275) [1评论](https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_8616240158405949534%22%7D&n_type=1&p_from=4)\n",
      "\n",
      "[![](https://t10.baidu.com/it/u=3310095063,262096134&fm=30&app=106&f=JPEG?w=312&h=208&s=58C7911AD2A077A7808E8FC4030070AF)](https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9441071679800052522%22%7D&n_type=1&p_from=4)\n",
      "\n",
      "[**寒潮真的要来了！本周后期这些地方降温或超20℃！**](https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9441071679800052522%22%7D&n_type=1&p_from=4)\n",
      "\n",
      "[手机中国网](https://author.baidu.com/home?from=bjh_article&app_id=1549585234806286) [1评论](https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9441071679800052522%22%7D&n_type=1&p_from=4)\n",
      "\n",
      "[![](https://t12.baidu.com/it/u=3492775413,262065394&fm=30&app=106&f=JPEG?w=312&h=208&s=D41A96F246483F45669C95B403009093)](https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9194837721460478408%22%7D&n_type=1&p_from=4)\n",
      "\n",
      "[**河南理工大学专升本专业「汇总与解读」值得报考吗？**](https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9194837721460478408%22%7D&n_type=1&p_from=4)\n",
      "\n",
      "[正能量学习笔记分享](https://author.baidu.com/home?from=bjh_article&app_id=1791493301631441)\n",
      "\n",
      "[![](https://t10.baidu.com/it/u=771834877,262071277&fm=30&app=106&f=JPEG?w=312&h=208&s=16A2E9A26CD38BF504A9B0040300A002)](https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9729405113696815456%22%7D&n_type=1&p_from=4)\n",
      "\n",
      "[**CBA一场定排名！10场都很精彩，辽宁最好第3最差第6，广东最好第4**](https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9729405113696815456%22%7D&n_type=1&p_from=4)\n",
      "\n",
      "[老吴说体育](https://author.baidu.com/home?from=bjh_article&app_id=1553763485935061) [2评论](https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9729405113696815456%22%7D&n_type=1&p_from=4)\n",
      "\n",
      "换一换\n",
      "\n",
      "- 1 [距深圳市约170公里发现1亿吨油田](https://www.baidu.com/s?wd=%E8%B7%9D%E6%B7%B1%E5%9C%B3%E5%B8%82%E7%BA%A6170%E5%85%AC%E9%87%8C%E5%8F%91%E7%8E%B01%E4%BA%BF%E5%90%A8%E6%B2%B9%E7%94%B0&sa=fyb_news_feedpc&rsv_dl=fyb_news_feedpc&from=feedpc) 热\n",
      "- 2 [副部段成刚落马 老同事3天前刚被查](https://www.baidu.com/s?wd=%E5%89%AF%E9%83%A8%E6%AE%B5%E6%88%90%E5%88%9A%E8%90%BD%E9%A9%AC+%E8%80%81%E5%90%8C%E4%BA%8B3%E5%A4%A9%E5%89%8D%E5%88%9A%E8%A2%AB%E6%9F%A5&sa=fyb_news_feedpc&rsv_dl=fyb_news_feedpc&from=feedpc) 热\n",
      "- 3 [AI时代 创作何为](https://www.baidu.com/s?wd=AI%E6%97%B6%E4%BB%A3+%E5%88%9B%E4%BD%9C%E4%BD%95%E4%B8%BA&sa=fyb_news_feedpc&rsv_dl=fyb_news_feedpc&from=feedpc)\n",
      "- 4 [赴缅中国公羊救援队说现场非常糟糕](https://www.baidu.com/s?wd=%E8%B5%B4%E7%BC%85%E4%B8%AD%E5%9B%BD%E5%85%AC%E7%BE%8A%E6%95%91%E6%8F%B4%E9%98%9F%E8%AF%B4%E7%8E%B0%E5%9C%BA%E9%9D%9E%E5%B8%B8%E7%B3%9F%E7%B3%95&sa=fyb_news_feedpc&rsv_dl=fyb_news_feedpc&from=feedpc) 热\n",
      "- 5 [多地争发购房补贴 3孩家庭可补20万](https://www.baidu.com/s?wd=%E5%A4%9A%E5%9C%B0%E4%BA%89%E5%8F%91%E8%B4%AD%E6%88%BF%E8%A1%A5%E8%B4%B4+3%E5%AD%A9%E5%AE%B6%E5%BA%AD%E5%8F%AF%E8%A1%A520%E4%B8%87&sa=fyb_news_feedpc&rsv_dl=fyb_news_feedpc&from=feedpc) 热\n",
      "- 6 [54岁王琳回应穿短裙婚纱走秀](https://www.baidu.com/s?wd=54%E5%B2%81%E7%8E%8B%E7%90%B3%E5%9B%9E%E5%BA%94%E7%A9%BF%E7%9F%AD%E8%A3%99%E5%A9%9A%E7%BA%B1%E8%B5%B0%E7%A7%80&sa=fyb_news_feedpc&rsv_dl=fyb_news_feedpc&from=feedpc)\n",
      "- 7 [废墟传出敲击 中国救援队大喊安静](https://www.baidu.com/s?wd=%E5%BA%9F%E5%A2%9F%E4%BC%A0%E5%87%BA%E6%95%B2%E5%87%BB+%E4%B8%AD%E5%9B%BD%E6%95%91%E6%8F%B4%E9%98%9F%E5%A4%A7%E5%96%8A%E5%AE%89%E9%9D%99&sa=fyb_news_feedpc&rsv_dl=fyb_news_feedpc&from=feedpc) 热\n",
      "- 8 [雷军把车价打下来后网友破防了](https://www.baidu.com/s?wd=%E9%9B%B7%E5%86%9B%E6%8A%8A%E8%BD%A6%E4%BB%B7%E6%89%93%E4%B8%8B%E6%9D%A5%E5%90%8E%E7%BD%91%E5%8F%8B%E7%A0%B4%E9%98%B2%E4%BA%86&sa=fyb_news_feedpc&rsv_dl=fyb_news_feedpc&from=feedpc)\n",
      "- 9 [柯文哲妻子：可能人死了才通知我收尸](https://www.baidu.com/s?wd=%E6%9F%AF%E6%96%87%E5%93%B2%E5%A6%BB%E5%AD%90%EF%BC%9A%E5%8F%AF%E8%83%BD%E4%BA%BA%E6%AD%BB%E4%BA%86%E6%89%8D%E9%80%9A%E7%9F%A5%E6%88%91%E6%94%B6%E5%B0%B8&sa=fyb_news_feedpc&rsv_dl=fyb_news_feedpc&from=feedpc)\n",
      "- 10 [赵露思被批“洗白翻车”](https://www.baidu.com/s?wd=%E8%B5%B5%E9%9C%B2%E6%80%9D%E8%A2%AB%E6%89%B9%E2%80%9C%E6%B4%97%E7%99%BD%E7%BF%BB%E8%BD%A6%E2%80%9D&sa=fyb_news_feedpc&rsv_dl=fyb_news_feedpc&from=feedpc) 热\n",
      "\n",
      "![](https://mbdp01.bdstatic.com/static/landing-pc/img/icon_comment.dc6aa49c.png)\n",
      "\n",
      "0\n",
      "\n",
      "![](https://mbdp01.bdstatic.com/static/landing-pc/img/icon_collect.e651bbbd.png)\n",
      "\n",
      "收藏\n",
      "\n",
      "![](https://mbdp01.bdstatic.com/static/landing-pc/img/icon_share.4090f818.png)\n",
      "\n",
      "分享\n",
      "\n",
      "![](https://mbdp01.bdstatic.com/static/landing-pc/img/icon_wechat.9ffaae23.png)\n",
      "\n",
      "微信好友\n",
      "\n",
      "![](https://mbdp01.bdstatic.com/static/landing-pc/img/icon_xinlang.7b202670.png)\n",
      "\n",
      "新浪微博\n",
      "\n",
      "![](https://mbdp01.bdstatic.com/static/landing-pc/img/icon_lianjie.221aa5a3.png)\n",
      "\n",
      "复制链接\n",
      "\n",
      "![](https://baijiahao.baidu.com/s?id=1827966357241680945)![](https://mbdp01.bdstatic.com/static/landing-pc/img/qrcode_wechat.554f7e9b.png)\n",
      "\n",
      "扫码分享至微信\n",
      "\n",
      "[设为首页](https://www.baidu.com/cache/sethelp/index.html) © Baidu [使用百度前必读](https://www.baidu.com/duty/) [意见反馈](http://jianyi.baidu.com/) 京ICP证030173号 ![](https://ss0.bdstatic.com/5aV1bjqh_Q23odCf/static/superman/img/copy_rignt_8.png)\n",
      "\n",
      "[京公网安备11000002000001号](http://www.beian.gov.cn/portal/registerSystemInfo?recordcode=11000002000001)\n"
     ]
    }
   ],
   "source": [
    "print(response[\"data\"][0][\"markdown\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Jina_url Reader** \n",
    "\n",
    "JinaURL Reader 是 Jina AI 的 URL 读取服务的 Python 客户端，经过优化，可从 URL 提供更清晰、对 LLM 可读的内容。该reader提供一定额度的免费调用次数。无需注册API也可使用。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/suntao/Documents/GitHub/camel/camel/loaders/jina_url_reader.py:59: UserWarning: JINA_API_KEY not set. This will result in a low rate limit of Jina URL Reader. Get API key here: https://jina.ai/reader.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datawhale-学用AI，从此开始\n",
      "===============  \n",
      "\n",
      "![Image 1: logo](https://www.datawhale.cn/assets/logo-vAxrscYT.png)\n",
      "\n",
      "[HOME首页](https://www.datawhale.cn/home)[OPEN 1+XAI 通识课](https://www.datawhale.cn/open-ai)[ACTIVITY活动](https://www.datawhale.cn/activity)[COURSE课程](https://www.datawhale.cn/learn)[CERTIFICATION认证](https://www.datawhale.cn/cert)[NEWS资讯](https://www.datawhale.cn/article)\n",
      "\n",
      "![Image 2: wechat](blob:http://localhost/cfd0357cb7301be8879b48a64347d08f)![Image 3: wechat](https://www.datawhale.cn/assets/wechat-qrcode-CPBf96kV.png)\n",
      "\n",
      "[![Image 4: github](blob:http://localhost/4d659f53c87d622c9cafa1b45920725f)](https://github.com/datawhalechina)\n",
      "\n",
      "登录\n",
      "\n",
      "![Image 5](https://www.datawhale.cn/assets/homebanner-left-DQp9I1cY.png)\n",
      "\n",
      "Datawhale for the learner\n",
      "\n",
      "![Image 6](https://www.datawhale.cn/assets/banner-title-CqrNZXqM.png)\n",
      "\n",
      "Datawhale通过开源学习模式，助力AI学习者与知识连接，与人连接，与场景连接，推动AI人才培养。\n",
      "\n",
      "![Image 7](https://datawhale.oss-cn-hangzhou.aliyuncs.com/SEO/%E9%80%9A%E4%B9%89%E7%81%B5%E7%A0%81-%E8%B5%9B%E5%8D%9A%E5%90%8C%E6%A1%8C.png)\n",
      "\n",
      "![Image 8](https://www.datawhale.cn/assets/homebanner-swiper1-CnhP9rkt.png)\n",
      "\n",
      "![Image 9](https://datawhale.oss-cn-hangzhou.aliyuncs.com/SEO/%E9%80%9A%E4%B9%89%E7%81%B5%E7%A0%81-%E8%B5%9B%E5%8D%9A%E5%90%8C%E6%A1%8C.png)\n",
      "\n",
      "![Image 10](https://www.datawhale.cn/assets/homebanner-swiper1-CnhP9rkt.png)\n",
      "\n",
      "![Image 11: logo](blob:http://localhost/7dd095def689b2660c34f51de0662bf6)\n",
      "\n",
      "活动\n",
      "\n",
      "活动\n",
      "\n",
      "![Image 12: logo](blob:http://localhost/7dd095def689b2660c34f51de0662bf6)\n",
      "\n",
      "Datawhale的线上开源学习活动和线下见面会，帮助了20W+AI学习者。\n",
      "\n",
      "![Image 13: logo](blob:http://localhost/6576e69ef49539522deae2ff33701318)\n",
      "\n",
      "课程\n",
      "\n",
      "课程\n",
      "\n",
      "![Image 14: logo](blob:http://localhost/6576e69ef49539522deae2ff33701318)\n",
      "\n",
      "上百门AI相关课程，Datawhale小伙伴们多年以来的贡献和积累。\n",
      "\n",
      "![Image 15: logo](blob:http://localhost/fb23e2d44445fae7b57674df2450d5a9)\n",
      "\n",
      "认证\n",
      "\n",
      "认证\n",
      "\n",
      "![Image 16: logo](blob:http://localhost/fb23e2d44445fae7b57674df2450d5a9)\n",
      "\n",
      "Datawhale与全球顶尖机构一起提供AI+X的微认证，让你的知识和技能更有含金量！\n",
      "\n",
      "![Image 17: logo](blob:http://localhost/201bc060f8e911ce74b7748b0ebcda24)\n",
      "\n",
      "资讯\n",
      "\n",
      "资讯\n",
      "\n",
      "![Image 18: logo](blob:http://localhost/201bc060f8e911ce74b7748b0ebcda24)\n",
      "\n",
      "精选AI行业动态和知识干货，Datawhale为学习者速递前沿资讯。\n",
      "\n",
      "AI TRANING PLAN\n",
      "\n",
      "AI学习路线\n",
      "\n",
      "给初涉AI的你，提供一份切实可行的学习路线\n",
      "\n",
      "学习路径\n",
      "\n",
      "![Image 19: arrowDown](blob:http://localhost/335cc68f7e3a067cf5d986354b6b8763)\n",
      "\n",
      "数据分析学习路径\n",
      "\n",
      "学习路径\n",
      "\n",
      "![Image 20: arrowDown](blob:http://localhost/335cc68f7e3a067cf5d986354b6b8763)\n",
      "\n",
      "计算机视觉学习路径\n",
      "\n",
      "学习路径\n",
      "\n",
      "![Image 21: arrowDown](blob:http://localhost/335cc68f7e3a067cf5d986354b6b8763)\n",
      "\n",
      "自然语言处理学习路径\n",
      "\n",
      "学习路径\n",
      "\n",
      "![Image 22: arrowDown](blob:http://localhost/335cc68f7e3a067cf5d986354b6b8763)\n",
      "\n",
      "推荐系统学习路径\n",
      "\n",
      "![Image 23: traningPlan](https://www.datawhale.cn/assets/data-analysis-CnHslXI1.png)\n",
      "\n",
      "![Image 24: homePracticeBg](blob:http://localhost/6b79bc0954ad5273d4b37e56a21dd064)\n",
      "\n",
      "AI STUDY\n",
      "\n",
      "AI学习\n",
      "\n",
      "面向开发者的 LLM 入门课程\n",
      "\n",
      "本项目是一个面向开发者的 LLM 入门教程，基于吴恩达老师大模型系列课程内容，将原课程内容翻译为中文并复现其范例代码，实现中文 Prompt，指导国内开发者如何基于 LLM 快速、高效开发具备强大能力的应用程序。\n",
      "\n",
      "高级github开源教程\n",
      "\n",
      "View details![Image 25: arrowRight](blob:http://localhost/5d34cbc71b56ddff5206c30feb66fd50)\n",
      "\n",
      "动手学大模型应用开发\n",
      "\n",
      "本项目是一个面向小白开发者的大模型应用开发教程，旨在结合个人知识库助手项目，通过一个课程完成大模型开发的重点入门\n",
      "\n",
      "初级github开源教程\n",
      "\n",
      "View details![Image 26: arrowRight](blob:http://localhost/5d34cbc71b56ddff5206c30feb66fd50)\n",
      "\n",
      "AI+数据分析 通识入门\n",
      "\n",
      "教你快速学会用AI进行数据分析\n",
      "\n",
      "初级高校行\n",
      "\n",
      "View details![Image 27: arrowRight](blob:http://localhost/5d34cbc71b56ddff5206c30feb66fd50)\n",
      "\n",
      "10分钟带你速通大模型挑战赛\n",
      "\n",
      "大语言模型、自然语言处理模型\n",
      "\n",
      "中级高校行\n",
      "\n",
      "View details![Image 28: arrowRight](blob:http://localhost/5d34cbc71b56ddff5206c30feb66fd50)\n",
      "\n",
      "大语言模型（LLM）原理与实践\n",
      "\n",
      "本项目旨在作为一个大规模预训练语言模型的教程，从数据准备、模型构建、训练策略到模型评估与改进，以及模型在安全、隐私、环境和法律道德方面的方面来提供开源知识。\n",
      "\n",
      "高级github开源教程\n",
      "\n",
      "View details![Image 29: arrowRight](blob:http://localhost/5d34cbc71b56ddff5206c30feb66fd50)\n",
      "\n",
      "Joyful-Pandas\n",
      "\n",
      "本教程共有十章，可分为三大模块：基础知识、四类操作、四类数据，涵盖了pandas的所有核心操作与特性。\n",
      "\n",
      "初级github开源教程\n",
      "\n",
      "View details![Image 30: arrowRight](blob:http://localhost/5d34cbc71b56ddff5206c30feb66fd50)\n",
      "\n",
      "more\n",
      "\n",
      "![Image 31: homeLearnBg](blob:http://localhost/3f7913d3631faca016048e0154ac207d)\n",
      "\n",
      "datawhale.cn\n",
      "\n",
      "关于我们 [关于Datawhale](https://www.datawhale.cn/about) [贡献者们](https://mp.weixin.qq.com/mp/appmsgalbum?action=getalbum&__biz=MzIyNjM2MzQyNg==&scene=1&album_id=2624200781860225026&count=3#wechat_redirect)[加入我们](https://jinshuju.net/f/OA3fi3)\n",
      "\n",
      "联系我们\n",
      "\n",
      "微信：a1434088958\n",
      "\n",
      "![Image 32: wechat](https://datawhale-business.oss-cn-hangzhou.aliyuncs.com/20194/dashboard/1733623456377/footer-wechat-qrcode.jpg)合作热线：18742585754邮箱：opensource@datawhale.club\n",
      "\n",
      "社交媒体[GITHUB](https://github.com/datawhalechina) [B站](https://space.bilibili.com/431850986) [CSDN](https://blog.csdn.net/Datawhale)\n",
      "\n",
      "[![Image 33](blob:http://localhost/a1d2760e5d7b70d1dbb76b573944cb7f) 我要反馈](https://jinshuju.net/f/gtuc5x)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from camel.loaders import JinaURLReader\n",
    "from camel.types.enums import JinaReturnFormat\n",
    "\n",
    "jina_reader = JinaURLReader(return_format=JinaReturnFormat.MARKDOWN)\n",
    "response = jina_reader.read_content(\"https://www.datawhale.cn/home\")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embddings\n",
    "\n",
    " **基本概念** \n",
    "\n",
    "为不同类型的数据（文本、图像、视频）创建嵌入的过程，是将这些输入转化为机器能够理解和高效处理的数值形式。每种嵌入都专注于捕获其对应数据类型的核心特征。以下是对主要数据类型嵌入的简要说明：\n",
    "\n",
    " **文本嵌入** \n",
    "\n",
    "文本嵌入（Text Embeddings）将文本数据转换为数值向量，每个向量代表文本的语义含义，使我们能够基于意义而非文本的原始形式处理和比较文本。通过这种方式，机器可以捕获语言中的上下文和细微差别。\n",
    "\n",
    " **嵌入技术** \n",
    "\n",
    "1. **OpenAI Embedding** :\n",
    "   \n",
    "   - 使用大规模语言模型（LLM）生成嵌入，能够理解语言中的复杂语境和语义细节。\n",
    "   \n",
    "   - 例如， `text-embedding-3-small` 模型生成 1536 维嵌入向量。\n",
    "   \n",
    "2. **SentenceTransformerEncoder** :\n",
    "   \n",
    "   - 专为生成句子级别的嵌入设计，通常基于 BERT 等模型。\n",
    "   \n",
    "   - 强调对句子语义的捕获，适合文本比较或语义搜索任务。\n",
    "   \n",
    " **示例：语义比较** \n",
    "\n",
    " **句子 1** : “A young boy is playing soccer in a park.” **句子 2** : “A child is kicking a football on a playground.”\n",
    "\n",
    "尽管两句话用词不同，但它们表达的语义非常相似。\n",
    "\n",
    "文本嵌入模型会将这些句子转换为高维向量，例如 1536 维。如果我们比较这两个向量，计算出的相似度值（如余弦相似度）会较高，表明它们具有相近的语义。\n",
    "\n",
    "---\n",
    "\n",
    " **语义处理的意义** \n",
    "\n",
    "1. **语义相似性** : 嵌入捕获了“孩子在户外踢球”的共同概念，而不是简单地依赖词语的字面匹配。\n",
    "\n",
    "2. **应用场景** :\n",
    "   \n",
    "   - **信息检索** : 根据语义找到相关内容，而非精确关键词匹配。\n",
    "   \n",
    "   - **问答系统** : 理解用户提问的核心含义并生成精准答案。\n",
    "   \n",
    "   - **文本聚类与分类** : 根据嵌入向量的分布，聚类相似语义的文本。\n",
    "   \n",
    "通过文本嵌入，机器不仅可以理解语言表面的表达，还能更深层次地处理和分析其语义关联，使语义搜索、文本匹配等任务更为智能和高效。\n",
    "\n",
    "---\n",
    "\n",
    " **图像嵌入** \n",
    "\n",
    "图像嵌入是一种将图片转化为数值向量的技术，这些向量能够表示图像中的关键特征，比如形状、颜色、纹理和空间层次。通过这种方式，机器可以理解图像的核心内容，并以此完成分类、检索和相似性比较等任务。\n",
    "\n",
    "举个例子，当你将一张猫的图片输入模型时，模型会分析图片中的视觉特征，比如猫耳朵的形状、毛发的纹理等。最后，这些特征会被压缩为一个高维向量，这个向量就浓缩了图片的核心信息，既能让模型识别这是猫的图片，也能与其他图像进行对比，区分它与狗或其他动物的差异。\n",
    "\n",
    "图像嵌入有很多应用场景。比如，在图像分类中，模型可以根据嵌入向量给图片打标签，识别出它是一只猫还是一辆车。在相似性比较中，嵌入向量可以用来衡量两张图片的相似程度，常见于推荐系统中，比如推荐风格相似的照片。还有图像检索，用户上传一张图片后，系统通过嵌入向量找到数据库中最相似的图片，像以图搜图这样的功能。\n",
    "\n",
    "实现图像嵌入通常依赖卷积神经网络（CNN），比如 ResNet 或 EfficientNet 这样的模型。这些模型经过大量数据的训练，能够提取图像的高层次特征。此外，随着技术的进步，像 Vision Transformer 这样的新模型也被用于更复杂的图像理解任务。\n",
    "\n",
    "通过图像嵌入技术，机器能够从简单的像素点处理，进化到真正理解图像内容，这也是现代计算机视觉任务的核心方法之一。\n",
    "\n",
    "---\n",
    "\n",
    " **动手实践** \n",
    "\n",
    "以下是如何使用不同嵌入方法的示例代码，帮助你快速生成文本和图像的嵌入向量。\n",
    "\n",
    "`OpenAIEmbedding` \n",
    "\n",
    "用于生成文本嵌入，基于 OpenAI 的模型(需要OPENAI_API_KEY)。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from camel.embeddings import OpenAIEmbedding\n",
    "from camel.types import EmbeddingModelType\n",
    "\n",
    "# 初始化 OpenAI 嵌入模型\n",
    "openai_embedding = OpenAIEmbedding(model_type=EmbeddingModelType.TEXT_EMBEDDING_3_SMALL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OpenAICompatibleEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from camel.memories.blocks.vectordb_block import VectorDBBlock\n",
    "from camel.memories.records import MemoryRecord\n",
    "from camel.messages import BaseMessage\n",
    "from camel.embeddings import SentenceTransformerEncoder,OpenAICompatibleEmbedding\n",
    "from camel.types import OpenAIBackendRole\n",
    "from camel.storages.vectordb_storages import QdrantStorage\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "embedding = OpenAICompatibleEmbedding(\n",
    "    model_type=\"Qwen/Qwen3-Embedding-8B\",\n",
    "    url= 'http://47.99.169.163:3000/v1',\n",
    "    api_key=\"sk-ZXT3bnVWO3RO3cwh8c1dCc55Dc2a41Ef8125371a0d69Ee8a\"\n",
    "    )\n",
    "\n",
    "#使用OpenAICompatibleEmbedding时 需要先调用 embed_list 来确定输出维度\n",
    "_ = embedding.embed_list([\"测试文本\"])\n",
    "\n",
    "\n",
    "vector_db_block = VectorDBBlock(embedding=embedding,storage=(QdrantStorage(vector_dim=1024)))\n",
    "# vertor_db_block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`MistralEmbedding` \n",
    "\n",
    "基于 Mistral 模型的嵌入方法(需要MISTRAL_API_KEY)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from camel.embeddings import MistralEmbedding\n",
    "from camel.types import EmbeddingModelType\n",
    "\n",
    "# 初始化 Mistral 嵌入模型\n",
    "mistral_embedding = MistralEmbedding(model_type=EmbeddingModelType.MISTRAL_EMBED)\n",
    "\n",
    "# 为一组文本生成嵌入向量\n",
    "embeddings = mistral_embedding.embed_list([\"Hello, world!\", \"Another example\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`SentenceTransformerEncoder`\n",
    "\n",
    "基于 Sentence Transformer 的文本嵌入方法，适用于高效语义表示(使用本地embedding模型，如果没有会自动下载)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from camel.embeddings import SentenceTransformerEncoder\n",
    "\n",
    "# 初始化 Sentence Transformer 编码器\n",
    "sentence_encoder = SentenceTransformerEncoder(model_name='intfloat/e5-large-v2')\n",
    "\n",
    "# 为一组文本生成嵌入向量\n",
    "embeddings = sentence_encoder.embed_list([\"Hello, world!\", \"Another example\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.022303013131022453, -0.034714311361312866, 0.026222843676805496, -0.02245742827653885, -0.05533646047115326, 0.023405734449625015, -0.045956119894981384, -0.01431057695299387, -0.05823829770088196, 0.003983663860708475, 0.03760166093707085, -0.016566162928938866, 0.030052829533815384, 0.05838202312588692, -0.013132063671946526, 0.04951498657464981, -0.0012516692513599992, -0.0025377993006259203, 0.026695119217038155, -0.004841017536818981, 0.026240631937980652, -0.02408909797668457, -0.0030735095497220755, 0.012629831209778786, -0.015909578651189804, -0.042372312396764755, -0.03456776589155197, -0.04385131224989891, -0.03479576110839844, 0.01995578408241272, -0.02307026833295822, -0.010534300468862057, 0.029732299968600273, -0.019060222432017326, 0.055770035833120346, -0.022509116679430008, -0.023742645978927612, -0.03607054799795151, 0.013509703800082207, -0.0004353156837169081, 0.0058114114217460155, 0.046685561537742615, -0.04191722348332405, 0.03406957536935806, 0.018464097753167152, 0.00594624038785696, -0.02558688260614872, -0.020972803235054016, 0.005860582925379276, -0.01860090158879757, 0.02080722525715828, -0.03650330752134323, 0.025314465165138245, 0.01631058193743229, -0.037803247570991516, 0.019017677754163742, 0.03203616291284561, 0.0437844917178154, -0.007630365435034037, 0.020650047808885574, 0.02653530426323414, -0.0024380162358283997, 0.04057498648762703, -0.03017684817314148, 0.02882101573050022, -0.015239376574754715, 0.030586980283260345, 0.0403316505253315, 0.02566712163388729, 0.0503980852663517, -0.04260127618908882, -0.03592918440699577, 0.030405165627598763, 0.029745297506451607, 0.062488701194524765, -0.03031444177031517, -0.01257272344082594, 0.012652743607759476, 0.015210993587970734, 0.03507391735911369, -0.0020726777147501707, -0.022330669686198235, -0.03175663203001022, -0.026779457926750183, 0.010699880309402943, -0.012588877230882645, 0.021257620304822922, -0.013146382756531239, 0.003535207826644182, 0.0338623933494091, 0.02374681830406189, -0.05140501633286476, 0.04327503591775894, 0.01716296188533306, -0.018956217914819717, -0.022155676037073135, -0.029925145208835602, 0.026125529780983925, 0.012290786020457745, -0.007916172966361046, -0.014907331205904484, -0.038253042846918106, -0.018007364124059677, 0.043342623859643936, -0.0008273090934380889, -0.013200577348470688, -0.04741593822836876, -0.013889898546040058, -0.07207737118005753, -0.02468729205429554, -0.008109007030725479, -0.023771503940224648, -0.018141523003578186, -0.027711793780326843, -0.026802927255630493, 0.03261975571513176, 0.013204424642026424, -0.02024984173476696, 0.02474193088710308, 0.04380831494927406, 0.07364165037870407, 0.003293851623311639, -0.03541790321469307, -0.03527151420712471, -0.012502670288085938, 0.03930417075753212, -0.029871812090277672, -0.02674592286348343, 0.0444687195122242, 0.05673481896519661, -0.013408969156444073, -0.04472479969263077, -0.0074411481618881226, 0.007421339862048626, 0.025915933772921562, 0.058489296585321426, -0.021959999576210976, -0.06616126745939255, 0.010068338364362717, 0.014983760192990303, -0.021130263805389404, -0.022122683003544807, 0.037859927862882614, 0.02954326570034027, 0.0309100691229105, -0.051938679069280624, -0.016172869130969048, -0.01571342721581459, -0.03777012974023819, -0.06822366267442703, -0.04580274596810341, 0.011062786914408207, -0.027429088950157166, -0.015188073739409447, 0.047984182834625244, -0.07360208034515381, -0.01631726510822773, -0.037709835916757584, -0.0034907031804323196, 0.03335987776517868, 0.039883628487586975, 0.011848358437418938, -0.014417010359466076, -0.005200137384235859, -0.008578448556363583, -0.03289138153195381, 0.022141335532069206, -0.0012490162625908852, -0.012461170554161072, 0.03855638951063156, -0.00908605195581913, 0.040993571281433105, 0.046798672527074814, 0.020892802625894547, 0.045733027160167694, -0.016627678647637367, 0.048152048140764236, -0.03375949710607529, 0.015372483059763908, -0.0008802220690995455, 0.018650464713573456, 0.015385535545647144, -0.024698294699192047, -0.029504399746656418, -0.06173963099718094, 0.015800608322024345, 0.03509726747870445, -0.03615995869040489, 0.009291324764490128, -0.045891933143138885, -0.009772117249667645, -0.007015634328126907, -0.051783185452222824, 0.03672551363706589, -0.02529982104897499, -0.009756767190992832, -0.036794304847717285, -0.027963833883404732, -0.017597876489162445, 0.03556176275014877, 0.04626443237066269, 0.019147757440805435, -0.011044485494494438, -0.024542173370718956, -0.0024337884970009327, 0.041610512882471085, 0.027738351374864578, 0.010086281225085258, -0.03255201503634453, -0.013214790262281895, 0.03197023272514343, 0.0039057612884789705, 0.04230743646621704, -0.0036053576041013002, -0.020260939374566078, 0.0024719303473830223, 0.03899636119604111, -0.0006265302654355764, -0.01756056770682335, 0.008884063921868801, -0.005272723734378815, -0.028307152912020683, 0.05409468710422516, 0.009525415487587452, 0.021644631400704384, -0.0042561693117022514, -0.0004966938286088407, 0.021269669756293297, -0.0026210465002804995, -0.020692724734544754, 0.032935164868831635, 0.011233516968786716, -0.021721120923757553, -0.03798649087548256, -0.01398182287812233, -0.011764728464186192, 0.03780268132686615, -0.010887930169701576, 0.011216769926249981, 0.052523620426654816, -0.0018124531488865614, 0.04506061226129532, -0.01025296375155449, -0.007616877090185881, 0.025367161259055138, 0.041387032717466354, 0.009998724795877934, 0.02504735440015793, 0.028533069416880608, 0.05275571718811989, 0.005028044804930687, 0.033564988523721695, -0.009417037479579449, -0.030158229172229767, -0.03253971412777901, -0.0067265573889017105, 0.07159071415662766, -0.03127487376332283, -0.05125698819756508, 0.007764674257487059, 0.028330247849225998, -0.06551464647054672, -0.046080902218818665, -0.01056267973035574, -0.03948080912232399, -0.03691262751817703, 0.018582994118332863, 0.002486062701791525, 0.050823453813791275, -0.04449492320418358, 0.017985710874199867, 0.04962538555264473, 0.02251105010509491, -0.05648043006658554, -0.017070624977350235, -0.01954316347837448, -0.013399767689406872, -0.04634873569011688, -0.007836482487618923, 0.02079017646610737, 0.023776158690452576, 0.007254040800035, 0.034609414637088776, 0.02446601912379265, -0.0116643775254488, 0.03772665932774544, -0.006073747295886278, 0.037110842764377594, 0.04908803850412369, 0.029570341110229492, -0.03120242990553379, -0.004909984301775694, 0.02684064768254757, -0.015751997008919716, -0.01329940464347601, 0.005695013329386711, -0.02582915686070919, 0.004446623846888542, 0.027734721079468727, 0.0191397275775671, 0.044365379959344864, 0.010583640076220036, -0.07970269024372101, -0.04310951381921768, -0.014990405179560184, -0.03083075024187565, 0.001593720749951899, -0.057053156197071075, 0.028698155656456947, -0.002154498128220439, 0.004930082242935896, -0.04849642887711525, -0.0011386382393538952, -0.04213951155543327, -0.061522308737039566, 0.024099761620163918, -0.026870785281062126, 0.04673336073756218, 0.0128230731934309, -0.01203238032758236, 0.07323262840509415, -0.018794842064380646, -0.03179147094488144, -0.03276630863547325, 0.00691795302554965, 0.00852004811167717, -0.04214631766080856, -0.0032868976704776287, -0.010206586681306362, -0.03117707557976246, -0.020545953884720802, 0.006362889893352985, 0.05471508204936981, 0.054398804903030396, -0.014989768154919147, -0.043274179100990295, -0.01345096342265606, -0.006942071486264467, 0.026743968948721886, 0.06916438043117523, 0.03754708170890808, 0.043002814054489136, -0.03949927166104317, -0.020490705966949463, 0.0032585635781288147, 0.04182637482881546, 0.0505332350730896, 0.0018111747922375798, 0.046125348657369614, 0.05023433640599251, 0.03206860274076462, -0.003639069152995944, -0.0214899480342865, -0.04048214480280876, -0.05544937774538994, -0.0821867361664772, 0.03717871755361557, -0.030040297657251358, 0.010497573763132095, 0.03320406377315521, 0.009389086626470089, -0.027799583971500397, 0.031334154307842255, -0.016136523336172104, -0.028010696172714233, -0.048770416527986526, 0.03444370999932289, -0.024918725714087486, 0.023090818896889687, 0.027209438383579254, 0.0202756617218256, 0.03201400488615036, -0.0004634525685105473, -0.049234673380851746, -0.038406383246183395, -0.018281515687704086, 0.013662534765899181, 0.04385654628276825, 0.02424051985144615, 0.011478587053716183, 0.03133159503340721, 0.04040553420782089, 0.004024962428957224, -0.017352860420942307, -0.05275827646255493, -0.03043368272483349, -0.029155883938074112, -0.03363259881734848, 0.006630169227719307, -0.06755906343460083, 0.01586836203932762, -0.05691966041922569, 0.033846959471702576, -0.04775841906666756, -0.015944361686706543, -0.01060883142054081, 0.03658732399344444, -0.05574474856257439, 0.027394069358706474, 0.0004640424740500748, 0.01156003586947918, 0.053325120359659195, -0.006899669766426086, -0.004070680122822523, -0.03598654270172119, -0.01820342056453228, 0.043244533240795135, 0.06000281497836113, 0.006344200577586889, -0.04829372093081474, -0.007382630370557308, 0.04706919193267822, 0.026694297790527344, -0.023641690611839294, -0.028507960960268974, 0.025374094024300575, -0.0029474792536348104, -0.0016886423109099269, -0.021555593237280846, -0.0073646483942866325, -0.011767832562327385, -0.015443765558302402, -0.003963422030210495, -0.023189865052700043, 0.021711820736527443, -0.009496322833001614, 0.0027607434894889593, -0.013151352293789387, -0.003702281741425395, -0.02345288172364235, 0.04553776979446411, -0.040102407336235046, -0.047870829701423645, -0.019630396738648415, 0.03509639576077461, -0.04039573296904564, 0.012500276789069176, -0.013013620860874653, 0.035271454602479935, -0.014579787850379944, 0.05146252363920212, 0.018833059817552567, -0.0027661407366394997, -0.028164681047201157, 0.03373780846595764, -0.02122846245765686, -0.01392100378870964, -0.025827301666140556, -0.023369496688246727, 0.014159990474581718, 0.05333608388900757, -0.018543697893619537, 0.06372363865375519, -0.049399830400943756, -0.03278309479355812, -0.048611994832754135, -0.011366568505764008, 0.015207590535283089, -0.027612019330263138, 0.021255383267998695, -0.05600757524371147, -0.02092880941927433, 0.02630375325679779, -0.045713938772678375, -0.03228916600346565, -0.024057283997535706, 0.040699176490306854, 0.01293847057968378, -0.02680961787700653, 0.022994766011834145, -0.03380213677883148, -0.05807832255959511, 0.037710994482040405, -0.01139212679117918, -0.037804923951625824, 0.009804760105907917, 0.042937517166137695, 0.045978982001543045, 0.012581697665154934, 0.044470690190792084, -0.024862876161932945, -0.0160745270550251, 0.019795892760157585, 0.008882113732397556, -0.027524113655090332, 0.016222655773162842, -0.03403453901410103, -0.010471140965819359, 0.03923068195581436, -0.024195510894060135, -0.04003074765205383, 0.026795005425810814, 0.021443301811814308, 0.027208594605326653, 0.01881282962858677, -0.022798709571361542, -0.01070244237780571, 0.026284830644726753, -0.05040069296956062, -0.03639271482825279, 0.031607259064912796, -0.02861793152987957, 0.02293652854859829, 0.054787445813417435, -0.046622682362794876, 0.045976363122463226, -0.030532898381352425, 0.013658350333571434, -0.019210584461688995, 0.022826388478279114, 0.0016879485920071602, -0.035165783017873764, -0.025219744071364403, 0.0269343052059412, 0.02378532662987709, 0.010967672802507877, 0.031706225126981735, 0.022393975406885147, 0.027365220710635185, 0.0114712780341506, -0.02031582221388817, -0.041467271745204926, -0.010718955658376217, -0.014496482908725739, -0.06159282103180885, 0.017608437687158585, 0.010740856640040874, 0.023720042780041695, -0.018690921366214752, -0.027763696387410164, -0.004347174894064665, 0.06446206569671631, -0.04034829139709473, 0.011022214777767658, 0.01093736756592989, 0.026813995093107224, -0.031035808846354485, -0.0390208400785923, -0.022856062278151512, 0.012919452041387558, 0.0060478514060378075, 0.018319256603717804, 0.03632153570652008, -0.0026389253325760365, -0.025351105257868767, -0.02963201515376568, -0.02992568537592888, 0.009042532183229923, 0.019504999741911888, -0.027815494686365128, 0.018655721098184586, -0.01911616325378418, -0.05635789409279823, -0.028072724118828773, -0.044028427451848984, 0.059756044298410416, -0.04962552338838577, -0.006781254429370165, 0.030828531831502914, -0.014084462076425552, 0.02098292112350464, 0.04194042459130287, 0.06246373429894447, 0.0070099295116961, -0.04591987282037735, 0.053528495132923126, -0.0027334659826010466, 0.01293363980948925, -0.032511308789253235, 0.042030155658721924, -0.0012416747631505132, 0.006040283013135195, 0.020261164754629135, -0.02555919997394085, -0.036484915763139725, 0.02311624214053154, 0.021241452544927597, 0.026147322729229927, 0.03931466117501259, -0.028351182118058205, 0.023310068994760513, -0.039589542895555496, 0.023464681580662727, -0.02835913561284542, -0.014004597440361977, 0.004677951335906982, -0.014189648441970348, -0.0709008276462555, 0.02296619862318039, 0.045520342886447906, 0.01570567861199379, 0.039627980440855026, -0.03429562225937843, -0.04076045751571655, 0.043937504291534424, -0.01344357430934906, 0.034623242914676666, -0.017862064763903618, -0.05194230377674103, 0.0005161851877346635, 0.03342881426215172, -0.04478044435381889, 0.02128816582262516, -0.05665105953812599, 0.006336483638733625, 0.011185791343450546, 0.0254208967089653, 0.020436231046915054, 0.014877239242196083, 0.012564828619360924, -0.031506750732660294, 0.05571381747722626, 0.037856169044971466, 0.004509789403527975, -0.029371589422225952, 0.03334997594356537, -0.011689423583447933, -0.005422893911600113, 0.018641065806150436, 0.030333654955029488, -0.022010521963238716, 0.045673221349716187, 0.03458786383271217, 0.03600946068763733, -0.03901457041501999, -0.015941226854920387, 0.03049204871058464, -0.05095243081450462, 0.0584106408059597, 0.030106399208307266, 0.029039617627859116, 0.007570150773972273, -0.018553875386714935, 0.012643693014979362, -0.012384014204144478, 0.005253944080322981, -0.001995658967643976, -0.0256354883313179, 0.009912521578371525, 0.054043836891651154, 0.0682184174656868, -0.0011863108957186341, -0.0199233740568161, 0.048499926924705505, -0.004119156394153833, 0.01895301602780819, -0.029143013060092926, -0.0451773963868618, 0.019092418253421783, -0.02241448126733303, -0.019599860534071922, 0.08217673748731613, 0.007364468649029732, 0.015924101695418358, 0.03912734240293503, 0.05793615058064461, 0.039120327681303024, 0.03238389268517494, 0.03508184105157852, 0.007725375238806009, 0.024503206834197044, 0.01762377843260765, -0.02021639607846737, -0.05786006525158882, 0.002020372310653329, 0.09124332666397095, 0.009287782944738865, 0.04511347413063049, -0.030367055907845497, 0.015209493227303028, 0.010711714625358582, -0.06377546489238739, 0.026941195130348206, -0.03669358789920807, 0.021513303741812706, 0.052670422941446304, 0.03077535144984722, 0.015257444232702255, 0.020644068717956543, -0.007735599763691425, 0.028227917850017548, 0.00889532919973135, -0.04024534672498703, -0.04560969024896622, -0.002416157629340887, 0.036391206085681915, 0.00488546397536993, -0.060403626412153244, -0.01190955750644207, 0.02613694593310356, -0.01255582831799984, 0.013591518625617027, -0.07219090312719345, 0.06256702542304993, 0.03835896775126457, -0.008905822411179543, 0.03277856111526489, -0.019673040136694908, -0.015107068233191967, -0.00953972339630127, -0.003785700537264347, -0.02946111001074314, 0.039727237075567245, 0.05018771439790726, -0.005809771362692118, 0.024629482999444008, 0.062332633882761, -0.02720496617257595, -0.02469690889120102, 0.02562248893082142, -0.011163688264787197, 0.034094907343387604, -0.041476067155599594, 0.007418043911457062, 0.03802460432052612, 0.021285956725478172, -0.027425246313214302, -0.024907905608415604, 0.008177465759217739, 0.017655789852142334, 0.029281580820679665, 0.01781524531543255, 0.0029657927807420492, -0.0003293761983513832, -0.0341360941529274, 0.016512997448444366, 0.021112538874149323, 0.020443279296159744, 0.019352274015545845, -0.04365777224302292, -0.030797582119703293, 0.050454191863536835, 0.035666290670633316, 0.0347558967769146, -0.049074605107307434, 0.003635082859545946, -0.04663097858428955, -0.00990299042314291, 0.021536681801080704, -0.033778104931116104, -0.03511393815279007, 0.012122966349124908, -0.01118506584316492, -0.016362495720386505, -0.01976022869348526, -0.03998089209198952, 0.007686160039156675, -0.03253967687487602, -0.0020719559397548437, 0.047055684030056, -0.04177483543753624, -0.022114967927336693, 0.02327141724526882, -0.0064025153405964375, -0.0169318076223135, -0.030502213165163994, 0.019317956641316414, -0.0281112901866436, 0.026857072487473488, -0.023970266804099083, 0.05289798602461815, -0.022679947316646576, 0.033863648772239685, -0.0012286804849281907, 0.041327159851789474, 0.03922614827752113, 0.008799754083156586, -0.007994983345270157, -0.00630453834310174, -0.053482674062252045, -0.014584018848836422, 0.036469120532274246, 0.043122898787260056, 0.02766292542219162, 0.010133031755685806, -0.002964676357805729, 0.019123395904898643, 0.015911394730210304, 0.02993321605026722, -0.00510199973359704, 0.015831783413887024, 0.0026796753518283367, -0.01078272145241499, 0.005912206135690212, 0.04352781921625137, 0.06445381045341492, 0.033024851232767105, 0.04195428267121315, 0.0006338897510431707, 0.002760451752692461, 0.01602909341454506, 0.0057452889159321785, -0.02315712533891201, -0.04341762512922287, -0.02646091766655445, 0.023816820234060287, -0.031103109940886497, 0.0012414801167324185, -0.029712628573179245, -0.007937544025480747, 0.030976764857769012, 0.02075033448636532, 0.013323863968253136, -0.04144078120589256, 0.0026226239278912544, -0.046947795897722244, -0.01948804035782814, -0.02460377849638462, -0.035497646778821945, 0.021433522924780846, 0.0008186284685507417, -0.027305562049150467, 0.014323600567877293, 0.04664353281259537, 0.03497825935482979, -0.014822610653936863, -0.04899512976408005, 0.035204317420721054, 0.04646623507142067, 0.04562012851238251, 0.06987843662500381, 0.05998624116182327, -0.046992816030979156, 0.007097031455487013, 0.0012152385897934437, -0.0015069606015458703, 0.03708933666348457, 0.0028208668809384108, -0.00022813510440755635, -0.05744607374072075, -0.030074061825871468, -0.01953216828405857, -0.055157750844955444, -0.01150825247168541, -0.022121939808130264, 0.02311752550303936, 0.02032327465713024, 0.0019805326592177153, -0.050556477159261703, 0.045881450176239014, 0.03567834943532944, 0.015231207944452763, -0.006532387342303991, 0.003891157917678356, 0.006852786988019943, 0.030139196664094925, 0.032369498163461685, -0.0048070140182971954, -0.013310053385794163, 0.01726183481514454, -0.043496377766132355, -0.042518895119428635, 0.028305791318416595, 0.03957011550664902, -0.03887413069605827, 0.012862762436270714, 0.0015077490825206041, -0.019312340766191483, -0.0324648879468441, -0.08017845451831818, -0.020827407017350197, 0.022917822003364563, 0.035191915929317474, 0.001970864599570632, 0.018110428005456924, 0.03729572892189026, 0.014428584836423397, 0.007837976329028606, 0.04642220214009285, -0.031953465193510056, -0.030343998223543167, -0.025241175666451454, 0.02428554743528366, 0.006547118071466684, -0.013459691777825356, -0.02311929129064083, -0.02320479229092598, 0.059483882039785385, 0.03215000405907631, 0.030859291553497314, 0.039474744349718094, -0.010754942893981934, -0.027710426598787308, 0.011246130801737309, -0.03927019238471985, 0.008459026925265789, 0.047991588711738586, -0.012429054826498032, -0.03182448446750641, -0.022259782999753952, 0.007790904957801104, -0.009216370061039925, 0.022786619141697884, -0.02103840559720993, -0.0334317721426487, 0.02652077004313469, 0.04628807678818703, -0.020739054307341576, -0.004372788593173027, 0.009472930803894997, -0.01956898532807827, 0.01977243274450302, 0.019179748371243477, -0.02730928547680378, 0.01832987740635872, -0.012110181152820587, -0.04158712550997734, 0.02850680984556675, -0.02610785886645317, 0.025975516065955162, 0.040061820298433304, -0.030269848182797432, 0.02229083515703678, -0.05124865844845772, -0.0031460111495107412, -0.007451866753399372, 0.023946531116962433, -0.02411838434636593, -0.005861916113644838, 0.0312909334897995, 0.03554892912507057, 0.06743530929088593, -0.05490916967391968, 0.0019058706238865852, 0.008798164315521717, -0.0005248885718174279, -0.022755764424800873, 0.035934146493673325, 0.036630384624004364, -0.06338344514369965, -0.032090939581394196, 0.003265426028519869, 0.026402827352285385, 0.0392497219145298, 0.013689480721950531, 0.002112708752974868, 0.03383690118789673, -0.04554140567779541, -0.04353845492005348, -0.024788517504930496, -0.02090269699692726, -0.012922417372465134, -0.017443666234612465, 0.06034981086850166, -0.043888919055461884, -0.0244030449539423, 0.005752908997237682, 0.01794579066336155, -0.02320324070751667, 0.02390405721962452, -0.04174862802028656, 0.016638536006212234, -0.03413793444633484, 0.0008735381416045129, 0.013999436981976032, 0.037925101816654205, -0.025955673307180405, -0.034053295850753784, -0.03811127692461014, 0.035823218524456024, -0.020384028553962708, -0.04329202324151993, 0.025228779762983322, 0.017868930473923683, 0.012399041093885899, -0.006180254276841879, -0.00040510325925424695, -0.01784687489271164, -0.021618356928229332, -0.053620751947164536, -0.02602216973900795, -0.02569330856204033, 0.0455714650452137, 0.021134119480848312, -0.010057896375656128, 0.00021837491658516228, 0.009183375164866447, -0.042495209723711014, -0.011210902594029903, 0.02126901224255562, 0.040576864033937454, 0.02744336612522602, -0.04371003806591034, -0.025294190272688866, 0.05447546765208244, 0.03345421701669693, 0.05211234837770462, 0.015131429769098759, -0.048012059181928635, 0.04397883266210556, -0.022203652188181877, -0.020084137097001076, -0.03183945268392563, -0.020201584324240685, -0.013390760868787766, -0.0026066831778734922, 0.001619735499843955, -0.042408157140016556, -0.04422574117779732, -0.0021670775022357702, 0.02117401547729969, 0.005997142288833857, 0.00697875814512372, -0.02256615087389946, -0.021681146696209908, 0.04869481176137924, 0.013847259804606438, 0.01571323722600937, 0.0004055400495417416, -0.051475655287504196, -0.019919797778129578, 0.001913769287057221, -0.005972045473754406, -0.020302969962358475, 0.023054851219058037, 0.0004860475892201066, 0.0253022238612175, 0.015149462968111038, 0.04368478059768677, -0.029273713007569313, 0.04063477739691734, -0.030807433649897575, 0.021939076483249664, 0.04805157706141472], [0.005676080007106066, -0.036704353988170624, 0.035494714975357056, -0.007823120802640915, -0.046174317598342896, 0.05375393107533455, -0.030921123921871185, -0.04651007428765297, -0.03737987205386162, 0.006578399799764156, 0.02082371525466442, -0.044115424156188965, 0.03129076212644577, 0.02521579898893833, 0.03844958916306496, 0.02291991002857685, -0.029934288933873177, 0.0004015771555714309, -0.00015156167501118034, -0.012700148858129978, -1.1766324860218447e-05, -0.03469853103160858, -0.0350385382771492, 0.012130971066653728, -0.01640220731496811, -0.03818722069263458, -0.014248584397137165, -0.03649555519223213, -0.003968792036175728, 0.013869560323655605, -0.006737067364156246, 0.008266022428870201, -0.004526012111455202, -0.028659848496317863, 0.03210797905921936, -0.01933935657143593, -0.03068704344332218, -0.037693630903959274, 0.03987818956375122, 0.012911255471408367, 0.01973322592675686, 0.038846198469400406, -0.004424275364726782, 0.032318294048309326, 0.020464351400732994, 0.01492531318217516, -0.024744337424635887, -0.022128796204924583, 0.005516841076314449, -0.014769797213375568, 0.041699979454278946, -0.031360723078250885, 0.03778462111949921, 0.013969171792268753, -0.02609521895647049, 0.021390294656157494, 0.008847316727042198, 0.027346141636371613, -0.03202597796916962, 0.008541223593056202, 0.023303857073187828, -0.005069676786661148, 0.039636023342609406, -0.024364719167351723, 0.04059111326932907, -0.04393473267555237, 0.020136112347245216, 0.011293996125459671, 0.006186254322528839, 0.01907193288207054, -0.04659726843237877, -0.027077483013272285, 0.033742424100637436, 0.023305339738726616, 0.0318569578230381, -0.026596255600452423, -0.05096361041069031, 0.009091203100979328, 0.04806269705295563, 0.03858286514878273, -0.054929692298173904, -0.03214521333575249, -0.04685264825820923, 0.01602523773908615, 0.02798425778746605, -0.02225690707564354, 0.016901768743991852, -0.03635934367775917, 0.04465927928686142, 0.022573737427592278, 0.01415086630731821, -0.006699568126350641, 0.020358387380838394, 0.03569084778428078, -0.02745581418275833, -0.0294774379581213, -0.05011982098221779, 0.03911321982741356, 0.02135600335896015, -0.00012831977801397443, -0.027160583063960075, -0.052583880722522736, 0.004147831816226244, 0.0157763808965683, 0.036649782210588455, -0.04068402573466301, -0.04313195124268532, 0.0035520608071237803, -0.04728621244430542, -0.03149890527129173, -0.03451161831617355, -0.01892726682126522, -0.03286845237016678, -0.012930112890899181, -0.039834968745708466, 0.04655034840106964, 0.02342984825372696, -0.027771657332777977, 0.012092836201190948, 0.0193637665361166, 0.08110708743333817, 0.027394644916057587, -0.03247971460223198, -0.06851837784051895, -0.03919007256627083, 0.051911938935518265, -0.02698204107582569, -0.039103858172893524, 0.03664608299732208, 0.04695708304643631, -0.011607496999204159, -0.022689754143357277, 0.00409634318202734, 0.02986581064760685, 0.014552047476172447, 0.025538280606269836, -0.024396585300564766, -0.05346357822418213, 0.006447454448789358, 0.019318517297506332, -0.03390907123684883, -0.038898929953575134, 0.04580974951386452, 0.016016453504562378, 0.015777453780174255, -0.030126433819532394, -0.03163473680615425, -0.03419160842895508, -0.053242672234773636, -0.06055103614926338, -0.0024940285366028547, -0.01882164552807808, -0.029594197869300842, -0.05674224719405174, 0.04474635794758797, -0.08709212392568588, 0.012706711888313293, -0.04097211733460426, -0.02119772881269455, 0.022562406957149506, 0.04812529310584068, 0.0051221647299826145, -0.016733471304178238, 0.012900260277092457, 0.010361792519688606, -0.02620677836239338, 0.02722844108939171, -0.02323594130575657, -0.03614398464560509, 0.02695070207118988, -0.006157638039439917, 0.03970663249492645, 0.036426663398742676, 0.016728464514017105, 0.042201459407806396, -0.020326873287558556, 0.013198530301451683, -0.012749099172651768, 0.023666825145483017, 0.019381674006581306, -0.010246501304209232, 0.007807993795722723, -0.009461082518100739, -0.012483257800340652, -0.06123732030391693, 0.01746169663965702, 0.0382746197283268, -0.024853484705090523, 0.03429277986288071, -0.061001550406217575, -0.013207989744842052, 0.006929862778633833, -0.01589169166982174, 0.028207330033183098, -0.034947339445352554, -0.02626858837902546, -0.015681518241763115, -0.01222473755478859, -0.0367361418902874, 0.017901437357068062, 0.02214706502854824, 0.012033972889184952, -0.03962277993559837, -0.020136266946792603, -0.009428240358829498, 0.035399340093135834, 0.014092491939663887, 0.017564067617058754, -0.019758978858590126, -0.001249267952516675, 0.04660608991980553, -0.005936269648373127, 0.02037089131772518, -0.01823470927774906, -0.01764828711748123, 0.052400682121515274, 0.03741314634680748, -0.004101206082850695, -0.0017134586814790964, 0.013080109842121601, -0.059598714113235474, 0.011101499199867249, 0.03951346129179001, 0.0061516049318015575, -0.0070058004930615425, -0.039118725806474686, -0.02935340628027916, 0.01618986204266548, 0.005241130478680134, -0.034820474684238434, 0.01857234723865986, 0.012358765117824078, -0.025646034628152847, -0.024428660050034523, -0.020592864602804184, -0.028655122965574265, 0.044511664658784866, -0.03308812528848648, 0.0351237878203392, 0.0399923250079155, 0.023755038157105446, 0.04113340750336647, 0.021408023312687874, -0.023122746497392654, 0.03481697663664818, 0.03664380684494972, 0.013591482304036617, 0.0205018799751997, 0.04723899066448212, 0.06253422796726227, 0.021569767966866493, 0.014034854248166084, -0.027751265093684196, -0.02064807154238224, -0.015708986669778824, 0.02283383719623089, 0.039556439965963364, -0.03583875298500061, -0.03724706172943115, 0.040688082575798035, 0.01472489908337593, -0.05946725606918335, -0.05367007106542587, -0.0104987109079957, -0.011414728127419949, -0.015963172540068626, -0.004431278444826603, -0.0458219014108181, 0.08308762311935425, -0.011930693872272968, 0.0231876652687788, 0.020488150417804718, 0.032052695751190186, -0.024040885269641876, -0.03924524411559105, 0.012438604608178139, -0.03953123092651367, -0.04029303044080734, -0.006268503610044718, 0.021206146106123924, -0.005336239468306303, 0.0086747445166111, 0.03743213042616844, 0.028163736686110497, -0.017316296696662903, 0.06425037980079651, -0.03112260438501835, 0.005256559234112501, -0.00034152489388361573, 0.03529924526810646, -0.029221152886748314, 0.0004844300274271518, 0.03434918820858002, -0.004655854776501656, -0.011887910775840282, 0.0148532185703516, -0.0233015064150095, 0.002664099680259824, 0.03274787589907646, 0.04451422020792961, 0.04929056391119957, -0.009502989239990711, -0.079266756772995, -0.030309151858091354, -0.01321176066994667, -0.031944841146469116, 0.021245181560516357, -0.024561364203691483, 0.021639598533511162, 0.03820274770259857, -0.01932782679796219, -0.0335334911942482, -0.05734799802303314, -0.035165935754776, -0.04258536547422409, -0.032556530088186264, -0.017529992386698723, 0.023965850472450256, 0.01746627874672413, -0.00595874385908246, 0.06815528124570847, 0.00897863321006298, -0.03015275113284588, -0.03513622656464577, -0.021135708317160606, 0.0034602596424520016, -0.01699761673808098, 0.0037350559141486883, -0.004025489557534456, -0.025805307552218437, -0.024345271289348602, -0.01653750240802765, 0.05022164061665535, -0.0009772933553904295, -0.0030797524377703667, -0.014997401274740696, -0.01544457022100687, -0.009267846122384071, 0.028092946857213974, 0.06611272692680359, 0.03811433166265488, 0.022968152537941933, -0.03122781030833721, -0.040149006992578506, 0.009163600392639637, 0.02853809855878353, 0.04667346924543381, 0.018369577825069427, 0.028846219182014465, 0.021188322454690933, 0.05845121666789055, 0.0461333766579628, -0.01364111714065075, -0.016840584576129913, -0.02318754605948925, -0.01637876406311989, 0.026450537145137787, -0.0458146370947361, 0.0036251305136829615, 0.006121705751866102, 0.043343350291252136, -0.02400505729019642, 0.03438689932227135, -0.0026942268013954163, -0.028916187584400177, -0.04794872924685478, 0.044074732810258865, -0.01005795318633318, 0.012436122633516788, 0.02379383146762848, -0.01761684939265251, 0.03570031374692917, 0.01997210644185543, -0.05430452153086662, -0.03547603264451027, -0.002572274301201105, 0.013000097125768661, 0.03161676228046417, 0.052803222090005875, -0.020647134631872177, 0.008885032497346401, 0.041071172803640366, 0.002649574540555477, -0.05571112781763077, -0.05426977947354317, -0.03632628172636032, 0.004984819795936346, -0.02781679481267929, -0.010007250122725964, -0.05701030418276787, 0.011646619066596031, -0.07145001739263535, 0.02836783416569233, -0.03709886595606804, -0.010166160762310028, -0.016895243898034096, 0.04026725888252258, -0.010529451072216034, 0.022084690630435944, 0.03987782448530197, 0.042844612151384354, 0.026906948536634445, 0.022968124598264694, -0.0009060278534889221, -0.054687730967998505, -0.020949695259332657, 0.038033489137887955, 0.026565637439489365, 0.023455247282981873, -0.018687354400753975, -0.032581720501184464, 0.028237368911504745, 0.03512132540345192, 0.009163450449705124, -0.01398773118853569, 0.02802903763949871, -0.0023881166707724333, 0.04248630627989769, -0.024173714220523834, -0.029514100402593613, -0.017082909122109413, -0.02832174301147461, -0.008712328039109707, -0.026690149679780006, 0.046171706169843674, -0.0052511426620185375, 0.0017717599403113127, -0.009606890380382538, 0.013330210000276566, -0.01123860664665699, 0.04727114364504814, -0.02916952595114708, -0.02471335604786873, -0.025191491469740868, 0.023405054584145546, -0.040562644600868225, 0.02339489944279194, -0.029713189229369164, 0.05119532346725464, 0.005989996716380119, 0.0269358828663826, 0.05557902157306671, -0.010167758911848068, -0.03404225781559944, 0.027786845341324806, -0.03352922946214676, -0.0716829001903534, -0.014354334212839603, -0.022615309804677963, 0.02332431636750698, 0.041812703013420105, -0.009906407445669174, 0.05414718762040138, -0.023610390722751617, -0.03304246813058853, -0.05257038027048111, -0.013457925990223885, 0.013362274505198002, -0.007268256042152643, -0.0012492418754845858, -0.015497276559472084, -0.00799375306814909, 0.037686847150325775, -0.003613694105297327, -0.018276335671544075, -0.0402064211666584, 0.037447739392519, 0.045902449637651443, -0.03441111370921135, 0.046833932399749756, 0.0016034826403483748, -0.059000421315431595, 0.0329272598028183, -0.01576366275548935, -0.03367651253938675, 0.009428351186215878, 0.03667063266038895, 0.04359150677919388, 0.04174063727259636, 0.029263675212860107, -0.03512519225478172, -0.0023222286254167557, 0.012146469205617905, -0.0029022402595728636, -0.037238478660583496, 0.036380428820848465, -0.01822792738676071, -0.007668526843190193, 0.042686156928539276, -0.016341403126716614, -0.0198038462549448, 0.008522145450115204, 0.020506281405687332, 0.03325217217206955, 0.04127616807818413, -0.009237261489033699, -0.026727301999926567, 0.017265941947698593, -0.011539522558450699, -0.013048119843006134, 0.07933719456195831, -0.01386040635406971, 0.012765089049935341, 0.03994022682309151, -0.022880636155605316, 0.041437726467847824, -0.01737089827656746, 0.018835267052054405, -0.016400866210460663, 0.02714916132390499, -0.003709284355863929, -0.011649140156805515, -0.007825714536011219, 0.04416672885417938, 0.043654914945364, 0.024614794179797173, 0.025798913091421127, 0.027021078392863274, 0.006923079956322908, -0.012287585996091366, -0.028414348140358925, -0.024867434054613113, 0.03853675723075867, -0.03798534348607063, -0.03233802691102028, 0.014100984670221806, 0.02496611699461937, 0.010695621371269226, -0.03577862307429314, -0.03996240347623825, -0.0013215159997344017, 0.0288640595972538, -0.042718175798654556, 0.03074280358850956, -0.006402342580258846, 0.030764512717723846, -0.020296210423111916, -0.027671867981553078, -0.013790321536362171, 0.03177561238408089, 0.003694007406011224, 0.04037847742438316, 0.024891948327422142, -0.035505395382642746, -0.022672828286886215, -0.029591770842671394, -0.034406185150146484, 0.010856382548809052, 0.025541134178638458, -0.039182260632514954, 0.0068515632301568985, -0.01766824908554554, -0.04988434538245201, -0.019541995599865913, -0.04085705056786537, 0.059930071234703064, -0.015219935216009617, 0.0077347783371806145, 0.007015719544142485, -0.02244732528924942, 0.029502125456929207, 0.05014720559120178, 0.030618954449892044, -0.004559146706014872, -0.015293285250663757, 0.026739630848169327, -0.008059808984398842, -0.006828598212450743, -0.044905614107847214, 0.03575925529003143, -0.008459468372166157, -0.009232415817677975, 0.03916855901479721, -0.010337740182876587, -0.056154727935791016, 0.04949679970741272, 0.02044251747429371, 0.020414991304278374, 0.06264417618513107, -0.024508539587259293, 0.02624599076807499, -0.04517228156328201, 0.02468261867761612, -0.0012359233805909753, -0.018151739612221718, 0.032049525529146194, -0.016452861949801445, -0.02552567794919014, 0.026117997244000435, 0.06640463322401047, 0.028230804949998856, 0.05122636631131172, -0.027770020067691803, -0.03143749386072159, 0.025634724646806717, -0.0021295498590916395, 0.019900811836123466, -0.047457266598939896, -0.04098907858133316, 0.002303855028003454, 0.04178819805383682, -0.029811805114150047, 0.01492695789784193, -0.03768952563405037, 0.021111825481057167, -0.0011181544978171587, 0.051629964262247086, 0.036303769797086716, 0.02077234722673893, 0.010056449100375175, -0.004951501730829477, 0.01700103096663952, 0.04058542475104332, 0.031163472682237625, -0.04410796985030174, 0.06749670952558517, -0.0220035333186388, -0.007584446109831333, 0.06080259382724762, 0.04480476677417755, -0.013826257549226284, 0.05489928275346756, 0.0450667180120945, 0.06391025334596634, -0.02686377987265587, -0.020249197259545326, 0.01275535300374031, -0.028569404035806656, 0.055799875408411026, 0.04845033213496208, 0.025131484493613243, 0.0009717590874060988, -0.019412623718380928, 0.03640295937657356, -0.019477086141705513, -0.02843329682946205, -0.014670622535049915, -0.048252470791339874, 0.018917107954621315, 0.05411016196012497, 0.04446227476000786, 0.030176861211657524, -0.045883629471063614, 0.052364323288202286, -0.01030047982931137, -0.01072664838284254, -0.04503645375370979, -0.03016069531440735, 0.04314975067973137, -0.013577137142419815, -0.020504385232925415, 0.03867979720234871, -0.02286812663078308, 0.03410216048359871, 0.031305134296417236, 0.03235090151429176, 0.03144287317991257, 0.030160997062921524, 0.025494158267974854, -0.008090730756521225, 0.05829683691263199, 0.006668406073004007, 0.03210848569869995, -0.03528231009840965, 0.01633172482252121, 0.11096690595149994, 0.014906417578458786, 0.019457632675766945, -0.011403067037463188, -0.00837719812989235, 0.027821186929941177, -0.05635535717010498, 0.009375948458909988, -0.025525132194161415, 0.05353953316807747, 0.0663156732916832, 0.03961682319641113, 0.03129996359348297, 0.029178323224186897, -0.023668531328439713, 0.05682874843478203, 0.03660931438207626, -0.030870847404003143, -0.016492705792188644, -0.0003529941604938358, 0.034091655164957047, -0.002121745375916362, -0.0861024558544159, 0.0049462770111858845, 0.02400919981300831, 0.01362336054444313, -0.011042320169508457, -0.022362664341926575, 0.033766187727451324, 0.034698013216257095, -0.03538498282432556, 0.02933412417769432, -0.021315135061740875, -0.04543108865618706, -0.02207336202263832, -0.021653329953551292, -0.021804235875606537, 0.01335033867508173, 0.03624226152896881, -0.0004601991968229413, 0.049638547003269196, 0.036691050976514816, -0.023023054003715515, -0.010733965784311295, 0.011527035385370255, -0.054329778999090195, -0.012765953317284584, -0.011362748220562935, 0.009684380143880844, 0.015080319717526436, 0.00943183433264494, -0.015140929259359837, -0.0009782679844647646, 0.014638369902968407, -0.0035957389045506716, -0.023887140676379204, 0.01569329760968685, 0.008513614535331726, 0.006176024209707975, -0.014949901960790157, -0.004497095476835966, 0.041121143847703934, 0.03329133987426758, 0.025239750742912292, -0.036351144313812256, -0.032999277114868164, 0.015117310918867588, 0.023843001574277878, 0.03077513910830021, -0.04124448075890541, 0.011981399729847908, -0.04316021502017975, 0.015399506315588951, 0.00632665166631341, -0.04241304099559784, -0.0320420004427433, -0.001680112793110311, 0.007329903077334166, -0.012973721139132977, 0.007852080278098583, -0.004195115994662046, -0.022999947890639305, -0.030871016904711723, -0.02127673849463463, 0.026364848017692566, -0.06142794340848923, -0.014931841753423214, 0.031164631247520447, -0.002767994999885559, -0.04753194376826286, -0.04703995957970619, 0.04131738096475601, -0.005263039376586676, 0.02197687327861786, -0.016480397433042526, 0.020299550145864487, -0.017579643055796623, 0.026792258024215698, -0.0008965705637820065, 0.028570124879479408, 0.04891642928123474, 0.015958433970808983, 0.009043638594448566, -0.000893445685505867, -0.045881882309913635, -0.01648479886353016, 0.03730747848749161, 0.0339367613196373, 0.0358148068189621, -0.004203713499009609, 0.02907915972173214, 0.0021058518905192614, -0.003083211835473776, 0.027994858101010323, -0.009671714156866074, 0.019745782017707825, 0.0038164916913956404, -0.03907710313796997, -0.02771567553281784, 0.023488270118832588, 0.029419230297207832, 0.05941205471754074, 0.04433515667915344, 0.004665408283472061, -0.025495771318674088, 0.005688241217285395, 0.020154589787125587, -0.012475600466132164, -0.05171557143330574, -0.0050901081413030624, 0.03591816872358322, -0.03092619776725769, 0.00042829386075027287, -0.01706206612288952, -0.0029456368647515774, 0.03287719190120697, 0.02952205389738083, 0.017498964443802834, -0.03192257136106491, 0.037638530135154724, -0.028442366048693657, -0.031496040523052216, -0.02130098268389702, -0.04630022123456001, 0.02889949642121792, 0.012752266600728035, -0.036513954401016235, 0.016962775960564613, 0.05024481192231178, 0.05328546091914177, -0.0015838382532820106, -0.05918951332569122, 0.028705621138215065, 0.04829036816954613, 0.03290966525673866, 0.02166355773806572, 0.04800906404852867, -0.0421488881111145, 0.0399475172162056, 0.014348664321005344, 0.001049276441335678, 0.021732782945036888, -0.042031507939100266, -0.0218527689576149, -0.04039541259407997, -0.03302350640296936, -0.05050645023584366, -0.024251632392406464, -0.020285647362470627, -0.017149828374385834, 0.01402354147285223, 0.02632162719964981, -0.02710748463869095, -0.01638011634349823, 0.026068463921546936, 0.02358543500304222, 0.018687646836042404, -0.02949104830622673, 0.04184751212596893, 0.030032768845558167, 0.015447890385985374, -0.0059568448923528194, -0.02717725560069084, -0.03172079846262932, 0.0210451390594244, -0.031263116747140884, -0.05809447169303894, 0.03981223702430725, 0.05036233738064766, -0.03198585659265518, 0.0179966539144516, 0.002805297961458564, -0.021888813003897667, -0.023433063179254532, -0.07442235946655273, 0.0021139872260391712, 0.02309942990541458, 0.00314218457788229, -0.004830494057387114, -0.014296827837824821, 0.05220463126897812, 0.03897162154316902, 0.0015593890566378832, 0.059264957904815674, -0.0342276468873024, -0.03617158532142639, -0.05081886425614357, 0.042564958333969116, 0.02626781165599823, -0.02453034184873104, -0.03180797025561333, -0.03585199639201164, 0.03596207872033119, 0.014291257597506046, 0.01765868254005909, 0.039076413959264755, -0.04465148225426674, -0.01677602343261242, 0.028023160994052887, -0.03894740343093872, 0.02929648756980896, 0.025113699957728386, -0.043276652693748474, -0.04519631713628769, -0.04313137009739876, -0.028509585186839104, -0.019259842112660408, 0.04877588897943497, -0.030242513865232468, -0.04021983966231346, 0.03710801154375076, 0.03368110954761505, 0.0038108420558273792, 0.017193296924233437, 0.03885503485798836, -0.026074208319187164, 0.021536720916628838, 0.0136181665584445, -0.022808687761425972, -0.04549071565270424, 0.00478128669783473, -0.06372677534818649, -0.010544788092374802, -0.0483197420835495, 0.02821457013487816, 0.03381205350160599, -0.05470012500882149, 0.042978983372449875, -0.04889887198805809, 0.006836038548499346, -0.03438301756978035, 0.021229544654488564, -0.042714327573776245, -0.05179903656244278, 0.0029739346355199814, 0.02203359454870224, 0.02283603884279728, -0.04466899111866951, -0.015548809431493282, 0.04572761803865433, -0.019311584532260895, -0.02380957640707493, 0.024910569190979004, 0.021552709862589836, -0.05564706400036812, -0.03411944583058357, 0.010197581723332405, 0.0208334568887949, 0.055461157113313675, 0.03791101276874542, -0.005199133884161711, 0.024435704573988914, -0.02694765292108059, -0.033418044447898865, -0.03550488501787186, -0.019164860248565674, 0.026288224384188652, -0.014621170237660408, 0.05505050718784332, -0.05292466655373573, -0.003595946589484811, 0.03508523106575012, -0.00013558384671341628, -0.02801239863038063, -0.016987614333629608, -0.021961666643619537, 0.002422924851998687, -0.017890121787786484, -0.013201506808400154, 0.0053805033676326275, 0.021641448140144348, -0.01516226027160883, -0.040525540709495544, -0.0552092008292675, 0.010913912206888199, 0.002901658648625016, -0.03816034644842148, 0.023080987855792046, 0.02566327527165413, 0.03302076831459999, -0.004425073973834515, 0.029289454221725464, -0.040718019008636475, -0.02066056616604328, -0.04838448762893677, -0.039266426116228104, 0.016259560361504555, 0.04936479032039642, -0.002838114043697715, -0.029373450204730034, 0.03728971257805824, 0.001789653324522078, -0.01917494833469391, -0.0356556735932827, 0.00044831717968918383, 0.03001583367586136, 0.017912523820996284, -0.02920527197420597, -0.0013136257184669375, 0.04448792710900307, 0.001701880362816155, 0.04586954042315483, 0.019970830529928207, -0.027550790458917618, 0.029431650415062904, -0.024754362180829048, -0.021446745842695236, -0.04201207309961319, -0.026781151071190834, -0.011044641025364399, -0.0006387197063304484, -0.004799188114702702, -0.060163285583257675, -0.05113838613033295, -0.02496909350156784, 0.03884066268801689, 0.040960803627967834, 0.025225333869457245, -0.005950512830168009, -0.006251529324799776, 0.04019416123628616, -0.0004795768763870001, 0.02879125438630581, -0.021825993433594704, -0.02459722012281418, -0.009021984413266182, -0.0064871106296777725, -0.0015985729405656457, -0.012944800779223442, 0.021087056025862694, -0.005682928953319788, -0.008894559927284718, 0.04405303671956062, -0.00885086040943861, -0.006319083273410797, 0.044590167701244354, -0.01608026959002018, 0.015452947467565536, 0.030829155817627907]]\n"
     ]
    }
   ],
   "source": [
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`VisionLanguageEmbedding`\n",
    "\n",
    "VisionLanguageEmbedding 是一个基于多模态模型（如 CLIP）的嵌入生成类，能够同时处理图像和文本输入，生成对应的嵌入向量。，默认使用本地的openai/clip-vit-base-patch32模型（如果没有会自动下载）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    }
   ],
   "source": [
    "from camel.embeddings import VisionLanguageEmbedding\n",
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "# 初始化视觉语言嵌入模型\n",
    "vlm_embedding = VisionLanguageEmbedding()\n",
    "\n",
    "# 下载测试图像\n",
    "url = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n",
    "test_images = [image, image]\n",
    "\n",
    "# 为一组图像生成嵌入向量\n",
    "embeddings = vlm_embedding.embed_list(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.10570287704467773, 0.13790832459926605, -0.2961166203022003, 0.021249782294034958, -0.06406781077384949, -0.1686195731163025, -0.1351460963487625, -0.00244689779356122, 0.4737624526023865, -0.176269993185997, 0.24439959228038788, -0.3797181248664856, 0.048328496515750885, -0.13981252908706665, -0.3404472768306732, -0.12675951421260834, -0.2326601892709732, -0.2975958585739136, 0.1788603663444519, 0.049609385430812836, -1.3074264526367188, -0.03243662789463997, 0.4214421808719635, -0.3336305618286133, -0.04737268015742302, 0.2980453073978424, 0.23910017311573029, -0.18429043889045715, 0.15669099986553192, -0.04880736023187637, -0.07758715003728867, 0.2588755190372467, -0.07355327159166336, 0.17691943049430847, -0.5791766047477722, -0.00492118950933218, 0.279061496257782, -0.2870664894580841, 0.1908007562160492, 0.32632556557655334, -0.10050452500581741, -0.3464755117893219, 0.007166767027229071, -0.1474604606628418, -0.1901044398546219, 0.000576389895286411, 0.5202240943908691, 0.15116697549819946, -0.09164635092020035, 0.1759442836046219, 0.16325300931930542, 0.2515672743320465, 0.11609247326850891, -0.0537881962954998, 0.2287086844444275, 0.18607613444328308, 0.2576334774494171, 0.6031379699707031, -0.2582339644432068, -0.16781078279018402, 0.4238543212413788, -0.13951164484024048, -0.0637437030673027, 0.3556762635707855, -0.07424549013376236, -0.2709555923938751, 0.22417069971561432, 1.0961954593658447, 0.19659291207790375, 0.07891951501369476, 0.2009924352169037, -0.10656934976577759, 0.27643445134162903, 0.2766098082065582, 0.49342411756515503, -0.01694260910153389, 0.06394752115011215, -0.34030768275260925, -0.052759867161512375, -0.13829007744789124, -0.18781282007694244, -0.6763344407081604, -0.4583938419818878, -0.01578698121011257, -0.5526782274246216, 0.2626262307167053, 0.4310169816017151, -0.5373604893684387, 0.29390549659729004, 0.09334171563386917, 0.1796339601278305, 0.027744537219405174, -7.342144966125488, 0.32605352997779846, -0.21535468101501465, 0.06709806621074677, 0.17347723245620728, -0.4252172112464905, -0.9265757203102112, 1.2662962675094604, -0.029130205512046814, 0.06121497228741646, -0.3054248094558716, -0.007549733854830265, 0.7245294451713562, 0.2502268850803375, 1.2299761772155762, 0.2684324383735657, -0.18050503730773926, -0.4729684591293335, -0.15611019730567932, -1.0560795068740845, 0.062212903052568436, 0.1999305933713913, 0.18817299604415894, 0.05971193686127663, 0.08617264777421951, 0.1167871281504631, 0.17643164098262787, -0.10635204613208771, 0.16236548125743866, -0.2102217674255371, -0.18188658356666565, 0.39628860354423523, -0.16403713822364807, -0.09291551262140274, -0.06028461456298828, 0.518394947052002, -0.1298706978559494, 0.028778063133358955, -0.05297021195292473, 0.07834135740995407, -0.19674336910247803, 0.9479541778564453, -0.41044285893440247, -0.3808958828449249, 0.1484849750995636, -0.4870170056819916, -0.41069623827934265, -0.1297605335712433, 0.15801949799060822, -0.3749215006828308, 0.3536660075187683, 0.4143676459789276, -0.1529131680727005, 0.28546711802482605, 0.32227078080177307, -0.5626535415649414, 0.08844893425703049, 0.24727967381477356, -0.48397302627563477, 0.18799111247062683, -0.3098369538784027, -0.22550925612449646, 0.019978128373622894, -0.05936810374259949, -0.3353929817676544, -0.47572511434555054, 0.11814451962709427, -0.40058043599128723, -0.02725914865732193, -0.2631533443927765, 0.11216927319765091, 0.22248278558254242, 0.00032498230575583875, -0.3847002685070038, -0.5201435089111328, 0.5281499624252319, 0.14545218646526337, 0.3045424520969391, 0.22328948974609375, 0.6872171759605408, 0.3052091896533966, -0.22130557894706726, -0.21167302131652832, 0.18805557489395142, 0.02205582894384861, 0.054691191762685776, 0.06969290226697922, 0.25775957107543945, -0.3721771836280823, 0.2323644906282425, -0.12269175797700882, -0.3624076843261719, -0.05869681015610695, 0.13108740746974945, 0.16810686886310577, -0.37949955463409424, 0.3286226987838745, -0.17761076986789703, 0.34696701169013977, -0.2887468636035919, -0.5429430603981018, -0.13270798325538635, -0.4873364567756653, -0.03303704038262367, -0.2627478539943695, -0.3498809039592743, -1.1122246980667114, -0.42773139476776123, 0.04396625608205795, 0.36075636744499207, 0.13401471078395844, 0.1844361275434494, -0.1015341728925705, -0.012237987481057644, 0.3283138573169708, 0.0674000233411789, -0.3025658428668976, 0.5625006556510925, -0.41209518909454346, 0.517858624458313, -0.03543311730027199, 0.33271461725234985, -0.42546024918556213, -0.3523058295249939, -0.002903853775933385, -0.7160463929176331, 0.8259756565093994, -0.3952375054359436, 0.0036206035874783993, 0.1551610231399536, -0.1997491866350174, 0.16136769950389862, -0.049928486347198486, 0.3685624897480011, 0.14779071509838104, -0.06942875683307648, 0.024152688682079315, -0.19426144659519196, -0.15363487601280212, 0.05179412662982941, -0.33299559354782104, 0.7616146802902222, 0.27635589241981506, -0.5335884094238281, -0.35003840923309326, 0.13251447677612305, 0.1488550901412964, -0.1880979835987091, 0.35506176948547363, -0.18194417655467987, -0.12301397323608398, -0.029973134398460388, -0.3248729109764099, 0.6294808387756348, 0.12427495419979095, -0.0464070625603199, -0.10913486778736115, 0.7081344723701477, 0.014802983961999416, 0.2766379117965698, -0.16041365265846252, -0.07424517720937729, 0.19206024706363678, 0.04841800779104233, -0.040806133300065994, -0.2754298746585846, -0.6399129033088684, -0.04421733319759369, -0.08591523766517639, 0.033266011625528336, -0.003534953109920025, 0.4533911347389221, 0.3268156945705414, -0.10774042457342148, -0.5372125506401062, -0.42815184593200684, -0.2819831669330597, 0.06113041192293167, -0.24625198543071747, -0.2074507772922516, 0.319989413022995, -0.13205160200595856, -0.22901397943496704, -0.18603861331939697, -0.01749206706881523, 0.17489032447338104, -0.4399864077568054, 0.10667271167039871, 0.3400995433330536, 0.2552586495876312, -0.3855089247226715, -0.06277640163898468, -0.22571112215518951, 0.07508645951747894, 0.017718231305480003, -0.013167144730687141, 0.4833050072193146, -0.19815687835216522, -0.14375098049640656, 0.17780661582946777, 0.27620866894721985, 0.3070693016052246, 0.1892937272787094, 0.19519908726215363, 0.26624596118927, -0.574797511100769, 0.007932588458061218, -0.15115346014499664, 0.23183037340641022, -0.14169497787952423, -0.11889635026454926, 0.4325288236141205, -0.09807692468166351, 0.3085118532180786, -0.0670490637421608, 0.3769824206829071, 0.08892586827278137, -0.18220478296279907, -0.5874049663543701, 0.27005571126937866, 0.9468771815299988, -0.06251055747270584, -0.18786485493183136, 0.25662338733673096, 0.1521727591753006, 0.48819977045059204, 0.18437908589839935, 0.2582789957523346, -0.1951378881931305, 1.6153086423873901, -0.5838145613670349, -0.03616561368107796, -0.24055926501750946, -0.13784334063529968, -0.09420888125896454, 0.5713981986045837, 0.19949397444725037, 0.026506396010518074, 0.014180918224155903, -0.15593117475509644, -0.17335952818393707, -0.14923825860023499, 0.034074947237968445, 0.5384852886199951, 0.07338636368513107, 0.1154211163520813, -0.015294651500880718, -0.022719629108905792, -0.019320622086524963, -0.05720587447285652, 0.21120786666870117, 0.07740107923746109, 0.2093820869922638, -0.4905032515525818, -0.12305721640586853, 0.1613413542509079, -0.08367418497800827, 0.0347759984433651, 0.11502520740032196, -0.2266622930765152, 0.5562050938606262, -0.40450263023376465, -0.20487172901630402, -0.10599718987941742, -0.27015450596809387, 0.26361173391342163, 0.2026362270116806, 0.3797832727432251, 0.15335138142108917, 0.12604907155036926, 0.0005003748228773475, -0.13194556534290314, -0.4700705409049988, 0.19778715074062347, 0.2908989191055298, -0.5481200814247131, 0.5849916338920593, -0.10590056329965591, 0.4754502475261688, 0.5050011277198792, -0.21748889982700348, -0.5940446853637695, 0.324834942817688, -0.15169990062713623, 1.8060166835784912, 0.07167848199605942, -0.4235505759716034, -0.07422562688589096, 0.06789050251245499, -0.5189818739891052, -0.16755472123622894, 0.42614543437957764, -0.12730003893375397, 0.016013871878385544, -0.11366309970617294, -0.4308634102344513, 0.12056116759777069, -0.8434318900108337, -0.32650139927864075, -0.4506414830684662, 0.11178594082593918, -0.26110967993736267, 0.19197137653827667, 0.12052135914564133, 0.4527924656867981, -0.3254508972167969, -0.35914281010627747, -0.27329349517822266, 0.03760543838143349, 0.2105000913143158, 0.4331527054309845, 0.28788870573043823, 0.09515269100666046, -0.03664647787809372, -0.20286346971988678, -0.45809832215309143, 0.6241486668586731, 0.03484102338552475, 0.5037246346473694, 0.7976609468460083, -0.1845136284828186, 0.26256075501441956, 0.0005574012757278979, -0.655474841594696, -0.337655246257782, -0.06358753144741058, -0.04020549729466438, -0.3678789734840393, -0.5800904631614685, 0.3292722702026367, 0.20085851848125458, 0.4227868914604187, 0.12952920794487, 0.0024371568579226732, 0.11158574372529984, -0.3712834119796753, 0.661823570728302, 0.2800860106945038, -0.3279719054698944, 0.7938916683197021, -0.5152537822723389, 0.268688827753067, -0.048718299716711044, -0.5801697373390198, -0.039885733276605606, 0.42183607816696167, 0.29164037108421326, 0.012953439727425575, -0.11650488525629044, -0.26768186688423157, 0.06793604046106339, -0.11774623394012451, 0.34765082597732544, -0.034616515040397644, 0.052752990275621414, -0.2952340245246887, -0.1953635960817337, -0.4187326729297638, -0.5584258437156677, -0.25225090980529785, -0.5310556292533875, 0.5352289080619812, -0.12159460783004761, -0.3084128499031067, 0.3726056218147278, 0.44893625378608704, 0.13557082414627075, 0.4511381983757019, -0.3281148672103882, -0.3968115746974945, 0.08492794632911682, -0.29096218943595886, 0.4158340394496918, 0.14221835136413574, -0.29783567786216736, -0.21870878338813782, -0.1939195841550827, -0.40934085845947266, 0.4281124174594879, -0.5089697241783142, -0.4147295653820038, -0.10546576231718063, -0.6701427698135376, -0.48980557918548584, -0.3761879503726959, -0.13543768227100372, -0.1233663484454155, -0.7220541834831238, -0.062176428735256195, -0.09981224685907364, 0.055190782994031906, 0.07306520640850067, 0.24989700317382812, 0.15880087018013, -0.200900137424469, 0.11332342028617859, -0.2510400414466858, -0.15369555354118347, -0.04350591078400612, -0.0851193219423294, -0.19081397354602814, -0.41291895508766174, 0.6238710880279541, 0.19057202339172363, 0.07978898286819458, 0.3065512776374817, 0.1208748072385788, 0.13618458807468414, -0.1666731983423233, 0.5703007578849792, -0.30685821175575256, -0.1733494997024536, 0.07368696480989456, -0.22815346717834473, 0.13494588434696198, -0.44910046458244324, 0.12776723504066467, 0.8668157458305359, -0.014580564573407173, 0.2563157379627228], [-0.10570287704467773, 0.13790832459926605, -0.2961166203022003, 0.021249782294034958, -0.06406781077384949, -0.1686195731163025, -0.1351460963487625, -0.00244689779356122, 0.4737624526023865, -0.176269993185997, 0.24439959228038788, -0.3797181248664856, 0.048328496515750885, -0.13981252908706665, -0.3404472768306732, -0.12675951421260834, -0.2326601892709732, -0.2975958585739136, 0.1788603663444519, 0.049609385430812836, -1.3074264526367188, -0.03243662789463997, 0.4214421808719635, -0.3336305618286133, -0.04737268015742302, 0.2980453073978424, 0.23910017311573029, -0.18429043889045715, 0.15669099986553192, -0.04880736023187637, -0.07758715003728867, 0.2588755190372467, -0.07355327159166336, 0.17691943049430847, -0.5791766047477722, -0.00492118950933218, 0.279061496257782, -0.2870664894580841, 0.1908007562160492, 0.32632556557655334, -0.10050452500581741, -0.3464755117893219, 0.007166767027229071, -0.1474604606628418, -0.1901044398546219, 0.000576389895286411, 0.5202240943908691, 0.15116697549819946, -0.09164635092020035, 0.1759442836046219, 0.16325300931930542, 0.2515672743320465, 0.11609247326850891, -0.0537881962954998, 0.2287086844444275, 0.18607613444328308, 0.2576334774494171, 0.6031379699707031, -0.2582339644432068, -0.16781078279018402, 0.4238543212413788, -0.13951164484024048, -0.0637437030673027, 0.3556762635707855, -0.07424549013376236, -0.2709555923938751, 0.22417069971561432, 1.0961954593658447, 0.19659291207790375, 0.07891951501369476, 0.2009924352169037, -0.10656934976577759, 0.27643445134162903, 0.2766098082065582, 0.49342411756515503, -0.01694260910153389, 0.06394752115011215, -0.34030768275260925, -0.052759867161512375, -0.13829007744789124, -0.18781282007694244, -0.6763344407081604, -0.4583938419818878, -0.01578698121011257, -0.5526782274246216, 0.2626262307167053, 0.4310169816017151, -0.5373604893684387, 0.29390549659729004, 0.09334171563386917, 0.1796339601278305, 0.027744537219405174, -7.342144966125488, 0.32605352997779846, -0.21535468101501465, 0.06709806621074677, 0.17347723245620728, -0.4252172112464905, -0.9265757203102112, 1.2662962675094604, -0.029130205512046814, 0.06121497228741646, -0.3054248094558716, -0.007549733854830265, 0.7245294451713562, 0.2502268850803375, 1.2299761772155762, 0.2684324383735657, -0.18050503730773926, -0.4729684591293335, -0.15611019730567932, -1.0560795068740845, 0.062212903052568436, 0.1999305933713913, 0.18817299604415894, 0.05971193686127663, 0.08617264777421951, 0.1167871281504631, 0.17643164098262787, -0.10635204613208771, 0.16236548125743866, -0.2102217674255371, -0.18188658356666565, 0.39628860354423523, -0.16403713822364807, -0.09291551262140274, -0.06028461456298828, 0.518394947052002, -0.1298706978559494, 0.028778063133358955, -0.05297021195292473, 0.07834135740995407, -0.19674336910247803, 0.9479541778564453, -0.41044285893440247, -0.3808958828449249, 0.1484849750995636, -0.4870170056819916, -0.41069623827934265, -0.1297605335712433, 0.15801949799060822, -0.3749215006828308, 0.3536660075187683, 0.4143676459789276, -0.1529131680727005, 0.28546711802482605, 0.32227078080177307, -0.5626535415649414, 0.08844893425703049, 0.24727967381477356, -0.48397302627563477, 0.18799111247062683, -0.3098369538784027, -0.22550925612449646, 0.019978128373622894, -0.05936810374259949, -0.3353929817676544, -0.47572511434555054, 0.11814451962709427, -0.40058043599128723, -0.02725914865732193, -0.2631533443927765, 0.11216927319765091, 0.22248278558254242, 0.00032498230575583875, -0.3847002685070038, -0.5201435089111328, 0.5281499624252319, 0.14545218646526337, 0.3045424520969391, 0.22328948974609375, 0.6872171759605408, 0.3052091896533966, -0.22130557894706726, -0.21167302131652832, 0.18805557489395142, 0.02205582894384861, 0.054691191762685776, 0.06969290226697922, 0.25775957107543945, -0.3721771836280823, 0.2323644906282425, -0.12269175797700882, -0.3624076843261719, -0.05869681015610695, 0.13108740746974945, 0.16810686886310577, -0.37949955463409424, 0.3286226987838745, -0.17761076986789703, 0.34696701169013977, -0.2887468636035919, -0.5429430603981018, -0.13270798325538635, -0.4873364567756653, -0.03303704038262367, -0.2627478539943695, -0.3498809039592743, -1.1122246980667114, -0.42773139476776123, 0.04396625608205795, 0.36075636744499207, 0.13401471078395844, 0.1844361275434494, -0.1015341728925705, -0.012237987481057644, 0.3283138573169708, 0.0674000233411789, -0.3025658428668976, 0.5625006556510925, -0.41209518909454346, 0.517858624458313, -0.03543311730027199, 0.33271461725234985, -0.42546024918556213, -0.3523058295249939, -0.002903853775933385, -0.7160463929176331, 0.8259756565093994, -0.3952375054359436, 0.0036206035874783993, 0.1551610231399536, -0.1997491866350174, 0.16136769950389862, -0.049928486347198486, 0.3685624897480011, 0.14779071509838104, -0.06942875683307648, 0.024152688682079315, -0.19426144659519196, -0.15363487601280212, 0.05179412662982941, -0.33299559354782104, 0.7616146802902222, 0.27635589241981506, -0.5335884094238281, -0.35003840923309326, 0.13251447677612305, 0.1488550901412964, -0.1880979835987091, 0.35506176948547363, -0.18194417655467987, -0.12301397323608398, -0.029973134398460388, -0.3248729109764099, 0.6294808387756348, 0.12427495419979095, -0.0464070625603199, -0.10913486778736115, 0.7081344723701477, 0.014802983961999416, 0.2766379117965698, -0.16041365265846252, -0.07424517720937729, 0.19206024706363678, 0.04841800779104233, -0.040806133300065994, -0.2754298746585846, -0.6399129033088684, -0.04421733319759369, -0.08591523766517639, 0.033266011625528336, -0.003534953109920025, 0.4533911347389221, 0.3268156945705414, -0.10774042457342148, -0.5372125506401062, -0.42815184593200684, -0.2819831669330597, 0.06113041192293167, -0.24625198543071747, -0.2074507772922516, 0.319989413022995, -0.13205160200595856, -0.22901397943496704, -0.18603861331939697, -0.01749206706881523, 0.17489032447338104, -0.4399864077568054, 0.10667271167039871, 0.3400995433330536, 0.2552586495876312, -0.3855089247226715, -0.06277640163898468, -0.22571112215518951, 0.07508645951747894, 0.017718231305480003, -0.013167144730687141, 0.4833050072193146, -0.19815687835216522, -0.14375098049640656, 0.17780661582946777, 0.27620866894721985, 0.3070693016052246, 0.1892937272787094, 0.19519908726215363, 0.26624596118927, -0.574797511100769, 0.007932588458061218, -0.15115346014499664, 0.23183037340641022, -0.14169497787952423, -0.11889635026454926, 0.4325288236141205, -0.09807692468166351, 0.3085118532180786, -0.0670490637421608, 0.3769824206829071, 0.08892586827278137, -0.18220478296279907, -0.5874049663543701, 0.27005571126937866, 0.9468771815299988, -0.06251055747270584, -0.18786485493183136, 0.25662338733673096, 0.1521727591753006, 0.48819977045059204, 0.18437908589839935, 0.2582789957523346, -0.1951378881931305, 1.6153086423873901, -0.5838145613670349, -0.03616561368107796, -0.24055926501750946, -0.13784334063529968, -0.09420888125896454, 0.5713981986045837, 0.19949397444725037, 0.026506396010518074, 0.014180918224155903, -0.15593117475509644, -0.17335952818393707, -0.14923825860023499, 0.034074947237968445, 0.5384852886199951, 0.07338636368513107, 0.1154211163520813, -0.015294651500880718, -0.022719629108905792, -0.019320622086524963, -0.05720587447285652, 0.21120786666870117, 0.07740107923746109, 0.2093820869922638, -0.4905032515525818, -0.12305721640586853, 0.1613413542509079, -0.08367418497800827, 0.0347759984433651, 0.11502520740032196, -0.2266622930765152, 0.5562050938606262, -0.40450263023376465, -0.20487172901630402, -0.10599718987941742, -0.27015450596809387, 0.26361173391342163, 0.2026362270116806, 0.3797832727432251, 0.15335138142108917, 0.12604907155036926, 0.0005003748228773475, -0.13194556534290314, -0.4700705409049988, 0.19778715074062347, 0.2908989191055298, -0.5481200814247131, 0.5849916338920593, -0.10590056329965591, 0.4754502475261688, 0.5050011277198792, -0.21748889982700348, -0.5940446853637695, 0.324834942817688, -0.15169990062713623, 1.8060166835784912, 0.07167848199605942, -0.4235505759716034, -0.07422562688589096, 0.06789050251245499, -0.5189818739891052, -0.16755472123622894, 0.42614543437957764, -0.12730003893375397, 0.016013871878385544, -0.11366309970617294, -0.4308634102344513, 0.12056116759777069, -0.8434318900108337, -0.32650139927864075, -0.4506414830684662, 0.11178594082593918, -0.26110967993736267, 0.19197137653827667, 0.12052135914564133, 0.4527924656867981, -0.3254508972167969, -0.35914281010627747, -0.27329349517822266, 0.03760543838143349, 0.2105000913143158, 0.4331527054309845, 0.28788870573043823, 0.09515269100666046, -0.03664647787809372, -0.20286346971988678, -0.45809832215309143, 0.6241486668586731, 0.03484102338552475, 0.5037246346473694, 0.7976609468460083, -0.1845136284828186, 0.26256075501441956, 0.0005574012757278979, -0.655474841594696, -0.337655246257782, -0.06358753144741058, -0.04020549729466438, -0.3678789734840393, -0.5800904631614685, 0.3292722702026367, 0.20085851848125458, 0.4227868914604187, 0.12952920794487, 0.0024371568579226732, 0.11158574372529984, -0.3712834119796753, 0.661823570728302, 0.2800860106945038, -0.3279719054698944, 0.7938916683197021, -0.5152537822723389, 0.268688827753067, -0.048718299716711044, -0.5801697373390198, -0.039885733276605606, 0.42183607816696167, 0.29164037108421326, 0.012953439727425575, -0.11650488525629044, -0.26768186688423157, 0.06793604046106339, -0.11774623394012451, 0.34765082597732544, -0.034616515040397644, 0.052752990275621414, -0.2952340245246887, -0.1953635960817337, -0.4187326729297638, -0.5584258437156677, -0.25225090980529785, -0.5310556292533875, 0.5352289080619812, -0.12159460783004761, -0.3084128499031067, 0.3726056218147278, 0.44893625378608704, 0.13557082414627075, 0.4511381983757019, -0.3281148672103882, -0.3968115746974945, 0.08492794632911682, -0.29096218943595886, 0.4158340394496918, 0.14221835136413574, -0.29783567786216736, -0.21870878338813782, -0.1939195841550827, -0.40934085845947266, 0.4281124174594879, -0.5089697241783142, -0.4147295653820038, -0.10546576231718063, -0.6701427698135376, -0.48980557918548584, -0.3761879503726959, -0.13543768227100372, -0.1233663484454155, -0.7220541834831238, -0.062176428735256195, -0.09981224685907364, 0.055190782994031906, 0.07306520640850067, 0.24989700317382812, 0.15880087018013, -0.200900137424469, 0.11332342028617859, -0.2510400414466858, -0.15369555354118347, -0.04350591078400612, -0.0851193219423294, -0.19081397354602814, -0.41291895508766174, 0.6238710880279541, 0.19057202339172363, 0.07978898286819458, 0.3065512776374817, 0.1208748072385788, 0.13618458807468414, -0.1666731983423233, 0.5703007578849792, -0.30685821175575256, -0.1733494997024536, 0.07368696480989456, -0.22815346717834473, 0.13494588434696198, -0.44910046458244324, 0.12776723504066467, 0.8668157458305359, -0.014580564573407173, 0.2563157379627228]]\n"
     ]
    }
   ],
   "source": [
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storages\n",
    "\n",
    " **基本概念** \n",
    "\n",
    "Storage模块在CAMEL框架中负责数据的存储与管理，是一个功能全面的框架，提供了统一的接口和数据结构，支持键值存储和向量存储等多种类型的数据存储机制。通过抽象基类与具体实现的结合，Storage模块能够高效地处理数据的读取、写入和检索操作，为RAG应用的实现提供了坚实的基础。\n",
    "\n",
    "---\n",
    "\n",
    " **键值存储** \n",
    "\n",
    " ` BaseKeyValueStorage`  \n",
    "\n",
    " **目的** :作为创建各种键值存储系统的基础抽象类。\n",
    "\n",
    " **功能** :\n",
    "\n",
    "- 标准化数据记录的保存、加载和清除操作。\n",
    "\n",
    "- 主要通过 Python 字典进行接口交互。\n",
    "\n",
    " **应用场景** :\n",
    "\n",
    "- JSON 文件存储\n",
    "\n",
    "- NoSQL 数据库（如 MongoDB 和 Redis）\n",
    "\n",
    "- Python 内存中的字典存储\n",
    "\n",
    "---\n",
    "\n",
    "  `InMemoryKeyValueStorage` \n",
    "\n",
    " **描述** :基于 `BaseKeyValueStorage` 的具体实现，使用内存中的列表存储数据。\n",
    "\n",
    " **特点** :\n",
    "\n",
    "- 适用于临时存储，数据为易失性，程序终止后即丢失。\n",
    "\n",
    " **功能** :\n",
    "\n",
    "- 实现了在内存中保存、加载和清除记录的方法。\n",
    "\n",
    "- 非常适合开发和测试场景，无需持久化存储需求。\n",
    "\n",
    "\n",
    "\n",
    " **向量存储** \n",
    "\n",
    "向量存储（Vector Store）用于存储高维度的向量数据，如文本或图像的嵌入表示。它支持高效的相似度计算和最近邻搜索，是RAG应用中检索相关信息的核心组件。向量存储的特点包括：\n",
    "\n",
    "- **高性能** ：支持大规模数据的快速检索\n",
    "\n",
    "- **可扩展性** ：适应不同规模的数据量\n",
    "\n",
    "- **灵活性** ：支持多种相似度度量方式\n",
    "\n",
    "\n",
    "\n",
    " ` BaseVectorStorage`  \n",
    "\n",
    " **目的** :设计为扩展特定向量存储实现的抽象基类。\n",
    "\n",
    " **特点** :\n",
    "\n",
    "- 支持多种操作，如添加、删除向量，查询相似向量，以及维护向量数据库的状态。\n",
    "\n",
    "- 提供灵活性，可指定向量维度、集合名称、距离度量等参数。\n",
    "\n",
    " **功能** :\n",
    "\n",
    "- 为构建多样化的向量存储解决方案提供基础架构。\n",
    "\n",
    " ` MilvusStorage`  \n",
    "\n",
    " **描述** :基于 `BaseVectorStorage` 的具体实现，专为与 Milvus 交互而设计的存储方案。\n",
    "\n",
    " **特点** :\n",
    "\n",
    "- 针对 Milvus（一个云原生向量搜索引擎）进行优化，支持高效的大规模向量检索和管理操作。\n",
    "\n",
    "Reference:[{u}`Milvus`](https://milvus.io/docs/overview.md/)\n",
    "\n",
    "\n",
    "\n",
    " ` QdrantStorage`  \n",
    "\n",
    " **描述** :基于 `BaseVectorStorage` 的具体实现，专为与 Qdrant 交互而设计。\n",
    "\n",
    " **特点** :\n",
    "\n",
    "- 针对 Qdrant 向量搜索引擎进行优化。\n",
    "\n",
    "- 提供高效的向量存储、管理和查询功能，支持大规模近似最近邻（ANN）搜索。\n",
    "\n",
    " **功能** :\n",
    "\n",
    "- 实现向量的添加、删除、相似度查询等核心操作。\n",
    "\n",
    "- 支持自定义向量维度、集合名称、距离度量（如欧几里得距离、余弦相似度等）。\n",
    "\n",
    "- 与 Qdrant 的 API 无缝集成，适用于高性能向量搜索场景。\n",
    "\n",
    " **适用场景** :\n",
    "\n",
    "- 推荐系统、自然语言处理（NLP）嵌入查询、多媒体检索（图像、音频、视频）等需要高效向量搜索的应用场景。\n",
    "\n",
    "Reference:[{u}`Qdrant`](https://qdrant.tech/)\n",
    "\n",
    "---\n",
    "\n",
    " **图存储** \n",
    "\n",
    " ` BaseGraphStorage`  \n",
    "\n",
    " **目的** :设计为扩展特定图存储实现的抽象基类。\n",
    "\n",
    " **特点** :\n",
    "\n",
    "- 支持多种操作，包括：\n",
    "  \n",
    "  - `get_client` : 获取图存储的客户端连接。\n",
    "  \n",
    "  - `get_schema` : 获取当前的图存储模式信息。\n",
    "  \n",
    "  - `get_structured_schema` : 获取结构化的模式表示。\n",
    "  \n",
    "  - `refresh_schema` : 刷新图存储的模式。\n",
    "  \n",
    "  - `add_triplet` : 添加三元组（节点及边的表示）。\n",
    "  \n",
    "  - `delete_triplet` : 删除三元组。\n",
    "  \n",
    "  - `query` : 执行图查询操作。\n",
    "  \n",
    " **功能** :\n",
    "\n",
    "- 为各种图存储解决方案提供基础架构，便于构建定制化图存储实现。\n",
    "\n",
    " ` NebulaGraph`  \n",
    "\n",
    " **描述** :基于 `BaseGraphStorage` 的具体实现，专为与 NebulaGraph 交互而设计。\n",
    "\n",
    " **特点** :\n",
    "\n",
    "- 面向 NebulaGraph 的优化实现，支持其分布式、高扩展性及高速图数据操作的特性。\n",
    "\n",
    "- 提供了对 NebulaGraph API 的无缝集成，用于高效处理图形数据的存储与查询。\n",
    "\n",
    " **功能** :\n",
    "\n",
    "- 实现了 `BaseGraphStorage` 的所有核心方法，支持快速执行分布式图数据的增删查改操作。\n",
    "\n",
    "- 支持复杂图查询语句，用于大规模图数据的结构化分析和推理。\n",
    "\n",
    " **适用场景** :\n",
    "\n",
    "- 推荐系统、知识图谱、社交网络分析、路径优化及大规模图数据挖掘等需要高性能图存储和查询的场景。\n",
    "\n",
    "Reference:[{u}`NebulaGraph`](https://www.nebula-graph.io/)\n",
    "\n",
    "\n",
    "\n",
    " ` Neo4jGraph`  \n",
    "\n",
    " **描述** :基于 `BaseGraphStorage` 的具体实现，专为与 Neo4j 交互而设计，Neo4j 是业内最受信赖的图数据库之一。\n",
    "\n",
    " **特点** :\n",
    "\n",
    "- 面向 Neo4j 的优化实现，充分利用其强大的关系建模能力和高效的图查询功能。\n",
    "\n",
    "- 支持复杂的图形操作和查询语句，提供强大的可视化和分析功能。\n",
    "\n",
    " **功能** :\n",
    "\n",
    "- 实现 `BaseGraphStorage` 的所有核心方法，包括：\n",
    "  \n",
    "  - `get_client` : 获取连接到 Neo4j 的客户端实例。\n",
    "  \n",
    "  - `get_schema` 和 `refresh_schema` : 管理 Neo4j 图数据库的模式。\n",
    "  \n",
    "  - `add_triplet` 和 `delete_triplet` : 实现节点和关系的添加与删除。\n",
    "  \n",
    "  - `query` : 执行基于 Cypher 的图查询操作。\n",
    "  \n",
    " **适用场景** :\n",
    "\n",
    "- 知识图谱、社交网络分析、推荐系统、诈骗检测、供应链管理及其他需要强关系建模的应用场景。\n",
    "\n",
    " **优势** :\n",
    "\n",
    "- 凭借 Neo4j 的成熟生态系统和广泛支持， `Neo4jGraph` 提供了一种稳定、高性能的解决方案，用于高效存储和处理复杂的图数据。\n",
    "\n",
    "Reference:[{u}`Neo4jGraph`](https://neo4j.com/)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**动手实践**\n",
    "\n",
    "这里以`QdrantStorage`为例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'key2': 'value2'} 0.5669467095138407\n"
     ]
    }
   ],
   "source": [
    "from camel.storages import QdrantStorage, VectorDBQuery, VectorRecord\n",
    "\n",
    "# Create an instance of QdrantStorage with dimension = 4\n",
    "qdrant_storage = QdrantStorage(vector_dim=4, collection_name=\"my_collection\")\n",
    "\n",
    "# Add two vector records\n",
    "qdrant_storage.add([VectorRecord(\n",
    "            vector=[-0.1, 0.1, -0.1, 0.1],\n",
    "            payload={'key1': 'value1'},\n",
    "        ),\n",
    "        VectorRecord(\n",
    "            vector=[-0.1, 0.1, 0.1, 0.1],\n",
    "            payload={'key2': 'value2'},\n",
    "        ),])\n",
    "\n",
    "# Query similar vectors\n",
    "query_results = qdrant_storage.query(VectorDBQuery(query_vector=[0.1, 0.2, 0.1, 0.1], top_k=1))\n",
    "for result in query_results:\n",
    "    print(result.record.payload, result.similarity)\n",
    "\n",
    "# Clear all vectors\n",
    "qdrant_storage.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里计算出的结果是向量之间的余弦距离（默认），CAMEL提供了3种计算距离的方式，可在`QdrantStorage`初始化的时候指定distance参数来选择：\n",
    "```python\n",
    "distance_map = {\n",
    "    VectorDistance.DOT: Distance.DOT,        # 点积距离\n",
    "    VectorDistance.COSINE: Distance.COSINE,  # 余弦距离 \n",
    "    VectorDistance.EUCLIDEAN: Distance.EUCLID # 欧氏距离\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrievers\n",
    "\n",
    " **基本概念** \n",
    "\n",
    "Retrievers 模块可以理解为一个搜索引擎，专门用于在大量文本中高效查找特定信息。它的功能就像一位熟练的图书管理员，帮助你快速找到需要的主题或关键词，无论是基于语义还是关键字。\n",
    "\n",
    "Retrievers 模块支持两种主要的检索方式：向量检索和关键词检索。\n",
    "\n",
    "向量检索器（Vector Retriever）基于向量表示技术，将文本、图像等数据转化为高维向量，通过嵌入模型生成数学表示并存储在向量存储系统中。当用户输入查询时，嵌入模型会将其转换为向量，在存储系统中寻找最接近的匹配向量。这种方式擅长处理语义搜索，能够理解自然语言的模糊关系，常应用于推荐系统、语义查询和跨模态搜索等场景。\n",
    "\n",
    "关键词检索器（Keyword Retriever）则更加直接，通过对文档进行预处理（如分词、建立关键词索引），解析用户的查询关键词并匹配相应的文档内容。它依赖于关键词的精确匹配，适合快速查找特定术语或短语。\n",
    "\n",
    "向量检索器偏向语义层面的理解，适合模糊查询和深度语义挖掘；而关键词检索器则注重精确性，适合快速直接的检索需求。两者结合使用，可以在不同场景中提供高效的解决方案，是知识管理、问答系统和检索增强生成（RAG）任务的重要工具。\n",
    "\n",
    "---\n",
    "\n",
    " **动手实践** \n",
    "\n",
    "1. 向量检索\n",
    "\n",
    "初始化 VectorRetriever\n",
    "\n",
    "我们首先需要初始化 `VectorRetriever` 。可以选择传入一个嵌入模型，如果不提供嵌入模型，默认会使用 `OpenAIEmbedding` 。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/suntao/Documents/GitHub/camel/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from camel.embeddings import SentenceTransformerEncoder\n",
    "from camel.retrievers import VectorRetriever\n",
    "\n",
    "embedding_model=SentenceTransformerEncoder(model_name='intfloat/e5-large-v2')\n",
    "# 初始化 VectorRetriever\n",
    "vr = VectorRetriever(embedding_model= embedding_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "嵌入并存储数据\n",
    "\n",
    "在执行检索之前，需要准备数据并将其存储在向量存储中。 `process` 方法会处理输入内容（可以是文件或 URL），将内容划分为小块，并将这些小块的嵌入存储在指定的向量存储中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 指定内容来源路径，可以是文件路径或 URL\n",
    "content_input_path = \"https://www.camel-ai.org/\"\n",
    "\n",
    "# 创建或初始化向量存储（例如 QdrantStorage）\n",
    "from camel.storages.vectordb_storages import QdrantStorage\n",
    "\n",
    "vector_storage = QdrantStorage(\n",
    "    vector_dim=embedding_model.get_output_dim(),  # 嵌入向量的维度\n",
    "    collection_name=\"my first collection\",          # 向量存储的集合名称\n",
    "    path=\"storage_customized_run\",                  # 向量存储的位置\n",
    ")\n",
    "# 初始化 VectorRetriever\n",
    "vr = VectorRetriever(embedding_model=embedding_model,storage=vector_storage)\n",
    "# 将内容嵌入并存储到向量存储中\n",
    "vr.process(content_input_path, chunk_type=\"chunk_by_title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'similarity score': '0.8443561052465522', 'content path': 'https://www.camel-ai.org/', 'metadata': {'filetype': 'text/html', 'languages': ['eng'], 'link_texts': ['Chain-of-Thought (CoT) Data Generation', 'Self-Instruct: Instruction Generation'], 'link_urls': ['https://github.com/camel-ai/camel/blob/master/camel/datagen/cot_datagen.py', 'https://github.com/camel-ai/camel/tree/master/camel/datagen/self_instruct'], 'url': 'https://www.camel-ai.org/', 'piece_num': 8}, 'extra_info': {}, 'text': \"You Can Use CAMEL to Build\\n\\nCAMEL is the world's first multi-agent system. It is designed to be data-driven, stateful, and agent-friendly.\\n\\n1. Data Generation\\n\\nChain-of-Thought (CoT) Data Generation\\n\\nThe Chain of Thought (CoT) data generation module implements a sophisticated system for generating high-quality reasoning paths through chat agent interactions. It combines several advanced algorithms to produce and validate reasoning chains.\\n\\nSelf-Instruct: Instruction Generation\"}]\n"
     ]
    }
   ],
   "source": [
    "# 指定查询字符串\n",
    "query = \"What is CAMEL\"\n",
    "\n",
    "# 执行查询并检索结果\n",
    "results = vr.query(query)\n",
    "\n",
    "# 打印检索结果\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 自动化检索\n",
    "\n",
    " **AutoRetriever** 方法进一步简化了检索流程，它自动处理嵌入、存储数据以及执行查询的任务，非常适合需要处理多个内容输入路径的场景。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Original Query': 'What is CAMEL-AI', 'Retrieved Context': [{'text': 'No suitable information retrieved from https://www.camel-ai.org/ with similarity_threshold = 0.7.'}]}\n"
     ]
    }
   ],
   "source": [
    "from camel.retrievers import AutoRetriever\n",
    "from camel.types import StorageType\n",
    "\n",
    "# 初始化 AutoRetriever\n",
    "ar = AutoRetriever(\n",
    "    vector_storage_local_path=\"retrievers\",  # 向量存储本地路径\n",
    "    storage_type=StorageType.QDRANT               # 使用 Qdrant 作为存储类型\n",
    ")\n",
    "\n",
    "# 使用 Auto Retriever 执行嵌入、存储和查询\n",
    "retrieved_info = ar.run_vector_retriever(\n",
    "    contents=[\n",
    "        \"https://www.camel-ai.org/\",  # 示例 URL\n",
    "    ],\n",
    "    query=\"What is CAMEL-AI\",         # 查询字符串\n",
    "    return_detailed_info=True         # 是否返回详细信息，包括元数据\n",
    ")\n",
    "\n",
    "# 打印检索结果\n",
    "print(retrieved_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**内容输入路径** ： `contents` 可以是文件路径或 URL，支持多个输入。 **查询字符串** ： `query` 定义了检索目标，AutoRetriever 将根据该字符串搜索相关内容。 **返回详细信息** ：设置 `return_detailed_info=True` 可返回包括元数据在内的详细检索信息。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "camel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
